{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Programming Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model validation on the Iris dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instructions\n",
    "\n",
    "In this notebook, you will build, compile and fit a neural network model to the Iris dataset. You will also implement validation, regularisation and callbacks to improve your model.\n",
    "\n",
    "Some code cells are provided you in the notebook. You should avoid editing provided code, and make sure to execute the cells in order to avoid unexpected errors. Some cells begin with the line: \n",
    "\n",
    "`#### GRADED CELL ####`\n",
    "\n",
    "Don't move or edit this first line - this is what the automatic grader looks for to recognise graded cells. These cells require you to write your own code to complete them, and are automatically graded when you submit the notebook. Don't edit the function name or signature provided in these cells, otherwise the automatic grader might not function properly. Inside these graded cells, you can use any functions or classes that are imported below, but make sure you don't use any variables that are outside the scope of the function.\n",
    "\n",
    "### How to submit\n",
    "\n",
    "Complete all the tasks you are asked for in the worksheet. When you have finished and are happy with your code, press the **Submit Assignment** button at the top of this notebook.\n",
    "\n",
    "### Let's get started!\n",
    "\n",
    "We'll start running some imports, and loading the dataset. Do not edit the existing imports in the following cell. If you would like to make further Tensorflow imports, you should add them here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### PACKAGE IMPORTS ####\n",
    "\n",
    "# Run this cell first to import all required packages. Do not make any imports elsewhere in the notebook\n",
    "from numpy.random import seed\n",
    "seed(8)\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import datasets, model_selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "%matplotlib inline\n",
    "\n",
    "# If you would like to make further imports from tensorflow, add them here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<tr>\n",
    "<td><img src=\"data/iris_setosa.jpg\" alt=\"Drawing\" style=\"height: 270px;\"/></td>\n",
    "<td><img src=\"data/iris_versicolor.jpg\" alt=\"Drawing\" style=\"height: 270px;\"/></td>\n",
    "<td><img src=\"data/iris_virginica.jpg\" alt=\"Drawing\" style=\"height: 270px;\"/></td>\n",
    "</tr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The Iris dataset\n",
    "\n",
    "In this assignment, you will use the [Iris dataset](https://scikit-learn.org/stable/auto_examples/datasets/plot_iris_dataset.html). It consists of 50 samples from each of three species of Iris (Iris setosa, Iris virginica and Iris versicolor). Four features were measured from each sample: the length and the width of the sepals and petals, in centimeters. For a reference, see the following papers:\n",
    "\n",
    "- R. A. Fisher. \"The use of multiple measurements in taxonomic problems\". Annals of Eugenics. 7 (2): 179â€“188, 1936.\n",
    "\n",
    "Your goal is to construct a neural network that classifies each sample into the correct class, as well as applying validation and regularisation techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load and preprocess the data\n",
    "\n",
    "First read in the Iris dataset using `datasets.load_iris()`, and split the dataset into training and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### GRADED CELL ####\n",
    "\n",
    "# Complete the following function. \n",
    "# Make sure to not change the function name or arguments.\n",
    "\n",
    "def read_in_and_split_data(iris_data):\n",
    "    \"\"\"\n",
    "    This function takes the Iris dataset as loaded by sklearn.datasets.load_iris(), and then \n",
    "    splits so that the training set includes 90% of the full dataset, with the test set \n",
    "    making up the remaining 10%.\n",
    "    Your function should return a tuple (train_data, test_data, train_targets, test_targets) \n",
    "    of appropriately split training and test data and targets.\n",
    "    \n",
    "    If you would like to import any further packages to aid you in this task, please do so in the \n",
    "    Package Imports cell above.\n",
    "    \"\"\"\n",
    "    data = iris_data['data']\n",
    "    targets = iris_data['target']\n",
    "    \n",
    "    train_data, test_data, train_targets, test_targets = train_test_split(data, targets, test_size=0.1)\n",
    "    \n",
    "    return (train_data, test_data, train_targets, test_targets)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run your function to generate the test and training data.\n",
    "\n",
    "iris_data = datasets.load_iris()\n",
    "train_data, test_data, train_targets, test_targets = read_in_and_split_data(iris_data)\n",
    "# test_targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now convert the training and test targets using a one hot encoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Constant',\n",
       " 'GlorotNormal',\n",
       " 'GlorotUniform',\n",
       " 'Identity',\n",
       " 'Initializer',\n",
       " 'Ones',\n",
       " 'Orthogonal',\n",
       " 'RandomNormal',\n",
       " 'RandomUniform',\n",
       " 'TruncatedNormal',\n",
       " 'VarianceScaling',\n",
       " 'Zeros',\n",
       " '__builtins__',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__path__',\n",
       " '__spec__',\n",
       " '_sys',\n",
       " 'constant',\n",
       " 'deserialize',\n",
       " 'get',\n",
       " 'glorot_normal',\n",
       " 'glorot_uniform',\n",
       " 'he_normal',\n",
       " 'he_uniform',\n",
       " 'identity',\n",
       " 'lecun_normal',\n",
       " 'lecun_uniform',\n",
       " 'ones',\n",
       " 'orthogonal',\n",
       " 'serialize',\n",
       " 'zeros']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert targets to a one-hot encoding\n",
    "\n",
    "train_targets = tf.keras.utils.to_categorical(np.array(train_targets))\n",
    "test_targets = tf.keras.utils.to_categorical(np.array(test_targets))\n",
    "# train_data\n",
    "dir(tf.keras.initializers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build the neural network model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can now construct a model to fit to the data. Using the Sequential API, build your model according to the following specifications:\n",
    "\n",
    "* The model should use the `input_shape` in the function argument to set the input size in the first layer.\n",
    "* The first layer should be a dense layer with 64 units.\n",
    "* The weights of the first layer should be initialised with the He uniform initializer.\n",
    "* The biases of the first layer should be all initially equal to one.\n",
    "* There should then be a further four dense layers, each with 128 units.\n",
    "* This should be followed with four dense layers, each with 64 units.\n",
    "* All of these Dense layers should use the ReLU activation function.\n",
    "* The output Dense layer should have 3 units and the softmax activation function.\n",
    "\n",
    "In total, the network should have 10 layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### GRADED CELL ####\n",
    "\n",
    "# Complete the following function. \n",
    "# Make sure to not change the function name or arguments.\n",
    "\n",
    "def get_model(input_shape):\n",
    "    \"\"\"\n",
    "    This function should build a Sequential model according to the above specification. Ensure the \n",
    "    weights are initialised by providing the input_shape argument in the first layer, given by the\n",
    "    function argument.\n",
    "    Your function should return the model.\n",
    "    \"\"\"\n",
    "    initializer = tf.keras.initializers.he_uniform()\n",
    "    model = Sequential([\n",
    "        Dense(64, \n",
    "              kernel_initializer=initializer, \n",
    "              bias_initializer='ones', \n",
    "              activation='relu', \n",
    "              input_shape=input_shape),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dense(3, activation='softmax')\n",
    "    ])\n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run your function to get the model\n",
    "\n",
    "model = get_model(train_data[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compile the model\n",
    "\n",
    "You should now compile the model using the `compile` method. Remember that you need to specify an optimizer, a loss function and a metric to judge the performance of your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### GRADED CELL ####\n",
    "\n",
    "# Complete the following function. \n",
    "# Make sure to not change the function name or arguments.\n",
    "\n",
    "def compile_model(model):\n",
    "    \"\"\"\n",
    "    This function takes in the model returned from your get_model function, and compiles it with an optimiser,\n",
    "    loss function and metric.\n",
    "    Compile the model using the Adam optimiser (with learning rate set to 0.0001), \n",
    "    the categorical crossentropy loss function and accuracy as the only metric. \n",
    "    Your function doesn't need to return anything; the model will be compiled in-place.\n",
    "    \"\"\"\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001), loss=tf.keras.losses.categorical_crossentropy, metrics=['acc'] )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run your function to compile the model\n",
    "\n",
    "compile_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fit the model to the training data\n",
    "\n",
    "Now you should train the model on the Iris dataset, using the model's `fit` method. \n",
    "* Run the training for a fixed number of epochs, given by the function's `epochs` argument.\n",
    "* Return the training history to be used for plotting the learning curves.\n",
    "* Set the batch size to 40.\n",
    "* Set the validation set to be 15% of the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### GRADED CELL ####\n",
    "\n",
    "# Complete the following function. \n",
    "# Make sure to not change the function name or arguments.\n",
    "\n",
    "def train_model(model, train_data, train_targets, epochs):\n",
    "    \"\"\"\n",
    "    This function should train the model for the given number of epochs on the \n",
    "    train_data and train_targets. \n",
    "    Your function should return the training history, as returned by model.fit.\n",
    "    \"\"\"\n",
    "    history = model.fit(train_data, train_targets, epochs = epochs, batch_size=40, validation_split=0.15)\n",
    "    return history\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following cell to run the training for 800 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 114 samples, validate on 21 samples\n",
      "Epoch 1/800\n",
      "114/114 [==============================] - 2s 15ms/sample - loss: 1.2166 - acc: 0.5965 - val_loss: 1.2713 - val_acc: 0.5238\n",
      "Epoch 2/800\n",
      "114/114 [==============================] - 0s 696us/sample - loss: 1.1243 - acc: 0.5439 - val_loss: 1.1462 - val_acc: 0.3333\n",
      "Epoch 3/800\n",
      "114/114 [==============================] - 0s 865us/sample - loss: 1.0319 - acc: 0.5614 - val_loss: 1.0414 - val_acc: 0.5238\n",
      "Epoch 4/800\n",
      "114/114 [==============================] - 0s 874us/sample - loss: 0.9642 - acc: 0.7193 - val_loss: 0.9671 - val_acc: 0.9048\n",
      "Epoch 5/800\n",
      "114/114 [==============================] - 0s 881us/sample - loss: 0.9216 - acc: 0.7368 - val_loss: 0.9150 - val_acc: 0.6190\n",
      "Epoch 6/800\n",
      "114/114 [==============================] - 0s 893us/sample - loss: 0.8761 - acc: 0.6667 - val_loss: 0.8743 - val_acc: 0.6190\n",
      "Epoch 7/800\n",
      "114/114 [==============================] - 0s 915us/sample - loss: 0.8360 - acc: 0.6667 - val_loss: 0.8370 - val_acc: 0.6190\n",
      "Epoch 8/800\n",
      "114/114 [==============================] - 0s 869us/sample - loss: 0.7951 - acc: 0.6667 - val_loss: 0.8055 - val_acc: 0.7143\n",
      "Epoch 9/800\n",
      "114/114 [==============================] - 0s 879us/sample - loss: 0.7600 - acc: 0.8333 - val_loss: 0.7788 - val_acc: 0.8095\n",
      "Epoch 10/800\n",
      "114/114 [==============================] - 0s 868us/sample - loss: 0.7244 - acc: 0.9298 - val_loss: 0.7452 - val_acc: 0.9048\n",
      "Epoch 11/800\n",
      "114/114 [==============================] - 0s 881us/sample - loss: 0.6892 - acc: 0.9561 - val_loss: 0.7127 - val_acc: 0.8571\n",
      "Epoch 12/800\n",
      "114/114 [==============================] - 0s 872us/sample - loss: 0.6553 - acc: 0.9561 - val_loss: 0.6822 - val_acc: 0.9048\n",
      "Epoch 13/800\n",
      "114/114 [==============================] - 0s 878us/sample - loss: 0.6229 - acc: 0.9561 - val_loss: 0.6543 - val_acc: 0.9048\n",
      "Epoch 14/800\n",
      "114/114 [==============================] - 0s 888us/sample - loss: 0.5884 - acc: 0.9737 - val_loss: 0.6261 - val_acc: 0.9048\n",
      "Epoch 15/800\n",
      "114/114 [==============================] - 0s 875us/sample - loss: 0.5577 - acc: 0.9561 - val_loss: 0.5970 - val_acc: 0.9048\n",
      "Epoch 16/800\n",
      "114/114 [==============================] - 0s 869us/sample - loss: 0.5240 - acc: 0.9561 - val_loss: 0.5707 - val_acc: 0.9524\n",
      "Epoch 17/800\n",
      "114/114 [==============================] - 0s 882us/sample - loss: 0.4921 - acc: 0.9737 - val_loss: 0.5420 - val_acc: 0.9524\n",
      "Epoch 18/800\n",
      "114/114 [==============================] - 0s 866us/sample - loss: 0.4626 - acc: 0.9737 - val_loss: 0.5136 - val_acc: 0.9524\n",
      "Epoch 19/800\n",
      "114/114 [==============================] - 0s 121us/sample - loss: 0.4340 - acc: 0.9737 - val_loss: 0.4888 - val_acc: 0.9524\n",
      "Epoch 20/800\n",
      "114/114 [==============================] - 0s 2ms/sample - loss: 0.4072 - acc: 0.9737 - val_loss: 0.4648 - val_acc: 0.9524\n",
      "Epoch 21/800\n",
      "114/114 [==============================] - 0s 897us/sample - loss: 0.3833 - acc: 0.9737 - val_loss: 0.4407 - val_acc: 0.9524\n",
      "Epoch 22/800\n",
      "114/114 [==============================] - 0s 889us/sample - loss: 0.3612 - acc: 0.9825 - val_loss: 0.4162 - val_acc: 0.9524\n",
      "Epoch 23/800\n",
      "114/114 [==============================] - 0s 853us/sample - loss: 0.3386 - acc: 0.9737 - val_loss: 0.3963 - val_acc: 0.9048\n",
      "Epoch 24/800\n",
      "114/114 [==============================] - 0s 889us/sample - loss: 0.3203 - acc: 0.9737 - val_loss: 0.3785 - val_acc: 0.9048\n",
      "Epoch 25/800\n",
      "114/114 [==============================] - 0s 905us/sample - loss: 0.3015 - acc: 0.9737 - val_loss: 0.3594 - val_acc: 0.9524\n",
      "Epoch 26/800\n",
      "114/114 [==============================] - 0s 860us/sample - loss: 0.2837 - acc: 0.9825 - val_loss: 0.3400 - val_acc: 0.9524\n",
      "Epoch 27/800\n",
      "114/114 [==============================] - 0s 886us/sample - loss: 0.2658 - acc: 0.9825 - val_loss: 0.3226 - val_acc: 0.9524\n",
      "Epoch 28/800\n",
      "114/114 [==============================] - 0s 869us/sample - loss: 0.2501 - acc: 0.9825 - val_loss: 0.3077 - val_acc: 0.9524\n",
      "Epoch 29/800\n",
      "114/114 [==============================] - 0s 883us/sample - loss: 0.2349 - acc: 0.9737 - val_loss: 0.2891 - val_acc: 0.9524\n",
      "Epoch 30/800\n",
      "114/114 [==============================] - 0s 878us/sample - loss: 0.2190 - acc: 0.9825 - val_loss: 0.2731 - val_acc: 0.9524\n",
      "Epoch 31/800\n",
      "114/114 [==============================] - 0s 873us/sample - loss: 0.2048 - acc: 0.9825 - val_loss: 0.2586 - val_acc: 0.9524\n",
      "Epoch 32/800\n",
      "114/114 [==============================] - 0s 120us/sample - loss: 0.1935 - acc: 0.9737 - val_loss: 0.2516 - val_acc: 0.9524\n",
      "Epoch 33/800\n",
      "114/114 [==============================] - 0s 854us/sample - loss: 0.1781 - acc: 0.9825 - val_loss: 0.2331 - val_acc: 0.9524\n",
      "Epoch 34/800\n",
      "114/114 [==============================] - 0s 2ms/sample - loss: 0.1680 - acc: 0.9912 - val_loss: 0.2216 - val_acc: 0.9524\n",
      "Epoch 35/800\n",
      "114/114 [==============================] - 0s 857us/sample - loss: 0.1575 - acc: 0.9825 - val_loss: 0.2267 - val_acc: 0.9524\n",
      "Epoch 36/800\n",
      "114/114 [==============================] - 0s 901us/sample - loss: 0.1473 - acc: 0.9825 - val_loss: 0.2073 - val_acc: 0.9524\n",
      "Epoch 37/800\n",
      "114/114 [==============================] - 0s 872us/sample - loss: 0.1363 - acc: 0.9912 - val_loss: 0.1977 - val_acc: 0.9524\n",
      "Epoch 38/800\n",
      "114/114 [==============================] - 0s 871us/sample - loss: 0.1305 - acc: 0.9912 - val_loss: 0.2091 - val_acc: 0.9524\n",
      "Epoch 39/800\n",
      "114/114 [==============================] - 0s 872us/sample - loss: 0.1220 - acc: 0.9825 - val_loss: 0.1995 - val_acc: 0.9524\n",
      "Epoch 40/800\n",
      "114/114 [==============================] - 0s 876us/sample - loss: 0.1123 - acc: 0.9912 - val_loss: 0.1814 - val_acc: 0.9048\n",
      "Epoch 41/800\n",
      "114/114 [==============================] - 0s 884us/sample - loss: 0.1072 - acc: 0.9737 - val_loss: 0.1938 - val_acc: 0.9524\n",
      "Epoch 42/800\n",
      "114/114 [==============================] - 0s 876us/sample - loss: 0.0949 - acc: 0.9825 - val_loss: 0.1948 - val_acc: 0.9524\n",
      "Epoch 43/800\n",
      "114/114 [==============================] - 0s 871us/sample - loss: 0.0906 - acc: 0.9825 - val_loss: 0.1887 - val_acc: 0.9524\n",
      "Epoch 44/800\n",
      "114/114 [==============================] - 0s 883us/sample - loss: 0.0849 - acc: 0.9912 - val_loss: 0.1759 - val_acc: 0.9524\n",
      "Epoch 45/800\n",
      "114/114 [==============================] - 0s 874us/sample - loss: 0.0813 - acc: 0.9912 - val_loss: 0.1892 - val_acc: 0.9524\n",
      "Epoch 46/800\n",
      "114/114 [==============================] - 0s 870us/sample - loss: 0.0804 - acc: 0.9912 - val_loss: 0.1836 - val_acc: 0.9524\n",
      "Epoch 47/800\n",
      "114/114 [==============================] - 0s 872us/sample - loss: 0.0727 - acc: 0.9825 - val_loss: 0.2032 - val_acc: 0.9524\n",
      "Epoch 48/800\n",
      "114/114 [==============================] - 0s 869us/sample - loss: 0.0779 - acc: 0.9825 - val_loss: 0.1843 - val_acc: 0.9524\n",
      "Epoch 49/800\n",
      "114/114 [==============================] - 0s 872us/sample - loss: 0.0673 - acc: 0.9912 - val_loss: 0.1979 - val_acc: 0.9524\n",
      "Epoch 50/800\n",
      "114/114 [==============================] - 0s 877us/sample - loss: 0.0668 - acc: 0.9825 - val_loss: 0.2054 - val_acc: 0.9524\n",
      "Epoch 51/800\n",
      "114/114 [==============================] - 0s 870us/sample - loss: 0.0666 - acc: 0.9825 - val_loss: 0.1920 - val_acc: 0.9524\n",
      "Epoch 52/800\n",
      "114/114 [==============================] - 0s 870us/sample - loss: 0.0621 - acc: 0.9912 - val_loss: 0.1887 - val_acc: 0.9524\n",
      "Epoch 53/800\n",
      "114/114 [==============================] - 0s 870us/sample - loss: 0.0691 - acc: 0.9825 - val_loss: 0.2103 - val_acc: 0.9524\n",
      "Epoch 54/800\n",
      "114/114 [==============================] - 0s 872us/sample - loss: 0.0601 - acc: 0.9825 - val_loss: 0.1882 - val_acc: 0.9524\n",
      "Epoch 55/800\n",
      "114/114 [==============================] - 0s 872us/sample - loss: 0.0608 - acc: 0.9825 - val_loss: 0.2020 - val_acc: 0.9524\n",
      "Epoch 56/800\n",
      "114/114 [==============================] - 0s 872us/sample - loss: 0.0555 - acc: 0.9825 - val_loss: 0.2032 - val_acc: 0.9524\n",
      "Epoch 57/800\n",
      "114/114 [==============================] - 0s 868us/sample - loss: 0.0559 - acc: 0.9825 - val_loss: 0.2075 - val_acc: 0.9524\n",
      "Epoch 58/800\n",
      "114/114 [==============================] - 0s 884us/sample - loss: 0.0558 - acc: 0.9825 - val_loss: 0.1993 - val_acc: 0.9524\n",
      "Epoch 59/800\n",
      "114/114 [==============================] - 0s 858us/sample - loss: 0.0604 - acc: 0.9825 - val_loss: 0.2231 - val_acc: 0.9524\n",
      "Epoch 60/800\n",
      "114/114 [==============================] - 0s 875us/sample - loss: 0.0604 - acc: 0.9825 - val_loss: 0.1981 - val_acc: 0.9524\n",
      "Epoch 61/800\n",
      "114/114 [==============================] - 0s 873us/sample - loss: 0.0499 - acc: 1.0000 - val_loss: 0.2206 - val_acc: 0.9524\n",
      "Epoch 62/800\n",
      "114/114 [==============================] - 0s 870us/sample - loss: 0.0499 - acc: 0.9825 - val_loss: 0.2293 - val_acc: 0.9524\n",
      "Epoch 63/800\n",
      "114/114 [==============================] - 0s 870us/sample - loss: 0.0504 - acc: 0.9825 - val_loss: 0.2079 - val_acc: 0.9524\n",
      "Epoch 64/800\n",
      "114/114 [==============================] - 0s 885us/sample - loss: 0.0496 - acc: 0.9912 - val_loss: 0.2098 - val_acc: 0.9524\n",
      "Epoch 65/800\n",
      "114/114 [==============================] - 0s 867us/sample - loss: 0.0456 - acc: 0.9825 - val_loss: 0.2342 - val_acc: 0.9524\n",
      "Epoch 66/800\n",
      "114/114 [==============================] - 0s 877us/sample - loss: 0.0479 - acc: 0.9825 - val_loss: 0.2216 - val_acc: 0.9524\n",
      "Epoch 67/800\n",
      "114/114 [==============================] - 0s 2ms/sample - loss: 0.0448 - acc: 0.9912 - val_loss: 0.2051 - val_acc: 0.9524\n",
      "Epoch 68/800\n",
      "114/114 [==============================] - 0s 875us/sample - loss: 0.0473 - acc: 1.0000 - val_loss: 0.2162 - val_acc: 0.9524\n",
      "Epoch 69/800\n",
      "114/114 [==============================] - 0s 112us/sample - loss: 0.0468 - acc: 0.9825 - val_loss: 0.2552 - val_acc: 0.9524\n",
      "Epoch 70/800\n",
      "114/114 [==============================] - 0s 879us/sample - loss: 0.0464 - acc: 0.9825 - val_loss: 0.2207 - val_acc: 0.9524\n",
      "Epoch 71/800\n",
      "114/114 [==============================] - 0s 923us/sample - loss: 0.0428 - acc: 0.9912 - val_loss: 0.2072 - val_acc: 0.9524\n",
      "Epoch 72/800\n",
      "114/114 [==============================] - 0s 834us/sample - loss: 0.0441 - acc: 1.0000 - val_loss: 0.2293 - val_acc: 0.9524\n",
      "Epoch 73/800\n",
      "114/114 [==============================] - 0s 891us/sample - loss: 0.0436 - acc: 0.9825 - val_loss: 0.2504 - val_acc: 0.9524\n",
      "Epoch 74/800\n",
      "114/114 [==============================] - 0s 889us/sample - loss: 0.0415 - acc: 0.9825 - val_loss: 0.2260 - val_acc: 0.9524\n",
      "Epoch 75/800\n",
      "114/114 [==============================] - 0s 872us/sample - loss: 0.0468 - acc: 1.0000 - val_loss: 0.2151 - val_acc: 0.9524\n",
      "Epoch 76/800\n",
      "114/114 [==============================] - 0s 895us/sample - loss: 0.0435 - acc: 0.9912 - val_loss: 0.2642 - val_acc: 0.9524\n",
      "Epoch 77/800\n",
      "114/114 [==============================] - 0s 857us/sample - loss: 0.0477 - acc: 0.9825 - val_loss: 0.2370 - val_acc: 0.9524\n",
      "Epoch 78/800\n",
      "114/114 [==============================] - 0s 872us/sample - loss: 0.0414 - acc: 0.9825 - val_loss: 0.2169 - val_acc: 0.9524\n",
      "Epoch 79/800\n",
      "114/114 [==============================] - 0s 882us/sample - loss: 0.0419 - acc: 1.0000 - val_loss: 0.2460 - val_acc: 0.9524\n",
      "Epoch 80/800\n",
      "114/114 [==============================] - 0s 890us/sample - loss: 0.0375 - acc: 0.9825 - val_loss: 0.2424 - val_acc: 0.9524\n",
      "Epoch 81/800\n",
      "114/114 [==============================] - 0s 865us/sample - loss: 0.0373 - acc: 0.9825 - val_loss: 0.2318 - val_acc: 0.9524\n",
      "Epoch 82/800\n",
      "114/114 [==============================] - 0s 877us/sample - loss: 0.0384 - acc: 0.9825 - val_loss: 0.2411 - val_acc: 0.9524\n",
      "Epoch 83/800\n",
      "114/114 [==============================] - 0s 870us/sample - loss: 0.0353 - acc: 0.9825 - val_loss: 0.2360 - val_acc: 0.9524\n",
      "Epoch 84/800\n",
      "114/114 [==============================] - 0s 873us/sample - loss: 0.0437 - acc: 0.9912 - val_loss: 0.2334 - val_acc: 0.9524\n",
      "Epoch 85/800\n",
      "114/114 [==============================] - 0s 868us/sample - loss: 0.0462 - acc: 0.9825 - val_loss: 0.2798 - val_acc: 0.9524\n",
      "Epoch 86/800\n",
      "114/114 [==============================] - 0s 868us/sample - loss: 0.0431 - acc: 0.9825 - val_loss: 0.2332 - val_acc: 0.9524\n",
      "Epoch 87/800\n",
      "114/114 [==============================] - 0s 872us/sample - loss: 0.0379 - acc: 1.0000 - val_loss: 0.2352 - val_acc: 0.9524\n",
      "Epoch 88/800\n",
      "114/114 [==============================] - 0s 874us/sample - loss: 0.0378 - acc: 0.9825 - val_loss: 0.2682 - val_acc: 0.9524\n",
      "Epoch 89/800\n",
      "114/114 [==============================] - 0s 873us/sample - loss: 0.0348 - acc: 0.9825 - val_loss: 0.2489 - val_acc: 0.9524\n",
      "Epoch 90/800\n",
      "114/114 [==============================] - 0s 870us/sample - loss: 0.0349 - acc: 0.9912 - val_loss: 0.2356 - val_acc: 0.9524\n",
      "Epoch 91/800\n",
      "114/114 [==============================] - 0s 874us/sample - loss: 0.0359 - acc: 0.9825 - val_loss: 0.2582 - val_acc: 0.9524\n",
      "Epoch 92/800\n",
      "114/114 [==============================] - 0s 872us/sample - loss: 0.0333 - acc: 0.9825 - val_loss: 0.2596 - val_acc: 0.9524\n",
      "Epoch 93/800\n",
      "114/114 [==============================] - 0s 870us/sample - loss: 0.0332 - acc: 0.9825 - val_loss: 0.2457 - val_acc: 0.9524\n",
      "Epoch 94/800\n",
      "114/114 [==============================] - 0s 875us/sample - loss: 0.0355 - acc: 1.0000 - val_loss: 0.2656 - val_acc: 0.9524\n",
      "Epoch 95/800\n",
      "114/114 [==============================] - 0s 869us/sample - loss: 0.0356 - acc: 0.9825 - val_loss: 0.2747 - val_acc: 0.9524\n",
      "Epoch 96/800\n",
      "114/114 [==============================] - 0s 875us/sample - loss: 0.0311 - acc: 0.9825 - val_loss: 0.2566 - val_acc: 0.9524\n",
      "Epoch 97/800\n",
      "114/114 [==============================] - 0s 868us/sample - loss: 0.0307 - acc: 0.9912 - val_loss: 0.2565 - val_acc: 0.9524\n",
      "Epoch 98/800\n",
      "114/114 [==============================] - 0s 875us/sample - loss: 0.0313 - acc: 0.9912 - val_loss: 0.2604 - val_acc: 0.9524\n",
      "Epoch 99/800\n",
      "114/114 [==============================] - 0s 868us/sample - loss: 0.0294 - acc: 0.9912 - val_loss: 0.2796 - val_acc: 0.9524\n",
      "Epoch 100/800\n",
      "114/114 [==============================] - 0s 871us/sample - loss: 0.0339 - acc: 0.9825 - val_loss: 0.2807 - val_acc: 0.9524\n",
      "Epoch 101/800\n",
      "114/114 [==============================] - 0s 885us/sample - loss: 0.0309 - acc: 0.9912 - val_loss: 0.2550 - val_acc: 0.9524\n",
      "Epoch 102/800\n",
      "114/114 [==============================] - 0s 863us/sample - loss: 0.0323 - acc: 0.9912 - val_loss: 0.2772 - val_acc: 0.9524\n",
      "Epoch 103/800\n",
      "114/114 [==============================] - 0s 882us/sample - loss: 0.0296 - acc: 0.9825 - val_loss: 0.2840 - val_acc: 0.9524\n",
      "Epoch 104/800\n",
      "114/114 [==============================] - 0s 897us/sample - loss: 0.0274 - acc: 0.9912 - val_loss: 0.2678 - val_acc: 0.9524\n",
      "Epoch 105/800\n",
      "114/114 [==============================] - 0s 888us/sample - loss: 0.0347 - acc: 1.0000 - val_loss: 0.2671 - val_acc: 0.9524\n",
      "Epoch 106/800\n",
      "114/114 [==============================] - 0s 848us/sample - loss: 0.0296 - acc: 0.9825 - val_loss: 0.3021 - val_acc: 0.9524\n",
      "Epoch 107/800\n",
      "114/114 [==============================] - 0s 885us/sample - loss: 0.0317 - acc: 0.9825 - val_loss: 0.2823 - val_acc: 0.9524\n",
      "Epoch 108/800\n",
      "114/114 [==============================] - 0s 883us/sample - loss: 0.0264 - acc: 1.0000 - val_loss: 0.2681 - val_acc: 0.9524\n",
      "Epoch 109/800\n",
      "114/114 [==============================] - 0s 888us/sample - loss: 0.0329 - acc: 0.9825 - val_loss: 0.2856 - val_acc: 0.9524\n",
      "Epoch 110/800\n",
      "114/114 [==============================] - 0s 864us/sample - loss: 0.0285 - acc: 0.9912 - val_loss: 0.2762 - val_acc: 0.9524\n",
      "Epoch 111/800\n",
      "114/114 [==============================] - 0s 873us/sample - loss: 0.0254 - acc: 1.0000 - val_loss: 0.2946 - val_acc: 0.9524\n",
      "Epoch 112/800\n",
      "114/114 [==============================] - 0s 872us/sample - loss: 0.0321 - acc: 0.9825 - val_loss: 0.3064 - val_acc: 0.9524\n",
      "Epoch 113/800\n",
      "114/114 [==============================] - 0s 878us/sample - loss: 0.0258 - acc: 0.9912 - val_loss: 0.2757 - val_acc: 0.9524\n",
      "Epoch 114/800\n",
      "114/114 [==============================] - 0s 883us/sample - loss: 0.0283 - acc: 1.0000 - val_loss: 0.2840 - val_acc: 0.9524\n",
      "Epoch 115/800\n",
      "114/114 [==============================] - 0s 882us/sample - loss: 0.0296 - acc: 1.0000 - val_loss: 0.2921 - val_acc: 0.9524\n",
      "Epoch 116/800\n",
      "114/114 [==============================] - 0s 862us/sample - loss: 0.0300 - acc: 0.9825 - val_loss: 0.3204 - val_acc: 0.9524\n",
      "Epoch 117/800\n",
      "114/114 [==============================] - 0s 887us/sample - loss: 0.0302 - acc: 0.9825 - val_loss: 0.2796 - val_acc: 0.9524\n",
      "Epoch 118/800\n",
      "114/114 [==============================] - 0s 872us/sample - loss: 0.0280 - acc: 1.0000 - val_loss: 0.2919 - val_acc: 0.9524\n",
      "Epoch 119/800\n",
      "114/114 [==============================] - 0s 879us/sample - loss: 0.0249 - acc: 0.9825 - val_loss: 0.3019 - val_acc: 0.9524\n",
      "Epoch 120/800\n",
      "114/114 [==============================] - 0s 863us/sample - loss: 0.0343 - acc: 0.9825 - val_loss: 0.2873 - val_acc: 0.9524\n",
      "Epoch 121/800\n",
      "114/114 [==============================] - 0s 879us/sample - loss: 0.0297 - acc: 0.9912 - val_loss: 0.3347 - val_acc: 0.9524\n",
      "Epoch 122/800\n",
      "114/114 [==============================] - 0s 865us/sample - loss: 0.0287 - acc: 0.9825 - val_loss: 0.2993 - val_acc: 0.9524\n",
      "Epoch 123/800\n",
      "114/114 [==============================] - 0s 871us/sample - loss: 0.0219 - acc: 1.0000 - val_loss: 0.2840 - val_acc: 0.9048\n",
      "Epoch 124/800\n",
      "114/114 [==============================] - 0s 873us/sample - loss: 0.0347 - acc: 0.9825 - val_loss: 0.3227 - val_acc: 0.9524\n",
      "Epoch 125/800\n",
      "114/114 [==============================] - 0s 891us/sample - loss: 0.0476 - acc: 0.9825 - val_loss: 0.3584 - val_acc: 0.9524\n",
      "Epoch 126/800\n",
      "114/114 [==============================] - 0s 2ms/sample - loss: 0.0426 - acc: 0.9825 - val_loss: 0.2909 - val_acc: 0.9524\n",
      "Epoch 127/800\n",
      "114/114 [==============================] - 0s 865us/sample - loss: 0.0243 - acc: 1.0000 - val_loss: 0.3080 - val_acc: 0.9524\n",
      "Epoch 128/800\n",
      "114/114 [==============================] - 0s 890us/sample - loss: 0.0210 - acc: 0.9912 - val_loss: 0.3278 - val_acc: 0.9524\n",
      "Epoch 129/800\n",
      "114/114 [==============================] - 0s 900us/sample - loss: 0.0253 - acc: 0.9825 - val_loss: 0.3079 - val_acc: 0.9524\n",
      "Epoch 130/800\n",
      "114/114 [==============================] - 0s 883us/sample - loss: 0.0215 - acc: 1.0000 - val_loss: 0.3032 - val_acc: 0.9524\n",
      "Epoch 131/800\n",
      "114/114 [==============================] - 0s 870us/sample - loss: 0.0215 - acc: 1.0000 - val_loss: 0.3157 - val_acc: 0.9524\n",
      "Epoch 132/800\n",
      "114/114 [==============================] - 0s 873us/sample - loss: 0.0213 - acc: 0.9825 - val_loss: 0.3114 - val_acc: 0.9524\n",
      "Epoch 133/800\n",
      "114/114 [==============================] - 0s 890us/sample - loss: 0.0204 - acc: 1.0000 - val_loss: 0.3055 - val_acc: 0.9524\n",
      "Epoch 134/800\n",
      "114/114 [==============================] - 0s 860us/sample - loss: 0.0280 - acc: 1.0000 - val_loss: 0.3036 - val_acc: 0.9524\n",
      "Epoch 135/800\n",
      "114/114 [==============================] - 0s 856us/sample - loss: 0.0216 - acc: 0.9912 - val_loss: 0.3376 - val_acc: 0.9524\n",
      "Epoch 136/800\n",
      "114/114 [==============================] - 0s 893us/sample - loss: 0.0268 - acc: 0.9825 - val_loss: 0.3194 - val_acc: 0.9524\n",
      "Epoch 137/800\n",
      "114/114 [==============================] - 0s 847us/sample - loss: 0.0199 - acc: 0.9912 - val_loss: 0.2977 - val_acc: 0.9048\n",
      "Epoch 138/800\n",
      "114/114 [==============================] - 0s 891us/sample - loss: 0.0267 - acc: 1.0000 - val_loss: 0.3191 - val_acc: 0.9524\n",
      "Epoch 139/800\n",
      "114/114 [==============================] - 0s 873us/sample - loss: 0.0387 - acc: 0.9825 - val_loss: 0.3454 - val_acc: 0.9524\n",
      "Epoch 140/800\n",
      "114/114 [==============================] - 0s 870us/sample - loss: 0.0274 - acc: 0.9912 - val_loss: 0.2995 - val_acc: 0.9048\n",
      "Epoch 141/800\n",
      "114/114 [==============================] - 0s 874us/sample - loss: 0.0287 - acc: 1.0000 - val_loss: 0.3221 - val_acc: 0.9524\n",
      "Epoch 142/800\n",
      "114/114 [==============================] - 0s 871us/sample - loss: 0.0187 - acc: 1.0000 - val_loss: 0.3373 - val_acc: 0.9524\n",
      "Epoch 143/800\n",
      "114/114 [==============================] - 0s 886us/sample - loss: 0.0302 - acc: 0.9825 - val_loss: 0.3319 - val_acc: 0.9524\n",
      "Epoch 144/800\n",
      "114/114 [==============================] - 0s 869us/sample - loss: 0.0265 - acc: 0.9912 - val_loss: 0.3024 - val_acc: 0.9048\n",
      "Epoch 145/800\n",
      "114/114 [==============================] - 0s 872us/sample - loss: 0.0276 - acc: 1.0000 - val_loss: 0.3277 - val_acc: 0.9524\n",
      "Epoch 146/800\n",
      "114/114 [==============================] - 0s 873us/sample - loss: 0.0223 - acc: 0.9825 - val_loss: 0.3275 - val_acc: 0.9524\n",
      "Epoch 147/800\n",
      "114/114 [==============================] - 0s 880us/sample - loss: 0.0183 - acc: 1.0000 - val_loss: 0.3171 - val_acc: 0.9524\n",
      "Epoch 148/800\n",
      "114/114 [==============================] - 0s 877us/sample - loss: 0.0186 - acc: 1.0000 - val_loss: 0.3178 - val_acc: 0.9524\n",
      "Epoch 149/800\n",
      "114/114 [==============================] - 0s 116us/sample - loss: 0.0199 - acc: 1.0000 - val_loss: 0.3235 - val_acc: 0.9524\n",
      "Epoch 150/800\n",
      "114/114 [==============================] - 0s 865us/sample - loss: 0.0179 - acc: 1.0000 - val_loss: 0.3309 - val_acc: 0.9524\n",
      "Epoch 151/800\n",
      "114/114 [==============================] - 0s 118us/sample - loss: 0.0184 - acc: 1.0000 - val_loss: 0.3221 - val_acc: 0.9524\n",
      "Epoch 152/800\n",
      "114/114 [==============================] - 0s 2ms/sample - loss: 0.0214 - acc: 1.0000 - val_loss: 0.3242 - val_acc: 0.9524\n",
      "Epoch 153/800\n",
      "114/114 [==============================] - 0s 892us/sample - loss: 0.0203 - acc: 0.9912 - val_loss: 0.3442 - val_acc: 0.9524\n",
      "Epoch 154/800\n",
      "114/114 [==============================] - 0s 855us/sample - loss: 0.0208 - acc: 0.9825 - val_loss: 0.3197 - val_acc: 0.9524\n",
      "Epoch 155/800\n",
      "114/114 [==============================] - 0s 912us/sample - loss: 0.0192 - acc: 1.0000 - val_loss: 0.3230 - val_acc: 0.9524\n",
      "Epoch 156/800\n",
      "114/114 [==============================] - 0s 864us/sample - loss: 0.0191 - acc: 0.9912 - val_loss: 0.3421 - val_acc: 0.9524\n",
      "Epoch 157/800\n",
      "114/114 [==============================] - 0s 870us/sample - loss: 0.0188 - acc: 0.9912 - val_loss: 0.3289 - val_acc: 0.9524\n",
      "Epoch 158/800\n",
      "114/114 [==============================] - 0s 872us/sample - loss: 0.0165 - acc: 1.0000 - val_loss: 0.3249 - val_acc: 0.9524\n",
      "Epoch 159/800\n",
      "114/114 [==============================] - 0s 895us/sample - loss: 0.0199 - acc: 1.0000 - val_loss: 0.3314 - val_acc: 0.9524\n",
      "Epoch 160/800\n",
      "114/114 [==============================] - 0s 865us/sample - loss: 0.0191 - acc: 0.9825 - val_loss: 0.3443 - val_acc: 0.9524\n",
      "Epoch 161/800\n",
      "114/114 [==============================] - 0s 896us/sample - loss: 0.0272 - acc: 0.9825 - val_loss: 0.3256 - val_acc: 0.9524\n",
      "Epoch 162/800\n",
      "114/114 [==============================] - 0s 869us/sample - loss: 0.0151 - acc: 1.0000 - val_loss: 0.3490 - val_acc: 0.9524\n",
      "Epoch 163/800\n",
      "114/114 [==============================] - 0s 882us/sample - loss: 0.0186 - acc: 0.9825 - val_loss: 0.3446 - val_acc: 0.9524\n",
      "Epoch 164/800\n",
      "114/114 [==============================] - 0s 860us/sample - loss: 0.0216 - acc: 1.0000 - val_loss: 0.3328 - val_acc: 0.9524\n",
      "Epoch 165/800\n",
      "114/114 [==============================] - 0s 869us/sample - loss: 0.0162 - acc: 1.0000 - val_loss: 0.3408 - val_acc: 0.9524\n",
      "Epoch 166/800\n",
      "114/114 [==============================] - 0s 872us/sample - loss: 0.0165 - acc: 1.0000 - val_loss: 0.3475 - val_acc: 0.9524\n",
      "Epoch 167/800\n",
      "114/114 [==============================] - 0s 874us/sample - loss: 0.0165 - acc: 0.9912 - val_loss: 0.3388 - val_acc: 0.9524\n",
      "Epoch 168/800\n",
      "114/114 [==============================] - 0s 871us/sample - loss: 0.0208 - acc: 1.0000 - val_loss: 0.3297 - val_acc: 0.9524\n",
      "Epoch 169/800\n",
      "114/114 [==============================] - 0s 871us/sample - loss: 0.0194 - acc: 1.0000 - val_loss: 0.3534 - val_acc: 0.9524\n",
      "Epoch 170/800\n",
      "114/114 [==============================] - 0s 890us/sample - loss: 0.0239 - acc: 0.9825 - val_loss: 0.3497 - val_acc: 0.9524\n",
      "Epoch 171/800\n",
      "114/114 [==============================] - 0s 858us/sample - loss: 0.0134 - acc: 1.0000 - val_loss: 0.3301 - val_acc: 0.9048\n",
      "Epoch 172/800\n",
      "114/114 [==============================] - 0s 873us/sample - loss: 0.0236 - acc: 1.0000 - val_loss: 0.3483 - val_acc: 0.9524\n",
      "Epoch 173/800\n",
      "114/114 [==============================] - 0s 951us/sample - loss: 0.0278 - acc: 0.9825 - val_loss: 0.3783 - val_acc: 0.9524\n",
      "Epoch 174/800\n",
      "114/114 [==============================] - 0s 808us/sample - loss: 0.0242 - acc: 0.9825 - val_loss: 0.3343 - val_acc: 0.9524\n",
      "Epoch 175/800\n",
      "114/114 [==============================] - 0s 2ms/sample - loss: 0.0214 - acc: 1.0000 - val_loss: 0.3398 - val_acc: 0.9524\n",
      "Epoch 176/800\n",
      "114/114 [==============================] - 0s 862us/sample - loss: 0.0126 - acc: 1.0000 - val_loss: 0.3740 - val_acc: 0.9524\n",
      "Epoch 177/800\n",
      "114/114 [==============================] - 0s 908us/sample - loss: 0.0229 - acc: 0.9825 - val_loss: 0.3561 - val_acc: 0.9524\n",
      "Epoch 178/800\n",
      "114/114 [==============================] - 0s 851us/sample - loss: 0.0167 - acc: 1.0000 - val_loss: 0.3436 - val_acc: 0.9524\n",
      "Epoch 179/800\n",
      "114/114 [==============================] - 0s 907us/sample - loss: 0.0145 - acc: 1.0000 - val_loss: 0.3503 - val_acc: 0.9524\n",
      "Epoch 180/800\n",
      "114/114 [==============================] - 0s 854us/sample - loss: 0.0148 - acc: 1.0000 - val_loss: 0.3499 - val_acc: 0.9524\n",
      "Epoch 181/800\n",
      "114/114 [==============================] - 0s 854us/sample - loss: 0.0160 - acc: 1.0000 - val_loss: 0.3521 - val_acc: 0.9524\n",
      "Epoch 182/800\n",
      "114/114 [==============================] - 0s 896us/sample - loss: 0.0201 - acc: 1.0000 - val_loss: 0.3482 - val_acc: 0.9524\n",
      "Epoch 183/800\n",
      "114/114 [==============================] - 0s 869us/sample - loss: 0.0155 - acc: 0.9912 - val_loss: 0.3766 - val_acc: 0.9524\n",
      "Epoch 184/800\n",
      "114/114 [==============================] - 0s 880us/sample - loss: 0.0230 - acc: 0.9825 - val_loss: 0.3620 - val_acc: 0.9524\n",
      "Epoch 185/800\n",
      "114/114 [==============================] - 0s 872us/sample - loss: 0.0211 - acc: 1.0000 - val_loss: 0.3438 - val_acc: 0.9048\n",
      "Epoch 186/800\n",
      "114/114 [==============================] - 0s 863us/sample - loss: 0.0280 - acc: 0.9825 - val_loss: 0.3596 - val_acc: 0.9524\n",
      "Epoch 187/800\n",
      "114/114 [==============================] - 0s 875us/sample - loss: 0.0286 - acc: 0.9825 - val_loss: 0.3983 - val_acc: 0.9524\n",
      "Epoch 188/800\n",
      "114/114 [==============================] - 0s 852us/sample - loss: 0.0222 - acc: 0.9825 - val_loss: 0.3538 - val_acc: 0.9524\n",
      "Epoch 189/800\n",
      "114/114 [==============================] - 0s 890us/sample - loss: 0.0218 - acc: 0.9912 - val_loss: 0.3458 - val_acc: 0.9524\n",
      "Epoch 190/800\n",
      "114/114 [==============================] - 0s 892us/sample - loss: 0.0240 - acc: 0.9912 - val_loss: 0.3945 - val_acc: 0.9524\n",
      "Epoch 191/800\n",
      "114/114 [==============================] - 0s 851us/sample - loss: 0.0256 - acc: 0.9825 - val_loss: 0.3641 - val_acc: 0.9524\n",
      "Epoch 192/800\n",
      "114/114 [==============================] - 0s 872us/sample - loss: 0.0113 - acc: 1.0000 - val_loss: 0.3497 - val_acc: 0.9524\n",
      "Epoch 193/800\n",
      "114/114 [==============================] - 0s 883us/sample - loss: 0.0165 - acc: 1.0000 - val_loss: 0.3519 - val_acc: 0.9524\n",
      "Epoch 194/800\n",
      "114/114 [==============================] - 0s 880us/sample - loss: 0.0153 - acc: 1.0000 - val_loss: 0.3716 - val_acc: 0.9524\n",
      "Epoch 195/800\n",
      "114/114 [==============================] - 0s 872us/sample - loss: 0.0170 - acc: 0.9825 - val_loss: 0.3658 - val_acc: 0.9524\n",
      "Epoch 196/800\n",
      "114/114 [==============================] - 0s 871us/sample - loss: 0.0151 - acc: 1.0000 - val_loss: 0.3518 - val_acc: 0.9524\n",
      "Epoch 197/800\n",
      "114/114 [==============================] - 0s 884us/sample - loss: 0.0151 - acc: 1.0000 - val_loss: 0.3603 - val_acc: 0.9524\n",
      "Epoch 198/800\n",
      "114/114 [==============================] - 0s 874us/sample - loss: 0.0153 - acc: 1.0000 - val_loss: 0.3722 - val_acc: 0.9524\n",
      "Epoch 199/800\n",
      "114/114 [==============================] - 0s 868us/sample - loss: 0.0182 - acc: 1.0000 - val_loss: 0.3551 - val_acc: 0.9524\n",
      "Epoch 200/800\n",
      "114/114 [==============================] - 0s 877us/sample - loss: 0.0139 - acc: 1.0000 - val_loss: 0.3661 - val_acc: 0.9524\n",
      "Epoch 201/800\n",
      "114/114 [==============================] - 0s 874us/sample - loss: 0.0153 - acc: 0.9912 - val_loss: 0.3851 - val_acc: 0.9524\n",
      "Epoch 202/800\n",
      "114/114 [==============================] - 0s 868us/sample - loss: 0.0176 - acc: 0.9912 - val_loss: 0.3599 - val_acc: 0.9524\n",
      "Epoch 203/800\n",
      "114/114 [==============================] - 0s 869us/sample - loss: 0.0135 - acc: 1.0000 - val_loss: 0.3618 - val_acc: 0.9524\n",
      "Epoch 204/800\n",
      "114/114 [==============================] - 0s 888us/sample - loss: 0.0123 - acc: 1.0000 - val_loss: 0.3677 - val_acc: 0.9524\n",
      "Epoch 205/800\n",
      "114/114 [==============================] - 0s 858us/sample - loss: 0.0137 - acc: 1.0000 - val_loss: 0.3707 - val_acc: 0.9524\n",
      "Epoch 206/800\n",
      "114/114 [==============================] - 0s 877us/sample - loss: 0.0122 - acc: 1.0000 - val_loss: 0.3670 - val_acc: 0.9524\n",
      "Epoch 207/800\n",
      "114/114 [==============================] - 0s 877us/sample - loss: 0.0119 - acc: 1.0000 - val_loss: 0.3669 - val_acc: 0.9524\n",
      "Epoch 208/800\n",
      "114/114 [==============================] - 0s 856us/sample - loss: 0.0130 - acc: 1.0000 - val_loss: 0.3747 - val_acc: 0.9524\n",
      "Epoch 209/800\n",
      "114/114 [==============================] - 0s 876us/sample - loss: 0.0126 - acc: 1.0000 - val_loss: 0.3701 - val_acc: 0.9524\n",
      "Epoch 210/800\n",
      "114/114 [==============================] - 0s 888us/sample - loss: 0.0155 - acc: 1.0000 - val_loss: 0.3703 - val_acc: 0.9524\n",
      "Epoch 211/800\n",
      "114/114 [==============================] - 0s 877us/sample - loss: 0.0146 - acc: 1.0000 - val_loss: 0.3828 - val_acc: 0.9524\n",
      "Epoch 212/800\n",
      "114/114 [==============================] - 0s 886us/sample - loss: 0.0125 - acc: 1.0000 - val_loss: 0.3711 - val_acc: 0.9524\n",
      "Epoch 213/800\n",
      "114/114 [==============================] - 0s 887us/sample - loss: 0.0114 - acc: 1.0000 - val_loss: 0.3671 - val_acc: 0.9524\n",
      "Epoch 214/800\n",
      "114/114 [==============================] - 0s 855us/sample - loss: 0.0141 - acc: 1.0000 - val_loss: 0.3803 - val_acc: 0.9524\n",
      "Epoch 215/800\n",
      "114/114 [==============================] - 0s 889us/sample - loss: 0.0170 - acc: 0.9825 - val_loss: 0.3885 - val_acc: 0.9524\n",
      "Epoch 216/800\n",
      "114/114 [==============================] - 0s 856us/sample - loss: 0.0128 - acc: 1.0000 - val_loss: 0.3737 - val_acc: 0.9524\n",
      "Epoch 217/800\n",
      "114/114 [==============================] - 0s 911us/sample - loss: 0.0118 - acc: 1.0000 - val_loss: 0.3751 - val_acc: 0.9524\n",
      "Epoch 218/800\n",
      "114/114 [==============================] - 0s 850us/sample - loss: 0.0123 - acc: 1.0000 - val_loss: 0.3819 - val_acc: 0.9524\n",
      "Epoch 219/800\n",
      "114/114 [==============================] - 0s 894us/sample - loss: 0.0130 - acc: 1.0000 - val_loss: 0.3835 - val_acc: 0.9524\n",
      "Epoch 220/800\n",
      "114/114 [==============================] - 0s 936us/sample - loss: 0.0104 - acc: 1.0000 - val_loss: 0.3761 - val_acc: 0.9524\n",
      "Epoch 221/800\n",
      "114/114 [==============================] - 0s 804us/sample - loss: 0.0115 - acc: 1.0000 - val_loss: 0.3788 - val_acc: 0.9524\n",
      "Epoch 222/800\n",
      "114/114 [==============================] - 0s 871us/sample - loss: 0.0111 - acc: 1.0000 - val_loss: 0.3864 - val_acc: 0.9524\n",
      "Epoch 223/800\n",
      "114/114 [==============================] - 0s 873us/sample - loss: 0.0134 - acc: 1.0000 - val_loss: 0.3832 - val_acc: 0.9524\n",
      "Epoch 224/800\n",
      "114/114 [==============================] - 0s 873us/sample - loss: 0.0109 - acc: 1.0000 - val_loss: 0.3766 - val_acc: 0.9524\n",
      "Epoch 225/800\n",
      "114/114 [==============================] - 0s 872us/sample - loss: 0.0132 - acc: 1.0000 - val_loss: 0.3845 - val_acc: 0.9524\n",
      "Epoch 226/800\n",
      "114/114 [==============================] - 0s 869us/sample - loss: 0.0121 - acc: 1.0000 - val_loss: 0.4046 - val_acc: 0.9524\n",
      "Epoch 227/800\n",
      "114/114 [==============================] - 0s 871us/sample - loss: 0.0158 - acc: 0.9825 - val_loss: 0.3844 - val_acc: 0.9524\n",
      "Epoch 228/800\n",
      "114/114 [==============================] - 0s 880us/sample - loss: 0.0098 - acc: 1.0000 - val_loss: 0.3823 - val_acc: 0.9524\n",
      "Epoch 229/800\n",
      "114/114 [==============================] - 0s 863us/sample - loss: 0.0107 - acc: 1.0000 - val_loss: 0.3875 - val_acc: 0.9524\n",
      "Epoch 230/800\n",
      "114/114 [==============================] - 0s 868us/sample - loss: 0.0119 - acc: 1.0000 - val_loss: 0.3897 - val_acc: 0.9524\n",
      "Epoch 231/800\n",
      "114/114 [==============================] - 0s 870us/sample - loss: 0.0113 - acc: 1.0000 - val_loss: 0.3882 - val_acc: 0.9524\n",
      "Epoch 232/800\n",
      "114/114 [==============================] - 0s 896us/sample - loss: 0.0130 - acc: 1.0000 - val_loss: 0.3835 - val_acc: 0.9524\n",
      "Epoch 233/800\n",
      "114/114 [==============================] - 0s 867us/sample - loss: 0.0123 - acc: 1.0000 - val_loss: 0.3980 - val_acc: 0.9524\n",
      "Epoch 234/800\n",
      "114/114 [==============================] - 0s 851us/sample - loss: 0.0116 - acc: 1.0000 - val_loss: 0.3906 - val_acc: 0.9524\n",
      "Epoch 235/800\n",
      "114/114 [==============================] - 0s 892us/sample - loss: 0.0096 - acc: 1.0000 - val_loss: 0.3933 - val_acc: 0.9524\n",
      "Epoch 236/800\n",
      "114/114 [==============================] - 0s 887us/sample - loss: 0.0103 - acc: 1.0000 - val_loss: 0.3928 - val_acc: 0.9524\n",
      "Epoch 237/800\n",
      "114/114 [==============================] - 0s 859us/sample - loss: 0.0095 - acc: 1.0000 - val_loss: 0.3968 - val_acc: 0.9524\n",
      "Epoch 238/800\n",
      "114/114 [==============================] - 0s 884us/sample - loss: 0.0103 - acc: 1.0000 - val_loss: 0.3952 - val_acc: 0.9524\n",
      "Epoch 239/800\n",
      "114/114 [==============================] - 0s 875us/sample - loss: 0.0113 - acc: 1.0000 - val_loss: 0.3907 - val_acc: 0.9524\n",
      "Epoch 240/800\n",
      "114/114 [==============================] - 0s 870us/sample - loss: 0.0094 - acc: 1.0000 - val_loss: 0.3997 - val_acc: 0.9524\n",
      "Epoch 241/800\n",
      "114/114 [==============================] - 0s 868us/sample - loss: 0.0114 - acc: 1.0000 - val_loss: 0.3990 - val_acc: 0.9524\n",
      "Epoch 242/800\n",
      "114/114 [==============================] - 0s 873us/sample - loss: 0.0089 - acc: 1.0000 - val_loss: 0.3953 - val_acc: 0.9524\n",
      "Epoch 243/800\n",
      "114/114 [==============================] - 0s 875us/sample - loss: 0.0112 - acc: 1.0000 - val_loss: 0.3951 - val_acc: 0.9524\n",
      "Epoch 244/800\n",
      "114/114 [==============================] - 0s 882us/sample - loss: 0.0081 - acc: 1.0000 - val_loss: 0.4112 - val_acc: 0.9524\n",
      "Epoch 245/800\n",
      "114/114 [==============================] - 0s 862us/sample - loss: 0.0123 - acc: 1.0000 - val_loss: 0.4094 - val_acc: 0.9524\n",
      "Epoch 246/800\n",
      "114/114 [==============================] - 0s 872us/sample - loss: 0.0204 - acc: 1.0000 - val_loss: 0.3953 - val_acc: 0.9524\n",
      "Epoch 247/800\n",
      "114/114 [==============================] - 0s 877us/sample - loss: 0.0117 - acc: 1.0000 - val_loss: 0.4313 - val_acc: 0.9524\n",
      "Epoch 248/800\n",
      "114/114 [==============================] - 0s 875us/sample - loss: 0.0277 - acc: 0.9825 - val_loss: 0.4165 - val_acc: 0.9524\n",
      "Epoch 249/800\n",
      "114/114 [==============================] - 0s 860us/sample - loss: 0.0128 - acc: 1.0000 - val_loss: 0.4041 - val_acc: 0.9048\n",
      "Epoch 250/800\n",
      "114/114 [==============================] - 0s 874us/sample - loss: 0.0207 - acc: 1.0000 - val_loss: 0.4070 - val_acc: 0.9524\n",
      "Epoch 251/800\n",
      "114/114 [==============================] - 0s 878us/sample - loss: 0.0272 - acc: 0.9825 - val_loss: 0.4390 - val_acc: 0.9524\n",
      "Epoch 252/800\n",
      "114/114 [==============================] - 0s 870us/sample - loss: 0.0281 - acc: 0.9825 - val_loss: 0.4067 - val_acc: 0.9048\n",
      "Epoch 253/800\n",
      "114/114 [==============================] - 0s 871us/sample - loss: 0.0295 - acc: 0.9912 - val_loss: 0.4081 - val_acc: 0.9524\n",
      "Epoch 254/800\n",
      "114/114 [==============================] - 0s 883us/sample - loss: 0.0129 - acc: 0.9912 - val_loss: 0.4489 - val_acc: 0.9524\n",
      "Epoch 255/800\n",
      "114/114 [==============================] - 0s 885us/sample - loss: 0.0259 - acc: 0.9825 - val_loss: 0.4148 - val_acc: 0.9524\n",
      "Epoch 256/800\n",
      "114/114 [==============================] - 0s 879us/sample - loss: 0.0078 - acc: 1.0000 - val_loss: 0.3990 - val_acc: 0.9048\n",
      "Epoch 257/800\n",
      "114/114 [==============================] - 0s 898us/sample - loss: 0.0233 - acc: 0.9912 - val_loss: 0.4110 - val_acc: 0.9524\n",
      "Epoch 258/800\n",
      "114/114 [==============================] - 0s 861us/sample - loss: 0.0239 - acc: 0.9825 - val_loss: 0.4379 - val_acc: 0.9524\n",
      "Epoch 259/800\n",
      "114/114 [==============================] - 0s 906us/sample - loss: 0.0172 - acc: 0.9912 - val_loss: 0.3989 - val_acc: 0.9048\n",
      "Epoch 260/800\n",
      "114/114 [==============================] - 0s 870us/sample - loss: 0.0251 - acc: 0.9912 - val_loss: 0.4050 - val_acc: 0.9524\n",
      "Epoch 261/800\n",
      "114/114 [==============================] - 0s 881us/sample - loss: 0.0075 - acc: 1.0000 - val_loss: 0.4282 - val_acc: 0.9524\n",
      "Epoch 262/800\n",
      "114/114 [==============================] - 0s 861us/sample - loss: 0.0145 - acc: 0.9912 - val_loss: 0.4128 - val_acc: 0.9524\n",
      "Epoch 263/800\n",
      "114/114 [==============================] - 0s 870us/sample - loss: 0.0075 - acc: 1.0000 - val_loss: 0.4012 - val_acc: 0.9048\n",
      "Epoch 264/800\n",
      "114/114 [==============================] - 0s 870us/sample - loss: 0.0131 - acc: 1.0000 - val_loss: 0.4036 - val_acc: 0.9524\n",
      "Epoch 265/800\n",
      "114/114 [==============================] - 0s 874us/sample - loss: 0.0073 - acc: 1.0000 - val_loss: 0.4159 - val_acc: 0.9524\n",
      "Epoch 266/800\n",
      "114/114 [==============================] - 0s 869us/sample - loss: 0.0135 - acc: 0.9912 - val_loss: 0.4104 - val_acc: 0.9524\n",
      "Epoch 267/800\n",
      "114/114 [==============================] - 0s 873us/sample - loss: 0.0076 - acc: 1.0000 - val_loss: 0.4043 - val_acc: 0.9524\n",
      "Epoch 268/800\n",
      "114/114 [==============================] - 0s 893us/sample - loss: 0.0088 - acc: 1.0000 - val_loss: 0.4059 - val_acc: 0.9524\n",
      "Epoch 269/800\n",
      "114/114 [==============================] - 0s 854us/sample - loss: 0.0075 - acc: 1.0000 - val_loss: 0.4133 - val_acc: 0.9524\n",
      "Epoch 270/800\n",
      "114/114 [==============================] - 0s 869us/sample - loss: 0.0092 - acc: 1.0000 - val_loss: 0.4141 - val_acc: 0.9524\n",
      "Epoch 271/800\n",
      "114/114 [==============================] - 0s 871us/sample - loss: 0.0104 - acc: 1.0000 - val_loss: 0.4053 - val_acc: 0.9524\n",
      "Epoch 272/800\n",
      "114/114 [==============================] - 0s 878us/sample - loss: 0.0100 - acc: 1.0000 - val_loss: 0.4140 - val_acc: 0.9524\n",
      "Epoch 273/800\n",
      "114/114 [==============================] - 0s 862us/sample - loss: 0.0077 - acc: 1.0000 - val_loss: 0.4180 - val_acc: 0.9524\n",
      "Epoch 274/800\n",
      "114/114 [==============================] - 0s 871us/sample - loss: 0.0089 - acc: 1.0000 - val_loss: 0.4123 - val_acc: 0.9524\n",
      "Epoch 275/800\n",
      "114/114 [==============================] - 0s 895us/sample - loss: 0.0074 - acc: 1.0000 - val_loss: 0.4106 - val_acc: 0.9524\n",
      "Epoch 276/800\n",
      "114/114 [==============================] - 0s 870us/sample - loss: 0.0082 - acc: 1.0000 - val_loss: 0.4157 - val_acc: 0.9524\n",
      "Epoch 277/800\n",
      "114/114 [==============================] - 0s 871us/sample - loss: 0.0078 - acc: 1.0000 - val_loss: 0.4156 - val_acc: 0.9524\n",
      "Epoch 278/800\n",
      "114/114 [==============================] - 0s 886us/sample - loss: 0.0072 - acc: 1.0000 - val_loss: 0.4129 - val_acc: 0.9524\n",
      "Epoch 279/800\n",
      "114/114 [==============================] - 0s 875us/sample - loss: 0.0088 - acc: 1.0000 - val_loss: 0.4149 - val_acc: 0.9524\n",
      "Epoch 280/800\n",
      "114/114 [==============================] - 0s 874us/sample - loss: 0.0061 - acc: 1.0000 - val_loss: 0.4255 - val_acc: 0.9524\n",
      "Epoch 281/800\n",
      "114/114 [==============================] - 0s 867us/sample - loss: 0.0114 - acc: 1.0000 - val_loss: 0.4218 - val_acc: 0.9524\n",
      "Epoch 282/800\n",
      "114/114 [==============================] - 0s 882us/sample - loss: 0.0077 - acc: 1.0000 - val_loss: 0.4137 - val_acc: 0.9524\n",
      "Epoch 283/800\n",
      "114/114 [==============================] - 0s 872us/sample - loss: 0.0087 - acc: 1.0000 - val_loss: 0.4188 - val_acc: 0.9524\n",
      "Epoch 284/800\n",
      "114/114 [==============================] - 0s 873us/sample - loss: 0.0068 - acc: 1.0000 - val_loss: 0.4234 - val_acc: 0.9524\n",
      "Epoch 285/800\n",
      "114/114 [==============================] - 0s 895us/sample - loss: 0.0080 - acc: 1.0000 - val_loss: 0.4247 - val_acc: 0.9524\n",
      "Epoch 286/800\n",
      "114/114 [==============================] - 0s 855us/sample - loss: 0.0119 - acc: 1.0000 - val_loss: 0.4172 - val_acc: 0.9524\n",
      "Epoch 287/800\n",
      "114/114 [==============================] - 0s 865us/sample - loss: 0.0063 - acc: 1.0000 - val_loss: 0.4302 - val_acc: 0.9524\n",
      "Epoch 288/800\n",
      "114/114 [==============================] - 0s 878us/sample - loss: 0.0129 - acc: 1.0000 - val_loss: 0.4341 - val_acc: 0.9524\n",
      "Epoch 289/800\n",
      "114/114 [==============================] - 0s 2ms/sample - loss: 0.0067 - acc: 1.0000 - val_loss: 0.4189 - val_acc: 0.9524\n",
      "Epoch 290/800\n",
      "114/114 [==============================] - 0s 874us/sample - loss: 0.0127 - acc: 1.0000 - val_loss: 0.4201 - val_acc: 0.9524\n",
      "Epoch 291/800\n",
      "114/114 [==============================] - 0s 926us/sample - loss: 0.0054 - acc: 1.0000 - val_loss: 0.4435 - val_acc: 0.9524\n",
      "Epoch 292/800\n",
      "114/114 [==============================] - 0s 873us/sample - loss: 0.0274 - acc: 0.9825 - val_loss: 0.4396 - val_acc: 0.9524\n",
      "Epoch 293/800\n",
      "114/114 [==============================] - 0s 872us/sample - loss: 0.0037 - acc: 1.0000 - val_loss: 0.4299 - val_acc: 0.9048\n",
      "Epoch 294/800\n",
      "114/114 [==============================] - 0s 873us/sample - loss: 0.0218 - acc: 0.9825 - val_loss: 0.4284 - val_acc: 0.9524\n",
      "Epoch 295/800\n",
      "114/114 [==============================] - 0s 884us/sample - loss: 0.0190 - acc: 0.9825 - val_loss: 0.4412 - val_acc: 0.9524\n",
      "Epoch 296/800\n",
      "114/114 [==============================] - 0s 861us/sample - loss: 0.0088 - acc: 1.0000 - val_loss: 0.4241 - val_acc: 0.9048\n",
      "Epoch 297/800\n",
      "114/114 [==============================] - 0s 872us/sample - loss: 0.0141 - acc: 1.0000 - val_loss: 0.4257 - val_acc: 0.9524\n",
      "Epoch 298/800\n",
      "114/114 [==============================] - 0s 882us/sample - loss: 0.0088 - acc: 1.0000 - val_loss: 0.4408 - val_acc: 0.9524\n",
      "Epoch 299/800\n",
      "114/114 [==============================] - 0s 874us/sample - loss: 0.0081 - acc: 1.0000 - val_loss: 0.4267 - val_acc: 0.9524\n",
      "Epoch 300/800\n",
      "114/114 [==============================] - 0s 877us/sample - loss: 0.0072 - acc: 1.0000 - val_loss: 0.4244 - val_acc: 0.9524\n",
      "Epoch 301/800\n",
      "114/114 [==============================] - 0s 872us/sample - loss: 0.0080 - acc: 1.0000 - val_loss: 0.4324 - val_acc: 0.9524\n",
      "Epoch 302/800\n",
      "114/114 [==============================] - 0s 879us/sample - loss: 0.0075 - acc: 1.0000 - val_loss: 0.4318 - val_acc: 0.9524\n",
      "Epoch 303/800\n",
      "114/114 [==============================] - 0s 877us/sample - loss: 0.0054 - acc: 1.0000 - val_loss: 0.4263 - val_acc: 0.9524\n",
      "Epoch 304/800\n",
      "114/114 [==============================] - 0s 872us/sample - loss: 0.0091 - acc: 1.0000 - val_loss: 0.4292 - val_acc: 0.9524\n",
      "Epoch 305/800\n",
      "114/114 [==============================] - 0s 871us/sample - loss: 0.0084 - acc: 1.0000 - val_loss: 0.4434 - val_acc: 0.9524\n",
      "Epoch 306/800\n",
      "114/114 [==============================] - 0s 867us/sample - loss: 0.0100 - acc: 1.0000 - val_loss: 0.4319 - val_acc: 0.9524\n",
      "Epoch 307/800\n",
      "114/114 [==============================] - 0s 880us/sample - loss: 0.0088 - acc: 1.0000 - val_loss: 0.4286 - val_acc: 0.9524\n",
      "Epoch 308/800\n",
      "114/114 [==============================] - 0s 865us/sample - loss: 0.0072 - acc: 1.0000 - val_loss: 0.4458 - val_acc: 0.9524\n",
      "Epoch 309/800\n",
      "114/114 [==============================] - 0s 869us/sample - loss: 0.0121 - acc: 1.0000 - val_loss: 0.4386 - val_acc: 0.9524\n",
      "Epoch 310/800\n",
      "114/114 [==============================] - 0s 870us/sample - loss: 0.0054 - acc: 1.0000 - val_loss: 0.4308 - val_acc: 0.9524\n",
      "Epoch 311/800\n",
      "114/114 [==============================] - 0s 883us/sample - loss: 0.0076 - acc: 1.0000 - val_loss: 0.4351 - val_acc: 0.9524\n",
      "Epoch 312/800\n",
      "114/114 [==============================] - 0s 860us/sample - loss: 0.0068 - acc: 1.0000 - val_loss: 0.4438 - val_acc: 0.9524\n",
      "Epoch 313/800\n",
      "114/114 [==============================] - 0s 888us/sample - loss: 0.0061 - acc: 1.0000 - val_loss: 0.4378 - val_acc: 0.9524\n",
      "Epoch 314/800\n",
      "114/114 [==============================] - 0s 870us/sample - loss: 0.0079 - acc: 1.0000 - val_loss: 0.4338 - val_acc: 0.9524\n",
      "Epoch 315/800\n",
      "114/114 [==============================] - 0s 2ms/sample - loss: 0.0075 - acc: 1.0000 - val_loss: 0.4445 - val_acc: 0.9524\n",
      "Epoch 316/800\n",
      "114/114 [==============================] - 0s 871us/sample - loss: 0.0076 - acc: 1.0000 - val_loss: 0.4410 - val_acc: 0.9524\n",
      "Epoch 317/800\n",
      "114/114 [==============================] - 0s 122us/sample - loss: 0.0060 - acc: 1.0000 - val_loss: 0.4361 - val_acc: 0.9524\n",
      "Epoch 318/800\n",
      "114/114 [==============================] - 0s 2ms/sample - loss: 0.0061 - acc: 1.0000 - val_loss: 0.4413 - val_acc: 0.9524\n",
      "Epoch 319/800\n",
      "114/114 [==============================] - 0s 852us/sample - loss: 0.0053 - acc: 1.0000 - val_loss: 0.4431 - val_acc: 0.9524\n",
      "Epoch 320/800\n",
      "114/114 [==============================] - 0s 866us/sample - loss: 0.0059 - acc: 1.0000 - val_loss: 0.4440 - val_acc: 0.9524\n",
      "Epoch 321/800\n",
      "114/114 [==============================] - 0s 906us/sample - loss: 0.0052 - acc: 1.0000 - val_loss: 0.4395 - val_acc: 0.9524\n",
      "Epoch 322/800\n",
      "114/114 [==============================] - 0s 878us/sample - loss: 0.0079 - acc: 1.0000 - val_loss: 0.4436 - val_acc: 0.9524\n",
      "Epoch 323/800\n",
      "114/114 [==============================] - 0s 856us/sample - loss: 0.0047 - acc: 1.0000 - val_loss: 0.4520 - val_acc: 0.9524\n",
      "Epoch 324/800\n",
      "114/114 [==============================] - 0s 872us/sample - loss: 0.0068 - acc: 1.0000 - val_loss: 0.4492 - val_acc: 0.9524\n",
      "Epoch 325/800\n",
      "114/114 [==============================] - 0s 867us/sample - loss: 0.0048 - acc: 1.0000 - val_loss: 0.4431 - val_acc: 0.9524\n",
      "Epoch 326/800\n",
      "114/114 [==============================] - 0s 893us/sample - loss: 0.0057 - acc: 1.0000 - val_loss: 0.4416 - val_acc: 0.9524\n",
      "Epoch 327/800\n",
      "114/114 [==============================] - 0s 848us/sample - loss: 0.0071 - acc: 1.0000 - val_loss: 0.4467 - val_acc: 0.9524\n",
      "Epoch 328/800\n",
      "114/114 [==============================] - 0s 872us/sample - loss: 0.0055 - acc: 1.0000 - val_loss: 0.4628 - val_acc: 0.9524\n",
      "Epoch 329/800\n",
      "114/114 [==============================] - 0s 889us/sample - loss: 0.0094 - acc: 1.0000 - val_loss: 0.4489 - val_acc: 0.9524\n",
      "Epoch 330/800\n",
      "114/114 [==============================] - 0s 871us/sample - loss: 0.0051 - acc: 1.0000 - val_loss: 0.4447 - val_acc: 0.9524\n",
      "Epoch 331/800\n",
      "114/114 [==============================] - 0s 875us/sample - loss: 0.0062 - acc: 1.0000 - val_loss: 0.4513 - val_acc: 0.9524\n",
      "Epoch 332/800\n",
      "114/114 [==============================] - 0s 881us/sample - loss: 0.0050 - acc: 1.0000 - val_loss: 0.4526 - val_acc: 0.9524\n",
      "Epoch 333/800\n",
      "114/114 [==============================] - 0s 872us/sample - loss: 0.0048 - acc: 1.0000 - val_loss: 0.4506 - val_acc: 0.9524\n",
      "Epoch 334/800\n",
      "114/114 [==============================] - 0s 873us/sample - loss: 0.0051 - acc: 1.0000 - val_loss: 0.4494 - val_acc: 0.9524\n",
      "Epoch 335/800\n",
      "114/114 [==============================] - 0s 875us/sample - loss: 0.0061 - acc: 1.0000 - val_loss: 0.4539 - val_acc: 0.9524\n",
      "Epoch 336/800\n",
      "114/114 [==============================] - 0s 863us/sample - loss: 0.0066 - acc: 1.0000 - val_loss: 0.4498 - val_acc: 0.9524\n",
      "Epoch 337/800\n",
      "114/114 [==============================] - 0s 867us/sample - loss: 0.0047 - acc: 1.0000 - val_loss: 0.4545 - val_acc: 0.9524\n",
      "Epoch 338/800\n",
      "114/114 [==============================] - 0s 885us/sample - loss: 0.0047 - acc: 1.0000 - val_loss: 0.4591 - val_acc: 0.9524\n",
      "Epoch 339/800\n",
      "114/114 [==============================] - 0s 861us/sample - loss: 0.0069 - acc: 1.0000 - val_loss: 0.4567 - val_acc: 0.9524\n",
      "Epoch 340/800\n",
      "114/114 [==============================] - 0s 872us/sample - loss: 0.0054 - acc: 1.0000 - val_loss: 0.4516 - val_acc: 0.9524\n",
      "Epoch 341/800\n",
      "114/114 [==============================] - 0s 872us/sample - loss: 0.0067 - acc: 1.0000 - val_loss: 0.4566 - val_acc: 0.9524\n",
      "Epoch 342/800\n",
      "114/114 [==============================] - 0s 873us/sample - loss: 0.0053 - acc: 1.0000 - val_loss: 0.4612 - val_acc: 0.9524\n",
      "Epoch 343/800\n",
      "114/114 [==============================] - 0s 880us/sample - loss: 0.0049 - acc: 1.0000 - val_loss: 0.4556 - val_acc: 0.9524\n",
      "Epoch 344/800\n",
      "114/114 [==============================] - 0s 874us/sample - loss: 0.0046 - acc: 1.0000 - val_loss: 0.4563 - val_acc: 0.9524\n",
      "Epoch 345/800\n",
      "114/114 [==============================] - 0s 855us/sample - loss: 0.0045 - acc: 1.0000 - val_loss: 0.4585 - val_acc: 0.9524\n",
      "Epoch 346/800\n",
      "114/114 [==============================] - 0s 114us/sample - loss: 0.0057 - acc: 1.0000 - val_loss: 0.4628 - val_acc: 0.9524\n",
      "Epoch 347/800\n",
      "114/114 [==============================] - 0s 862us/sample - loss: 0.0050 - acc: 1.0000 - val_loss: 0.4587 - val_acc: 0.9524\n",
      "Epoch 348/800\n",
      "114/114 [==============================] - 0s 880us/sample - loss: 0.0052 - acc: 1.0000 - val_loss: 0.4609 - val_acc: 0.9524\n",
      "Epoch 349/800\n",
      "114/114 [==============================] - 0s 2ms/sample - loss: 0.0041 - acc: 1.0000 - val_loss: 0.4651 - val_acc: 0.9524\n",
      "Epoch 350/800\n",
      "114/114 [==============================] - 0s 111us/sample - loss: 0.0048 - acc: 1.0000 - val_loss: 0.4635 - val_acc: 0.9524\n",
      "Epoch 351/800\n",
      "114/114 [==============================] - 0s 833us/sample - loss: 0.0042 - acc: 1.0000 - val_loss: 0.4606 - val_acc: 0.9524\n",
      "Epoch 352/800\n",
      "114/114 [==============================] - 0s 2ms/sample - loss: 0.0044 - acc: 1.0000 - val_loss: 0.4623 - val_acc: 0.9524\n",
      "Epoch 353/800\n",
      "114/114 [==============================] - 0s 882us/sample - loss: 0.0041 - acc: 1.0000 - val_loss: 0.4665 - val_acc: 0.9524\n",
      "Epoch 354/800\n",
      "114/114 [==============================] - 0s 857us/sample - loss: 0.0063 - acc: 1.0000 - val_loss: 0.4672 - val_acc: 0.9524\n",
      "Epoch 355/800\n",
      "114/114 [==============================] - 0s 874us/sample - loss: 0.0044 - acc: 1.0000 - val_loss: 0.4615 - val_acc: 0.9524\n",
      "Epoch 356/800\n",
      "114/114 [==============================] - 0s 891us/sample - loss: 0.0055 - acc: 1.0000 - val_loss: 0.4666 - val_acc: 0.9524\n",
      "Epoch 357/800\n",
      "114/114 [==============================] - 0s 901us/sample - loss: 0.0044 - acc: 1.0000 - val_loss: 0.4683 - val_acc: 0.9524\n",
      "Epoch 358/800\n",
      "114/114 [==============================] - 0s 850us/sample - loss: 0.0044 - acc: 1.0000 - val_loss: 0.4648 - val_acc: 0.9524\n",
      "Epoch 359/800\n",
      "114/114 [==============================] - 0s 893us/sample - loss: 0.0043 - acc: 1.0000 - val_loss: 0.4654 - val_acc: 0.9524\n",
      "Epoch 360/800\n",
      "114/114 [==============================] - 0s 873us/sample - loss: 0.0048 - acc: 1.0000 - val_loss: 0.4697 - val_acc: 0.9524\n",
      "Epoch 361/800\n",
      "114/114 [==============================] - 0s 870us/sample - loss: 0.0041 - acc: 1.0000 - val_loss: 0.4678 - val_acc: 0.9524\n",
      "Epoch 362/800\n",
      "114/114 [==============================] - 0s 872us/sample - loss: 0.0043 - acc: 1.0000 - val_loss: 0.4674 - val_acc: 0.9524\n",
      "Epoch 363/800\n",
      "114/114 [==============================] - 0s 869us/sample - loss: 0.0054 - acc: 1.0000 - val_loss: 0.4715 - val_acc: 0.9524\n",
      "Epoch 364/800\n",
      "114/114 [==============================] - 0s 875us/sample - loss: 0.0039 - acc: 1.0000 - val_loss: 0.4678 - val_acc: 0.9524\n",
      "Epoch 365/800\n",
      "114/114 [==============================] - 0s 889us/sample - loss: 0.0050 - acc: 1.0000 - val_loss: 0.4688 - val_acc: 0.9524\n",
      "Epoch 366/800\n",
      "114/114 [==============================] - 0s 850us/sample - loss: 0.0036 - acc: 1.0000 - val_loss: 0.4790 - val_acc: 0.9524\n",
      "Epoch 367/800\n",
      "114/114 [==============================] - 0s 895us/sample - loss: 0.0071 - acc: 1.0000 - val_loss: 0.4749 - val_acc: 0.9524\n",
      "Epoch 368/800\n",
      "114/114 [==============================] - 0s 857us/sample - loss: 0.0042 - acc: 1.0000 - val_loss: 0.4698 - val_acc: 0.9524\n",
      "Epoch 369/800\n",
      "114/114 [==============================] - 0s 882us/sample - loss: 0.0051 - acc: 1.0000 - val_loss: 0.4731 - val_acc: 0.9524\n",
      "Epoch 370/800\n",
      "114/114 [==============================] - 0s 888us/sample - loss: 0.0033 - acc: 1.0000 - val_loss: 0.4817 - val_acc: 0.9524\n",
      "Epoch 371/800\n",
      "114/114 [==============================] - 0s 856us/sample - loss: 0.0047 - acc: 1.0000 - val_loss: 0.4791 - val_acc: 0.9524\n",
      "Epoch 372/800\n",
      "114/114 [==============================] - 0s 897us/sample - loss: 0.0047 - acc: 1.0000 - val_loss: 0.4722 - val_acc: 0.9524\n",
      "Epoch 373/800\n",
      "114/114 [==============================] - 0s 872us/sample - loss: 0.0069 - acc: 1.0000 - val_loss: 0.4784 - val_acc: 0.9524\n",
      "Epoch 374/800\n",
      "114/114 [==============================] - 0s 877us/sample - loss: 0.0043 - acc: 1.0000 - val_loss: 0.4888 - val_acc: 0.9524\n",
      "Epoch 375/800\n",
      "114/114 [==============================] - 0s 897us/sample - loss: 0.0078 - acc: 1.0000 - val_loss: 0.4746 - val_acc: 0.9524\n",
      "Epoch 376/800\n",
      "114/114 [==============================] - 0s 2ms/sample - loss: 0.0048 - acc: 1.0000 - val_loss: 0.4758 - val_acc: 0.9524\n",
      "Epoch 377/800\n",
      "114/114 [==============================] - 0s 902us/sample - loss: 0.0029 - acc: 1.0000 - val_loss: 0.4887 - val_acc: 0.9524\n",
      "Epoch 378/800\n",
      "114/114 [==============================] - 0s 858us/sample - loss: 0.0062 - acc: 1.0000 - val_loss: 0.4813 - val_acc: 0.9524\n",
      "Epoch 379/800\n",
      "114/114 [==============================] - 0s 890us/sample - loss: 0.0033 - acc: 1.0000 - val_loss: 0.4773 - val_acc: 0.9524\n",
      "Epoch 380/800\n",
      "114/114 [==============================] - 0s 885us/sample - loss: 0.0035 - acc: 1.0000 - val_loss: 0.4779 - val_acc: 0.9524\n",
      "Epoch 381/800\n",
      "114/114 [==============================] - 0s 867us/sample - loss: 0.0034 - acc: 1.0000 - val_loss: 0.4808 - val_acc: 0.9524\n",
      "Epoch 382/800\n",
      "114/114 [==============================] - 0s 893us/sample - loss: 0.0038 - acc: 1.0000 - val_loss: 0.4835 - val_acc: 0.9524\n",
      "Epoch 383/800\n",
      "114/114 [==============================] - 0s 850us/sample - loss: 0.0037 - acc: 1.0000 - val_loss: 0.4795 - val_acc: 0.9524\n",
      "Epoch 384/800\n",
      "114/114 [==============================] - 0s 871us/sample - loss: 0.0036 - acc: 1.0000 - val_loss: 0.4820 - val_acc: 0.9524\n",
      "Epoch 385/800\n",
      "114/114 [==============================] - 0s 872us/sample - loss: 0.0039 - acc: 1.0000 - val_loss: 0.4857 - val_acc: 0.9524\n",
      "Epoch 386/800\n",
      "114/114 [==============================] - 0s 867us/sample - loss: 0.0035 - acc: 1.0000 - val_loss: 0.4814 - val_acc: 0.9524\n",
      "Epoch 387/800\n",
      "114/114 [==============================] - 0s 877us/sample - loss: 0.0040 - acc: 1.0000 - val_loss: 0.4831 - val_acc: 0.9524\n",
      "Epoch 388/800\n",
      "114/114 [==============================] - 0s 894us/sample - loss: 0.0037 - acc: 1.0000 - val_loss: 0.4934 - val_acc: 0.9524\n",
      "Epoch 389/800\n",
      "114/114 [==============================] - 0s 869us/sample - loss: 0.0059 - acc: 1.0000 - val_loss: 0.4854 - val_acc: 0.9524\n",
      "Epoch 390/800\n",
      "114/114 [==============================] - 0s 864us/sample - loss: 0.0047 - acc: 1.0000 - val_loss: 0.4832 - val_acc: 0.9524\n",
      "Epoch 391/800\n",
      "114/114 [==============================] - 0s 897us/sample - loss: 0.0034 - acc: 1.0000 - val_loss: 0.4885 - val_acc: 0.9524\n",
      "Epoch 392/800\n",
      "114/114 [==============================] - 0s 856us/sample - loss: 0.0036 - acc: 1.0000 - val_loss: 0.4930 - val_acc: 0.9524\n",
      "Epoch 393/800\n",
      "114/114 [==============================] - 0s 884us/sample - loss: 0.0036 - acc: 1.0000 - val_loss: 0.4863 - val_acc: 0.9524\n",
      "Epoch 394/800\n",
      "114/114 [==============================] - 0s 873us/sample - loss: 0.0032 - acc: 1.0000 - val_loss: 0.4862 - val_acc: 0.9524\n",
      "Epoch 395/800\n",
      "114/114 [==============================] - 0s 875us/sample - loss: 0.0035 - acc: 1.0000 - val_loss: 0.4918 - val_acc: 0.9524\n",
      "Epoch 396/800\n",
      "114/114 [==============================] - 0s 899us/sample - loss: 0.0033 - acc: 1.0000 - val_loss: 0.4899 - val_acc: 0.9524\n",
      "Epoch 397/800\n",
      "114/114 [==============================] - 0s 857us/sample - loss: 0.0031 - acc: 1.0000 - val_loss: 0.4897 - val_acc: 0.9524\n",
      "Epoch 398/800\n",
      "114/114 [==============================] - 0s 866us/sample - loss: 0.0038 - acc: 1.0000 - val_loss: 0.4898 - val_acc: 0.9524\n",
      "Epoch 399/800\n",
      "114/114 [==============================] - 0s 872us/sample - loss: 0.0027 - acc: 1.0000 - val_loss: 0.4965 - val_acc: 0.9524\n",
      "Epoch 400/800\n",
      "114/114 [==============================] - 0s 883us/sample - loss: 0.0036 - acc: 1.0000 - val_loss: 0.4944 - val_acc: 0.9524\n",
      "Epoch 401/800\n",
      "114/114 [==============================] - 0s 862us/sample - loss: 0.0029 - acc: 1.0000 - val_loss: 0.4907 - val_acc: 0.9524\n",
      "Epoch 402/800\n",
      "114/114 [==============================] - 0s 2ms/sample - loss: 0.0044 - acc: 1.0000 - val_loss: 0.4915 - val_acc: 0.9524\n",
      "Epoch 403/800\n",
      "114/114 [==============================] - 0s 856us/sample - loss: 0.0036 - acc: 1.0000 - val_loss: 0.5044 - val_acc: 0.9524\n",
      "Epoch 404/800\n",
      "114/114 [==============================] - 0s 910us/sample - loss: 0.0062 - acc: 1.0000 - val_loss: 0.4973 - val_acc: 0.9524\n",
      "Epoch 405/800\n",
      "114/114 [==============================] - 0s 878us/sample - loss: 0.0036 - acc: 1.0000 - val_loss: 0.4983 - val_acc: 0.9048\n",
      "Epoch 406/800\n",
      "114/114 [==============================] - 0s 871us/sample - loss: 0.0089 - acc: 1.0000 - val_loss: 0.5034 - val_acc: 0.9524\n",
      "Epoch 407/800\n",
      "114/114 [==============================] - 0s 867us/sample - loss: 0.0062 - acc: 1.0000 - val_loss: 0.5133 - val_acc: 0.9524\n",
      "Epoch 408/800\n",
      "114/114 [==============================] - 0s 868us/sample - loss: 0.0049 - acc: 1.0000 - val_loss: 0.4933 - val_acc: 0.9524\n",
      "Epoch 409/800\n",
      "114/114 [==============================] - 0s 870us/sample - loss: 0.0047 - acc: 1.0000 - val_loss: 0.4937 - val_acc: 0.9524\n",
      "Epoch 410/800\n",
      "114/114 [==============================] - 0s 901us/sample - loss: 0.0041 - acc: 1.0000 - val_loss: 0.5093 - val_acc: 0.9524\n",
      "Epoch 411/800\n",
      "114/114 [==============================] - 0s 874us/sample - loss: 0.0047 - acc: 1.0000 - val_loss: 0.5016 - val_acc: 0.9524\n",
      "Epoch 412/800\n",
      "114/114 [==============================] - 0s 891us/sample - loss: 0.0026 - acc: 1.0000 - val_loss: 0.4977 - val_acc: 0.9524\n",
      "Epoch 413/800\n",
      "114/114 [==============================] - 0s 859us/sample - loss: 0.0029 - acc: 1.0000 - val_loss: 0.4978 - val_acc: 0.9524\n",
      "Epoch 414/800\n",
      "114/114 [==============================] - 0s 873us/sample - loss: 0.0028 - acc: 1.0000 - val_loss: 0.5008 - val_acc: 0.9524\n",
      "Epoch 415/800\n",
      "114/114 [==============================] - 0s 884us/sample - loss: 0.0033 - acc: 1.0000 - val_loss: 0.5020 - val_acc: 0.9524\n",
      "Epoch 416/800\n",
      "114/114 [==============================] - 0s 2ms/sample - loss: 0.0030 - acc: 1.0000 - val_loss: 0.4981 - val_acc: 0.9524\n",
      "Epoch 417/800\n",
      "114/114 [==============================] - 0s 867us/sample - loss: 0.0030 - acc: 1.0000 - val_loss: 0.4999 - val_acc: 0.9524\n",
      "Epoch 418/800\n",
      "114/114 [==============================] - 0s 938us/sample - loss: 0.0024 - acc: 1.0000 - val_loss: 0.5052 - val_acc: 0.9524\n",
      "Epoch 419/800\n",
      "114/114 [==============================] - 0s 888us/sample - loss: 0.0029 - acc: 1.0000 - val_loss: 0.5056 - val_acc: 0.9524\n",
      "Epoch 420/800\n",
      "114/114 [==============================] - 0s 869us/sample - loss: 0.0027 - acc: 1.0000 - val_loss: 0.5037 - val_acc: 0.9524\n",
      "Epoch 421/800\n",
      "114/114 [==============================] - 0s 2ms/sample - loss: 0.0025 - acc: 1.0000 - val_loss: 0.5024 - val_acc: 0.9524\n",
      "Epoch 422/800\n",
      "114/114 [==============================] - 0s 849us/sample - loss: 0.0026 - acc: 1.0000 - val_loss: 0.5036 - val_acc: 0.9524\n",
      "Epoch 423/800\n",
      "114/114 [==============================] - 0s 893us/sample - loss: 0.0025 - acc: 1.0000 - val_loss: 0.5050 - val_acc: 0.9524\n",
      "Epoch 424/800\n",
      "114/114 [==============================] - 0s 893us/sample - loss: 0.0025 - acc: 1.0000 - val_loss: 0.5064 - val_acc: 0.9524\n",
      "Epoch 425/800\n",
      "114/114 [==============================] - 0s 886us/sample - loss: 0.0025 - acc: 1.0000 - val_loss: 0.5054 - val_acc: 0.9524\n",
      "Epoch 426/800\n",
      "114/114 [==============================] - 0s 879us/sample - loss: 0.0026 - acc: 1.0000 - val_loss: 0.5074 - val_acc: 0.9524\n",
      "Epoch 427/800\n",
      "114/114 [==============================] - 0s 864us/sample - loss: 0.0024 - acc: 1.0000 - val_loss: 0.5054 - val_acc: 0.9524\n",
      "Epoch 428/800\n",
      "114/114 [==============================] - 0s 871us/sample - loss: 0.0025 - acc: 1.0000 - val_loss: 0.5064 - val_acc: 0.9524\n",
      "Epoch 429/800\n",
      "114/114 [==============================] - 0s 880us/sample - loss: 0.0023 - acc: 1.0000 - val_loss: 0.5095 - val_acc: 0.9524\n",
      "Epoch 430/800\n",
      "114/114 [==============================] - 0s 860us/sample - loss: 0.0028 - acc: 1.0000 - val_loss: 0.5102 - val_acc: 0.9524\n",
      "Epoch 431/800\n",
      "114/114 [==============================] - 0s 894us/sample - loss: 0.0023 - acc: 1.0000 - val_loss: 0.5089 - val_acc: 0.9524\n",
      "Epoch 432/800\n",
      "114/114 [==============================] - 0s 848us/sample - loss: 0.0023 - acc: 1.0000 - val_loss: 0.5085 - val_acc: 0.9524\n",
      "Epoch 433/800\n",
      "114/114 [==============================] - 0s 872us/sample - loss: 0.0023 - acc: 1.0000 - val_loss: 0.5096 - val_acc: 0.9524\n",
      "Epoch 434/800\n",
      "114/114 [==============================] - 0s 895us/sample - loss: 0.0025 - acc: 1.0000 - val_loss: 0.5120 - val_acc: 0.9524\n",
      "Epoch 435/800\n",
      "114/114 [==============================] - 0s 873us/sample - loss: 0.0023 - acc: 1.0000 - val_loss: 0.5106 - val_acc: 0.9524\n",
      "Epoch 436/800\n",
      "114/114 [==============================] - 0s 873us/sample - loss: 0.0027 - acc: 1.0000 - val_loss: 0.5096 - val_acc: 0.9524\n",
      "Epoch 437/800\n",
      "114/114 [==============================] - 0s 882us/sample - loss: 0.0023 - acc: 1.0000 - val_loss: 0.5139 - val_acc: 0.9524\n",
      "Epoch 438/800\n",
      "114/114 [==============================] - 0s 882us/sample - loss: 0.0023 - acc: 1.0000 - val_loss: 0.5123 - val_acc: 0.9524\n",
      "Epoch 439/800\n",
      "114/114 [==============================] - 0s 866us/sample - loss: 0.0023 - acc: 1.0000 - val_loss: 0.5123 - val_acc: 0.9524\n",
      "Epoch 440/800\n",
      "114/114 [==============================] - 0s 868us/sample - loss: 0.0024 - acc: 1.0000 - val_loss: 0.5157 - val_acc: 0.9524\n",
      "Epoch 441/800\n",
      "114/114 [==============================] - 0s 872us/sample - loss: 0.0022 - acc: 1.0000 - val_loss: 0.5149 - val_acc: 0.9524\n",
      "Epoch 442/800\n",
      "114/114 [==============================] - 0s 878us/sample - loss: 0.0022 - acc: 1.0000 - val_loss: 0.5136 - val_acc: 0.9524\n",
      "Epoch 443/800\n",
      "114/114 [==============================] - 0s 865us/sample - loss: 0.0022 - acc: 1.0000 - val_loss: 0.5143 - val_acc: 0.9524\n",
      "Epoch 444/800\n",
      "114/114 [==============================] - 0s 869us/sample - loss: 0.0024 - acc: 1.0000 - val_loss: 0.5179 - val_acc: 0.9524\n",
      "Epoch 445/800\n",
      "114/114 [==============================] - 0s 878us/sample - loss: 0.0025 - acc: 1.0000 - val_loss: 0.5160 - val_acc: 0.9524\n",
      "Epoch 446/800\n",
      "114/114 [==============================] - 0s 119us/sample - loss: 0.0023 - acc: 1.0000 - val_loss: 0.5184 - val_acc: 0.9524\n",
      "Epoch 447/800\n",
      "114/114 [==============================] - 0s 2ms/sample - loss: 0.0021 - acc: 1.0000 - val_loss: 0.5178 - val_acc: 0.9524\n",
      "Epoch 448/800\n",
      "114/114 [==============================] - 0s 873us/sample - loss: 0.0021 - acc: 1.0000 - val_loss: 0.5167 - val_acc: 0.9524\n",
      "Epoch 449/800\n",
      "114/114 [==============================] - 0s 899us/sample - loss: 0.0021 - acc: 1.0000 - val_loss: 0.5176 - val_acc: 0.9524\n",
      "Epoch 450/800\n",
      "114/114 [==============================] - 0s 855us/sample - loss: 0.0022 - acc: 1.0000 - val_loss: 0.5191 - val_acc: 0.9524\n",
      "Epoch 451/800\n",
      "114/114 [==============================] - 0s 889us/sample - loss: 0.0025 - acc: 1.0000 - val_loss: 0.5240 - val_acc: 0.9524\n",
      "Epoch 452/800\n",
      "114/114 [==============================] - 0s 898us/sample - loss: 0.0022 - acc: 1.0000 - val_loss: 0.5193 - val_acc: 0.9524\n",
      "Epoch 453/800\n",
      "114/114 [==============================] - 0s 862us/sample - loss: 0.0021 - acc: 1.0000 - val_loss: 0.5186 - val_acc: 0.9524\n",
      "Epoch 454/800\n",
      "114/114 [==============================] - 0s 879us/sample - loss: 0.0024 - acc: 1.0000 - val_loss: 0.5202 - val_acc: 0.9524\n",
      "Epoch 455/800\n",
      "114/114 [==============================] - 0s 891us/sample - loss: 0.0025 - acc: 1.0000 - val_loss: 0.5270 - val_acc: 0.9524\n",
      "Epoch 456/800\n",
      "114/114 [==============================] - 0s 877us/sample - loss: 0.0026 - acc: 1.0000 - val_loss: 0.5236 - val_acc: 0.9524\n",
      "Epoch 457/800\n",
      "114/114 [==============================] - 0s 866us/sample - loss: 0.0036 - acc: 1.0000 - val_loss: 0.5194 - val_acc: 0.9524\n",
      "Epoch 458/800\n",
      "114/114 [==============================] - 0s 872us/sample - loss: 0.0023 - acc: 1.0000 - val_loss: 0.5283 - val_acc: 0.9524\n",
      "Epoch 459/800\n",
      "114/114 [==============================] - 0s 875us/sample - loss: 0.0025 - acc: 1.0000 - val_loss: 0.5319 - val_acc: 0.9524\n",
      "Epoch 460/800\n",
      "114/114 [==============================] - 0s 881us/sample - loss: 0.0025 - acc: 1.0000 - val_loss: 0.5247 - val_acc: 0.9524\n",
      "Epoch 461/800\n",
      "114/114 [==============================] - 0s 883us/sample - loss: 0.0018 - acc: 1.0000 - val_loss: 0.5219 - val_acc: 0.9524\n",
      "Epoch 462/800\n",
      "114/114 [==============================] - 0s 860us/sample - loss: 0.0024 - acc: 1.0000 - val_loss: 0.5238 - val_acc: 0.9524\n",
      "Epoch 463/800\n",
      "114/114 [==============================] - 0s 873us/sample - loss: 0.0020 - acc: 1.0000 - val_loss: 0.5285 - val_acc: 0.9524\n",
      "Epoch 464/800\n",
      "114/114 [==============================] - 0s 888us/sample - loss: 0.0019 - acc: 1.0000 - val_loss: 0.5267 - val_acc: 0.9524\n",
      "Epoch 465/800\n",
      "114/114 [==============================] - 0s 860us/sample - loss: 0.0018 - acc: 1.0000 - val_loss: 0.5264 - val_acc: 0.9524\n",
      "Epoch 466/800\n",
      "114/114 [==============================] - 0s 878us/sample - loss: 0.0019 - acc: 1.0000 - val_loss: 0.5268 - val_acc: 0.9524\n",
      "Epoch 467/800\n",
      "114/114 [==============================] - 0s 2ms/sample - loss: 0.0019 - acc: 1.0000 - val_loss: 0.5285 - val_acc: 0.9524\n",
      "Epoch 468/800\n",
      "114/114 [==============================] - 0s 888us/sample - loss: 0.0019 - acc: 1.0000 - val_loss: 0.5291 - val_acc: 0.9524\n",
      "Epoch 469/800\n",
      "114/114 [==============================] - 0s 884us/sample - loss: 0.0019 - acc: 1.0000 - val_loss: 0.5272 - val_acc: 0.9524\n",
      "Epoch 470/800\n",
      "114/114 [==============================] - 0s 884us/sample - loss: 0.0020 - acc: 1.0000 - val_loss: 0.5296 - val_acc: 0.9524\n",
      "Epoch 471/800\n",
      "114/114 [==============================] - 0s 851us/sample - loss: 0.0017 - acc: 1.0000 - val_loss: 0.5324 - val_acc: 0.9524\n",
      "Epoch 472/800\n",
      "114/114 [==============================] - 0s 889us/sample - loss: 0.0021 - acc: 1.0000 - val_loss: 0.5331 - val_acc: 0.9524\n",
      "Epoch 473/800\n",
      "114/114 [==============================] - 0s 902us/sample - loss: 0.0019 - acc: 1.0000 - val_loss: 0.5305 - val_acc: 0.9524\n",
      "Epoch 474/800\n",
      "114/114 [==============================] - 0s 871us/sample - loss: 0.0019 - acc: 1.0000 - val_loss: 0.5304 - val_acc: 0.9524\n",
      "Epoch 475/800\n",
      "114/114 [==============================] - 0s 863us/sample - loss: 0.0017 - acc: 1.0000 - val_loss: 0.5337 - val_acc: 0.9524\n",
      "Epoch 476/800\n",
      "114/114 [==============================] - 0s 891us/sample - loss: 0.0019 - acc: 1.0000 - val_loss: 0.5338 - val_acc: 0.9524\n",
      "Epoch 477/800\n",
      "114/114 [==============================] - 0s 861us/sample - loss: 0.0021 - acc: 1.0000 - val_loss: 0.5351 - val_acc: 0.9524\n",
      "Epoch 478/800\n",
      "114/114 [==============================] - 0s 902us/sample - loss: 0.0021 - acc: 1.0000 - val_loss: 0.5325 - val_acc: 0.9524\n",
      "Epoch 479/800\n",
      "114/114 [==============================] - 0s 860us/sample - loss: 0.0017 - acc: 1.0000 - val_loss: 0.5348 - val_acc: 0.9524\n",
      "Epoch 480/800\n",
      "114/114 [==============================] - 0s 866us/sample - loss: 0.0017 - acc: 1.0000 - val_loss: 0.5379 - val_acc: 0.9524\n",
      "Epoch 481/800\n",
      "114/114 [==============================] - 0s 884us/sample - loss: 0.0019 - acc: 1.0000 - val_loss: 0.5370 - val_acc: 0.9524\n",
      "Epoch 482/800\n",
      "114/114 [==============================] - 0s 882us/sample - loss: 0.0019 - acc: 1.0000 - val_loss: 0.5333 - val_acc: 0.9524\n",
      "Epoch 483/800\n",
      "114/114 [==============================] - 0s 856us/sample - loss: 0.0019 - acc: 1.0000 - val_loss: 0.5353 - val_acc: 0.9524\n",
      "Epoch 484/800\n",
      "114/114 [==============================] - 0s 870us/sample - loss: 0.0016 - acc: 1.0000 - val_loss: 0.5382 - val_acc: 0.9524\n",
      "Epoch 485/800\n",
      "114/114 [==============================] - 0s 884us/sample - loss: 0.0019 - acc: 1.0000 - val_loss: 0.5398 - val_acc: 0.9524\n",
      "Epoch 486/800\n",
      "114/114 [==============================] - 0s 857us/sample - loss: 0.0017 - acc: 1.0000 - val_loss: 0.5374 - val_acc: 0.9524\n",
      "Epoch 487/800\n",
      "114/114 [==============================] - 0s 875us/sample - loss: 0.0030 - acc: 1.0000 - val_loss: 0.5351 - val_acc: 0.9524\n",
      "Epoch 488/800\n",
      "114/114 [==============================] - 0s 878us/sample - loss: 0.0015 - acc: 1.0000 - val_loss: 0.5459 - val_acc: 0.9524\n",
      "Epoch 489/800\n",
      "114/114 [==============================] - 0s 866us/sample - loss: 0.0059 - acc: 1.0000 - val_loss: 0.5428 - val_acc: 0.9524\n",
      "Epoch 490/800\n",
      "114/114 [==============================] - 0s 871us/sample - loss: 0.0060 - acc: 1.0000 - val_loss: 0.5418 - val_acc: 0.9048\n",
      "Epoch 491/800\n",
      "114/114 [==============================] - 0s 882us/sample - loss: 0.0041 - acc: 1.0000 - val_loss: 0.5594 - val_acc: 0.9524\n",
      "Epoch 492/800\n",
      "114/114 [==============================] - 0s 861us/sample - loss: 0.0150 - acc: 0.9825 - val_loss: 0.5392 - val_acc: 0.9524\n",
      "Epoch 493/800\n",
      "114/114 [==============================] - 0s 875us/sample - loss: 0.0162 - acc: 0.9912 - val_loss: 0.5378 - val_acc: 0.9524\n",
      "Epoch 494/800\n",
      "114/114 [==============================] - 0s 872us/sample - loss: 0.0081 - acc: 1.0000 - val_loss: 0.5685 - val_acc: 0.9524\n",
      "Epoch 495/800\n",
      "114/114 [==============================] - 0s 867us/sample - loss: 0.0060 - acc: 1.0000 - val_loss: 0.5371 - val_acc: 0.9524\n",
      "Epoch 496/800\n",
      "114/114 [==============================] - 0s 872us/sample - loss: 0.0036 - acc: 1.0000 - val_loss: 0.5350 - val_acc: 0.9524\n",
      "Epoch 497/800\n",
      "114/114 [==============================] - 0s 871us/sample - loss: 0.0070 - acc: 1.0000 - val_loss: 0.5561 - val_acc: 0.9524\n",
      "Epoch 498/800\n",
      "114/114 [==============================] - 0s 873us/sample - loss: 0.0089 - acc: 0.9912 - val_loss: 0.5531 - val_acc: 0.9524\n",
      "Epoch 499/800\n",
      "114/114 [==============================] - 0s 871us/sample - loss: 9.1116e-04 - acc: 1.0000 - val_loss: 0.5432 - val_acc: 0.9048\n",
      "Epoch 500/800\n",
      "114/114 [==============================] - 0s 871us/sample - loss: 0.0084 - acc: 0.9912 - val_loss: 0.5446 - val_acc: 0.9524\n",
      "Epoch 501/800\n",
      "114/114 [==============================] - 0s 871us/sample - loss: 0.0015 - acc: 1.0000 - val_loss: 0.5598 - val_acc: 0.9524\n",
      "Epoch 502/800\n",
      "114/114 [==============================] - 0s 873us/sample - loss: 0.0057 - acc: 1.0000 - val_loss: 0.5410 - val_acc: 0.9524\n",
      "Epoch 503/800\n",
      "114/114 [==============================] - 0s 868us/sample - loss: 0.0015 - acc: 1.0000 - val_loss: 0.5443 - val_acc: 0.9048\n",
      "Epoch 504/800\n",
      "114/114 [==============================] - 0s 871us/sample - loss: 0.0039 - acc: 1.0000 - val_loss: 0.5406 - val_acc: 0.9524\n",
      "Epoch 505/800\n",
      "114/114 [==============================] - 0s 872us/sample - loss: 0.0039 - acc: 1.0000 - val_loss: 0.5491 - val_acc: 0.9524\n",
      "Epoch 506/800\n",
      "114/114 [==============================] - 0s 869us/sample - loss: 0.0022 - acc: 1.0000 - val_loss: 0.5402 - val_acc: 0.9524\n",
      "Epoch 507/800\n",
      "114/114 [==============================] - 0s 874us/sample - loss: 0.0025 - acc: 1.0000 - val_loss: 0.5403 - val_acc: 0.9524\n",
      "Epoch 508/800\n",
      "114/114 [==============================] - 0s 885us/sample - loss: 0.0017 - acc: 1.0000 - val_loss: 0.5441 - val_acc: 0.9524\n",
      "Epoch 509/800\n",
      "114/114 [==============================] - 0s 868us/sample - loss: 0.0015 - acc: 1.0000 - val_loss: 0.5526 - val_acc: 0.9524\n",
      "Epoch 510/800\n",
      "114/114 [==============================] - 0s 873us/sample - loss: 0.0022 - acc: 1.0000 - val_loss: 0.5501 - val_acc: 0.9524\n",
      "Epoch 511/800\n",
      "114/114 [==============================] - 0s 2ms/sample - loss: 0.0014 - acc: 1.0000 - val_loss: 0.5426 - val_acc: 0.9524\n",
      "Epoch 512/800\n",
      "114/114 [==============================] - 0s 891us/sample - loss: 0.0021 - acc: 1.0000 - val_loss: 0.5424 - val_acc: 0.9524\n",
      "Epoch 513/800\n",
      "114/114 [==============================] - 0s 853us/sample - loss: 0.0020 - acc: 1.0000 - val_loss: 0.5550 - val_acc: 0.9524\n",
      "Epoch 514/800\n",
      "114/114 [==============================] - 0s 887us/sample - loss: 0.0023 - acc: 1.0000 - val_loss: 0.5545 - val_acc: 0.9524\n",
      "Epoch 515/800\n",
      "114/114 [==============================] - 0s 911us/sample - loss: 0.0022 - acc: 1.0000 - val_loss: 0.5437 - val_acc: 0.9524\n",
      "Epoch 516/800\n",
      "114/114 [==============================] - 0s 877us/sample - loss: 0.0023 - acc: 1.0000 - val_loss: 0.5441 - val_acc: 0.9524\n",
      "Epoch 517/800\n",
      "114/114 [==============================] - 0s 862us/sample - loss: 0.0022 - acc: 1.0000 - val_loss: 0.5555 - val_acc: 0.9524\n",
      "Epoch 518/800\n",
      "114/114 [==============================] - 0s 851us/sample - loss: 0.0020 - acc: 1.0000 - val_loss: 0.5541 - val_acc: 0.9524\n",
      "Epoch 519/800\n",
      "114/114 [==============================] - ETA: 0s - loss: 5.1296e-05 - acc: 1.000 - 0s 894us/sample - loss: 0.0016 - acc: 1.0000 - val_loss: 0.5482 - val_acc: 0.9524\n",
      "Epoch 520/800\n",
      "114/114 [==============================] - 0s 876us/sample - loss: 0.0013 - acc: 1.0000 - val_loss: 0.5467 - val_acc: 0.9524\n",
      "Epoch 521/800\n",
      "114/114 [==============================] - 0s 863us/sample - loss: 0.0014 - acc: 1.0000 - val_loss: 0.5501 - val_acc: 0.9524\n",
      "Epoch 522/800\n",
      "114/114 [==============================] - 0s 871us/sample - loss: 0.0014 - acc: 1.0000 - val_loss: 0.5523 - val_acc: 0.9524\n",
      "Epoch 523/800\n",
      "114/114 [==============================] - 0s 901us/sample - loss: 0.0013 - acc: 1.0000 - val_loss: 0.5500 - val_acc: 0.9524\n",
      "Epoch 524/800\n",
      "114/114 [==============================] - 0s 841us/sample - loss: 0.0014 - acc: 1.0000 - val_loss: 0.5490 - val_acc: 0.9524\n",
      "Epoch 525/800\n",
      "114/114 [==============================] - 0s 881us/sample - loss: 0.0014 - acc: 1.0000 - val_loss: 0.5528 - val_acc: 0.9524\n",
      "Epoch 526/800\n",
      "114/114 [==============================] - 0s 888us/sample - loss: 0.0013 - acc: 1.0000 - val_loss: 0.5519 - val_acc: 0.9524\n",
      "Epoch 527/800\n",
      "114/114 [==============================] - 0s 883us/sample - loss: 0.0012 - acc: 1.0000 - val_loss: 0.5522 - val_acc: 0.9524\n",
      "Epoch 528/800\n",
      "114/114 [==============================] - 0s 870us/sample - loss: 0.0012 - acc: 1.0000 - val_loss: 0.5535 - val_acc: 0.9524\n",
      "Epoch 529/800\n",
      "114/114 [==============================] - 0s 871us/sample - loss: 0.0013 - acc: 1.0000 - val_loss: 0.5540 - val_acc: 0.9524\n",
      "Epoch 530/800\n",
      "114/114 [==============================] - 0s 873us/sample - loss: 0.0013 - acc: 1.0000 - val_loss: 0.5519 - val_acc: 0.9524\n",
      "Epoch 531/800\n",
      "114/114 [==============================] - 0s 874us/sample - loss: 0.0013 - acc: 1.0000 - val_loss: 0.5536 - val_acc: 0.9524\n",
      "Epoch 532/800\n",
      "114/114 [==============================] - 0s 883us/sample - loss: 0.0012 - acc: 1.0000 - val_loss: 0.5539 - val_acc: 0.9524\n",
      "Epoch 533/800\n",
      "114/114 [==============================] - 0s 864us/sample - loss: 0.0012 - acc: 1.0000 - val_loss: 0.5552 - val_acc: 0.9524\n",
      "Epoch 534/800\n",
      "114/114 [==============================] - 0s 907us/sample - loss: 0.0013 - acc: 1.0000 - val_loss: 0.5589 - val_acc: 0.9524\n",
      "Epoch 535/800\n",
      "114/114 [==============================] - 0s 125us/sample - loss: 0.0013 - acc: 1.0000 - val_loss: 0.5555 - val_acc: 0.9524\n",
      "Epoch 536/800\n",
      "114/114 [==============================] - 0s 907us/sample - loss: 0.0013 - acc: 1.0000 - val_loss: 0.5542 - val_acc: 0.9524\n",
      "Epoch 537/800\n",
      "114/114 [==============================] - 0s 868us/sample - loss: 0.0012 - acc: 1.0000 - val_loss: 0.5568 - val_acc: 0.9524\n",
      "Epoch 538/800\n",
      "114/114 [==============================] - 0s 911us/sample - loss: 0.0011 - acc: 1.0000 - val_loss: 0.5587 - val_acc: 0.9524\n",
      "Epoch 539/800\n",
      "114/114 [==============================] - 0s 878us/sample - loss: 0.0012 - acc: 1.0000 - val_loss: 0.5586 - val_acc: 0.9524\n",
      "Epoch 540/800\n",
      "114/114 [==============================] - 0s 873us/sample - loss: 0.0011 - acc: 1.0000 - val_loss: 0.5575 - val_acc: 0.9524\n",
      "Epoch 541/800\n",
      "114/114 [==============================] - 0s 866us/sample - loss: 0.0012 - acc: 1.0000 - val_loss: 0.5558 - val_acc: 0.9524\n",
      "Epoch 542/800\n",
      "114/114 [==============================] - 0s 869us/sample - loss: 0.0012 - acc: 1.0000 - val_loss: 0.5573 - val_acc: 0.9524\n",
      "Epoch 543/800\n",
      "114/114 [==============================] - 0s 896us/sample - loss: 0.0014 - acc: 1.0000 - val_loss: 0.5626 - val_acc: 0.9524\n",
      "Epoch 544/800\n",
      "114/114 [==============================] - 0s 863us/sample - loss: 0.0013 - acc: 1.0000 - val_loss: 0.5612 - val_acc: 0.9524\n",
      "Epoch 545/800\n",
      "114/114 [==============================] - 0s 879us/sample - loss: 0.0010 - acc: 1.0000 - val_loss: 0.5577 - val_acc: 0.9524\n",
      "Epoch 546/800\n",
      "114/114 [==============================] - 0s 881us/sample - loss: 0.0012 - acc: 1.0000 - val_loss: 0.5579 - val_acc: 0.9524\n",
      "Epoch 547/800\n",
      "114/114 [==============================] - 0s 880us/sample - loss: 0.0012 - acc: 1.0000 - val_loss: 0.5603 - val_acc: 0.9524\n",
      "Epoch 548/800\n",
      "114/114 [==============================] - 0s 862us/sample - loss: 0.0011 - acc: 1.0000 - val_loss: 0.5631 - val_acc: 0.9524\n",
      "Epoch 549/800\n",
      "114/114 [==============================] - 0s 867us/sample - loss: 0.0014 - acc: 1.0000 - val_loss: 0.5634 - val_acc: 0.9524\n",
      "Epoch 550/800\n",
      "114/114 [==============================] - 0s 871us/sample - loss: 0.0012 - acc: 1.0000 - val_loss: 0.5591 - val_acc: 0.9524\n",
      "Epoch 551/800\n",
      "114/114 [==============================] - 0s 870us/sample - loss: 0.0013 - acc: 1.0000 - val_loss: 0.5595 - val_acc: 0.9524\n",
      "Epoch 552/800\n",
      "114/114 [==============================] - 0s 876us/sample - loss: 0.0012 - acc: 1.0000 - val_loss: 0.5633 - val_acc: 0.9524\n",
      "Epoch 553/800\n",
      "114/114 [==============================] - 0s 883us/sample - loss: 0.0010 - acc: 1.0000 - val_loss: 0.5644 - val_acc: 0.9524\n",
      "Epoch 554/800\n",
      "114/114 [==============================] - 0s 863us/sample - loss: 0.0011 - acc: 1.0000 - val_loss: 0.5650 - val_acc: 0.9524\n",
      "Epoch 555/800\n",
      "114/114 [==============================] - 0s 884us/sample - loss: 0.0011 - acc: 1.0000 - val_loss: 0.5633 - val_acc: 0.9524\n",
      "Epoch 556/800\n",
      "114/114 [==============================] - 0s 881us/sample - loss: 0.0010 - acc: 1.0000 - val_loss: 0.5633 - val_acc: 0.9524\n",
      "Epoch 557/800\n",
      "114/114 [==============================] - 0s 2ms/sample - loss: 0.0012 - acc: 1.0000 - val_loss: 0.5657 - val_acc: 0.9524\n",
      "Epoch 558/800\n",
      "114/114 [==============================] - 0s 897us/sample - loss: 0.0010 - acc: 1.0000 - val_loss: 0.5648 - val_acc: 0.9524\n",
      "Epoch 559/800\n",
      "114/114 [==============================] - 0s 898us/sample - loss: 0.0010 - acc: 1.0000 - val_loss: 0.5649 - val_acc: 0.9524\n",
      "Epoch 560/800\n",
      "114/114 [==============================] - 0s 872us/sample - loss: 9.9752e-04 - acc: 1.0000 - val_loss: 0.5654 - val_acc: 0.9524\n",
      "Epoch 561/800\n",
      "114/114 [==============================] - 0s 876us/sample - loss: 0.0010 - acc: 1.0000 - val_loss: 0.5666 - val_acc: 0.9524\n",
      "Epoch 562/800\n",
      "114/114 [==============================] - 0s 857us/sample - loss: 0.0011 - acc: 1.0000 - val_loss: 0.5659 - val_acc: 0.9524\n",
      "Epoch 563/800\n",
      "114/114 [==============================] - 0s 881us/sample - loss: 0.0011 - acc: 1.0000 - val_loss: 0.5689 - val_acc: 0.9524\n",
      "Epoch 564/800\n",
      "114/114 [==============================] - 0s 872us/sample - loss: 0.0010 - acc: 1.0000 - val_loss: 0.5673 - val_acc: 0.9524\n",
      "Epoch 565/800\n",
      "114/114 [==============================] - 0s 898us/sample - loss: 9.7472e-04 - acc: 1.0000 - val_loss: 0.5670 - val_acc: 0.9524\n",
      "Epoch 566/800\n",
      "114/114 [==============================] - 0s 866us/sample - loss: 0.0010 - acc: 1.0000 - val_loss: 0.5679 - val_acc: 0.9524\n",
      "Epoch 567/800\n",
      "114/114 [==============================] - 0s 867us/sample - loss: 9.9042e-04 - acc: 1.0000 - val_loss: 0.5699 - val_acc: 0.9524\n",
      "Epoch 568/800\n",
      "114/114 [==============================] - 0s 882us/sample - loss: 0.0011 - acc: 1.0000 - val_loss: 0.5688 - val_acc: 0.9524\n",
      "Epoch 569/800\n",
      "114/114 [==============================] - 0s 872us/sample - loss: 0.0011 - acc: 1.0000 - val_loss: 0.5715 - val_acc: 0.9524\n",
      "Epoch 570/800\n",
      "114/114 [==============================] - 0s 871us/sample - loss: 0.0010 - acc: 1.0000 - val_loss: 0.5693 - val_acc: 0.9524\n",
      "Epoch 571/800\n",
      "114/114 [==============================] - 0s 871us/sample - loss: 0.0012 - acc: 1.0000 - val_loss: 0.5677 - val_acc: 0.9524\n",
      "Epoch 572/800\n",
      "114/114 [==============================] - 0s 870us/sample - loss: 9.8184e-04 - acc: 1.0000 - val_loss: 0.5714 - val_acc: 0.9524\n",
      "Epoch 573/800\n",
      "114/114 [==============================] - 0s 873us/sample - loss: 0.0010 - acc: 1.0000 - val_loss: 0.5745 - val_acc: 0.9524\n",
      "Epoch 574/800\n",
      "114/114 [==============================] - 0s 873us/sample - loss: 0.0011 - acc: 1.0000 - val_loss: 0.5704 - val_acc: 0.9524\n",
      "Epoch 575/800\n",
      "114/114 [==============================] - 0s 873us/sample - loss: 9.5061e-04 - acc: 1.0000 - val_loss: 0.5701 - val_acc: 0.9524\n",
      "Epoch 576/800\n",
      "114/114 [==============================] - 0s 888us/sample - loss: 9.5926e-04 - acc: 1.0000 - val_loss: 0.5718 - val_acc: 0.9524\n",
      "Epoch 577/800\n",
      "114/114 [==============================] - 0s 866us/sample - loss: 9.1254e-04 - acc: 1.0000 - val_loss: 0.5735 - val_acc: 0.9524\n",
      "Epoch 578/800\n",
      "114/114 [==============================] - 0s 894us/sample - loss: 9.0978e-04 - acc: 1.0000 - val_loss: 0.5748 - val_acc: 0.9524\n",
      "Epoch 579/800\n",
      "114/114 [==============================] - 0s 875us/sample - loss: 9.4135e-04 - acc: 1.0000 - val_loss: 0.5749 - val_acc: 0.9524\n",
      "Epoch 580/800\n",
      "114/114 [==============================] - 0s 892us/sample - loss: 9.4444e-04 - acc: 1.0000 - val_loss: 0.5736 - val_acc: 0.9524\n",
      "Epoch 581/800\n",
      "114/114 [==============================] - 0s 854us/sample - loss: 0.0010 - acc: 1.0000 - val_loss: 0.5730 - val_acc: 0.9524\n",
      "Epoch 582/800\n",
      "114/114 [==============================] - 0s 892us/sample - loss: 9.2033e-04 - acc: 1.0000 - val_loss: 0.5755 - val_acc: 0.9524\n",
      "Epoch 583/800\n",
      "114/114 [==============================] - 0s 894us/sample - loss: 8.9583e-04 - acc: 1.0000 - val_loss: 0.5759 - val_acc: 0.9524\n",
      "Epoch 584/800\n",
      "114/114 [==============================] - 0s 864us/sample - loss: 9.7760e-04 - acc: 1.0000 - val_loss: 0.5765 - val_acc: 0.9524\n",
      "Epoch 585/800\n",
      "114/114 [==============================] - 0s 876us/sample - loss: 9.2946e-04 - acc: 1.0000 - val_loss: 0.5742 - val_acc: 0.9524\n",
      "Epoch 586/800\n",
      "114/114 [==============================] - 0s 895us/sample - loss: 9.6099e-04 - acc: 1.0000 - val_loss: 0.5744 - val_acc: 0.9524\n",
      "Epoch 587/800\n",
      "114/114 [==============================] - 0s 843us/sample - loss: 0.0011 - acc: 1.0000 - val_loss: 0.5784 - val_acc: 0.9524\n",
      "Epoch 588/800\n",
      "114/114 [==============================] - 0s 897us/sample - loss: 9.3504e-04 - acc: 1.0000 - val_loss: 0.5758 - val_acc: 0.9524\n",
      "Epoch 589/800\n",
      "114/114 [==============================] - 0s 863us/sample - loss: 8.5952e-04 - acc: 1.0000 - val_loss: 0.5763 - val_acc: 0.9524\n",
      "Epoch 590/800\n",
      "114/114 [==============================] - 0s 888us/sample - loss: 8.7511e-04 - acc: 1.0000 - val_loss: 0.5772 - val_acc: 0.9524\n",
      "Epoch 591/800\n",
      "114/114 [==============================] - 0s 872us/sample - loss: 8.3769e-04 - acc: 1.0000 - val_loss: 0.5794 - val_acc: 0.9524\n",
      "Epoch 592/800\n",
      "114/114 [==============================] - 0s 871us/sample - loss: 8.4579e-04 - acc: 1.0000 - val_loss: 0.5800 - val_acc: 0.9524\n",
      "Epoch 593/800\n",
      "114/114 [==============================] - 0s 867us/sample - loss: 8.3176e-04 - acc: 1.0000 - val_loss: 0.5802 - val_acc: 0.9524\n",
      "Epoch 594/800\n",
      "114/114 [==============================] - 0s 886us/sample - loss: 8.6702e-04 - acc: 1.0000 - val_loss: 0.5793 - val_acc: 0.9524\n",
      "Epoch 595/800\n",
      "114/114 [==============================] - 0s 879us/sample - loss: 8.1264e-04 - acc: 1.0000 - val_loss: 0.5804 - val_acc: 0.9524\n",
      "Epoch 596/800\n",
      "114/114 [==============================] - 0s 868us/sample - loss: 8.2447e-04 - acc: 1.0000 - val_loss: 0.5812 - val_acc: 0.9524\n",
      "Epoch 597/800\n",
      "114/114 [==============================] - 0s 861us/sample - loss: 8.2635e-04 - acc: 1.0000 - val_loss: 0.5805 - val_acc: 0.9524\n",
      "Epoch 598/800\n",
      "114/114 [==============================] - 0s 2ms/sample - loss: 8.3363e-04 - acc: 1.0000 - val_loss: 0.5807 - val_acc: 0.9524\n",
      "Epoch 599/800\n",
      "114/114 [==============================] - 0s 893us/sample - loss: 8.3409e-04 - acc: 1.0000 - val_loss: 0.5826 - val_acc: 0.9524\n",
      "Epoch 600/800\n",
      "114/114 [==============================] - 0s 889us/sample - loss: 8.2076e-04 - acc: 1.0000 - val_loss: 0.5820 - val_acc: 0.9524\n",
      "Epoch 601/800\n",
      "114/114 [==============================] - 0s 853us/sample - loss: 8.4766e-04 - acc: 1.0000 - val_loss: 0.5827 - val_acc: 0.9524\n",
      "Epoch 602/800\n",
      "114/114 [==============================] - 0s 904us/sample - loss: 8.3019e-04 - acc: 1.0000 - val_loss: 0.5824 - val_acc: 0.9524\n",
      "Epoch 603/800\n",
      "114/114 [==============================] - 0s 872us/sample - loss: 7.9546e-04 - acc: 1.0000 - val_loss: 0.5829 - val_acc: 0.9524\n",
      "Epoch 604/800\n",
      "114/114 [==============================] - 0s 881us/sample - loss: 8.1889e-04 - acc: 1.0000 - val_loss: 0.5826 - val_acc: 0.9524\n",
      "Epoch 605/800\n",
      "114/114 [==============================] - 0s 861us/sample - loss: 8.7064e-04 - acc: 1.0000 - val_loss: 0.5853 - val_acc: 0.9524\n",
      "Epoch 606/800\n",
      "114/114 [==============================] - 0s 889us/sample - loss: 7.9655e-04 - acc: 1.0000 - val_loss: 0.5848 - val_acc: 0.9524\n",
      "Epoch 607/800\n",
      "114/114 [==============================] - 0s 850us/sample - loss: 7.7464e-04 - acc: 1.0000 - val_loss: 0.5852 - val_acc: 0.9524\n",
      "Epoch 608/800\n",
      "114/114 [==============================] - 0s 873us/sample - loss: 7.9265e-04 - acc: 1.0000 - val_loss: 0.5844 - val_acc: 0.9524\n",
      "Epoch 609/800\n",
      "114/114 [==============================] - 0s 906us/sample - loss: 7.6079e-04 - acc: 1.0000 - val_loss: 0.5851 - val_acc: 0.9524\n",
      "Epoch 610/800\n",
      "114/114 [==============================] - 0s 865us/sample - loss: 8.2734e-04 - acc: 1.0000 - val_loss: 0.5851 - val_acc: 0.9524\n",
      "Epoch 611/800\n",
      "114/114 [==============================] - 0s 878us/sample - loss: 7.3900e-04 - acc: 1.0000 - val_loss: 0.5879 - val_acc: 0.9524\n",
      "Epoch 612/800\n",
      "114/114 [==============================] - 0s 876us/sample - loss: 8.0116e-04 - acc: 1.0000 - val_loss: 0.5889 - val_acc: 0.9524\n",
      "Epoch 613/800\n",
      "114/114 [==============================] - 0s 884us/sample - loss: 8.4121e-04 - acc: 1.0000 - val_loss: 0.5860 - val_acc: 0.9524\n",
      "Epoch 614/800\n",
      "114/114 [==============================] - 0s 874us/sample - loss: 7.4823e-04 - acc: 1.0000 - val_loss: 0.5866 - val_acc: 0.9524\n",
      "Epoch 615/800\n",
      "114/114 [==============================] - 0s 116us/sample - loss: 7.3196e-04 - acc: 1.0000 - val_loss: 0.5871 - val_acc: 0.9524\n",
      "Epoch 616/800\n",
      "114/114 [==============================] - 0s 2ms/sample - loss: 7.3472e-04 - acc: 1.0000 - val_loss: 0.5875 - val_acc: 0.9524\n",
      "Epoch 617/800\n",
      "114/114 [==============================] - 0s 872us/sample - loss: 7.2720e-04 - acc: 1.0000 - val_loss: 0.5892 - val_acc: 0.9524\n",
      "Epoch 618/800\n",
      "114/114 [==============================] - 0s 877us/sample - loss: 7.9942e-04 - acc: 1.0000 - val_loss: 0.5885 - val_acc: 0.9524\n",
      "Epoch 619/800\n",
      "114/114 [==============================] - 0s 892us/sample - loss: 8.5048e-04 - acc: 1.0000 - val_loss: 0.5911 - val_acc: 0.9524\n",
      "Epoch 620/800\n",
      "114/114 [==============================] - 0s 866us/sample - loss: 8.4597e-04 - acc: 1.0000 - val_loss: 0.5879 - val_acc: 0.9524\n",
      "Epoch 621/800\n",
      "114/114 [==============================] - 0s 919us/sample - loss: 7.5037e-04 - acc: 1.0000 - val_loss: 0.5891 - val_acc: 0.9524\n",
      "Epoch 622/800\n",
      "114/114 [==============================] - 0s 867us/sample - loss: 7.6906e-04 - acc: 1.0000 - val_loss: 0.5893 - val_acc: 0.9524\n",
      "Epoch 623/800\n",
      "114/114 [==============================] - 0s 881us/sample - loss: 7.2679e-04 - acc: 1.0000 - val_loss: 0.5922 - val_acc: 0.9524\n",
      "Epoch 624/800\n",
      "114/114 [==============================] - 0s 871us/sample - loss: 7.4402e-04 - acc: 1.0000 - val_loss: 0.5920 - val_acc: 0.9524\n",
      "Epoch 625/800\n",
      "114/114 [==============================] - 0s 873us/sample - loss: 7.0255e-04 - acc: 1.0000 - val_loss: 0.5912 - val_acc: 0.9524\n",
      "Epoch 626/800\n",
      "114/114 [==============================] - 0s 887us/sample - loss: 7.4885e-04 - acc: 1.0000 - val_loss: 0.5895 - val_acc: 0.9524\n",
      "Epoch 627/800\n",
      "114/114 [==============================] - 0s 870us/sample - loss: 7.3357e-04 - acc: 1.0000 - val_loss: 0.5905 - val_acc: 0.9524\n",
      "Epoch 628/800\n",
      "114/114 [==============================] - 0s 874us/sample - loss: 6.8825e-04 - acc: 1.0000 - val_loss: 0.5926 - val_acc: 0.9524\n",
      "Epoch 629/800\n",
      "114/114 [==============================] - 0s 885us/sample - loss: 7.8728e-04 - acc: 1.0000 - val_loss: 0.5970 - val_acc: 0.9524\n",
      "Epoch 630/800\n",
      "114/114 [==============================] - 0s 883us/sample - loss: 8.0526e-04 - acc: 1.0000 - val_loss: 0.5948 - val_acc: 0.9524\n",
      "Epoch 631/800\n",
      "114/114 [==============================] - 0s 871us/sample - loss: 6.6305e-04 - acc: 1.0000 - val_loss: 0.5906 - val_acc: 0.9524\n",
      "Epoch 632/800\n",
      "114/114 [==============================] - 0s 144us/sample - loss: 8.0871e-04 - acc: 1.0000 - val_loss: 0.5899 - val_acc: 0.9524\n",
      "Epoch 633/800\n",
      "114/114 [==============================] - 0s 918us/sample - loss: 8.0244e-04 - acc: 1.0000 - val_loss: 0.5937 - val_acc: 0.9524\n",
      "Epoch 634/800\n",
      "114/114 [==============================] - 0s 914us/sample - loss: 8.0855e-04 - acc: 1.0000 - val_loss: 0.5989 - val_acc: 0.9524\n",
      "Epoch 635/800\n",
      "114/114 [==============================] - 0s 889us/sample - loss: 7.8332e-04 - acc: 1.0000 - val_loss: 0.5952 - val_acc: 0.9524\n",
      "Epoch 636/800\n",
      "114/114 [==============================] - 0s 847us/sample - loss: 7.4182e-04 - acc: 1.0000 - val_loss: 0.5924 - val_acc: 0.9524\n",
      "Epoch 637/800\n",
      "114/114 [==============================] - 0s 889us/sample - loss: 7.0996e-04 - acc: 1.0000 - val_loss: 0.5939 - val_acc: 0.9524\n",
      "Epoch 638/800\n",
      "114/114 [==============================] - 0s 865us/sample - loss: 7.5940e-04 - acc: 1.0000 - val_loss: 0.5968 - val_acc: 0.9524\n",
      "Epoch 639/800\n",
      "114/114 [==============================] - 0s 870us/sample - loss: 6.8719e-04 - acc: 1.0000 - val_loss: 0.5953 - val_acc: 0.9524\n",
      "Epoch 640/800\n",
      "114/114 [==============================] - 0s 871us/sample - loss: 6.5920e-04 - acc: 1.0000 - val_loss: 0.5960 - val_acc: 0.9524\n",
      "Epoch 641/800\n",
      "114/114 [==============================] - 0s 869us/sample - loss: 6.4035e-04 - acc: 1.0000 - val_loss: 0.5956 - val_acc: 0.9524\n",
      "Epoch 642/800\n",
      "114/114 [==============================] - 0s 872us/sample - loss: 6.4464e-04 - acc: 1.0000 - val_loss: 0.5961 - val_acc: 0.9524\n",
      "Epoch 643/800\n",
      "114/114 [==============================] - 0s 891us/sample - loss: 6.4766e-04 - acc: 1.0000 - val_loss: 0.5965 - val_acc: 0.9524\n",
      "Epoch 644/800\n",
      "114/114 [==============================] - 0s 870us/sample - loss: 6.3140e-04 - acc: 1.0000 - val_loss: 0.5978 - val_acc: 0.9524\n",
      "Epoch 645/800\n",
      "114/114 [==============================] - 0s 864us/sample - loss: 7.2164e-04 - acc: 1.0000 - val_loss: 0.5991 - val_acc: 0.9524\n",
      "Epoch 646/800\n",
      "114/114 [==============================] - 0s 878us/sample - loss: 6.1666e-04 - acc: 1.0000 - val_loss: 0.5970 - val_acc: 0.9524\n",
      "Epoch 647/800\n",
      "114/114 [==============================] - 0s 862us/sample - loss: 6.6846e-04 - acc: 1.0000 - val_loss: 0.5966 - val_acc: 0.9524\n",
      "Epoch 648/800\n",
      "114/114 [==============================] - 0s 885us/sample - loss: 6.8183e-04 - acc: 1.0000 - val_loss: 0.6002 - val_acc: 0.9524\n",
      "Epoch 649/800\n",
      "114/114 [==============================] - 0s 2ms/sample - loss: 6.9086e-04 - acc: 1.0000 - val_loss: 0.6013 - val_acc: 0.9524\n",
      "Epoch 650/800\n",
      "114/114 [==============================] - 0s 888us/sample - loss: 6.2590e-04 - acc: 1.0000 - val_loss: 0.5979 - val_acc: 0.9524\n",
      "Epoch 651/800\n",
      "114/114 [==============================] - 0s 888us/sample - loss: 7.3842e-04 - acc: 1.0000 - val_loss: 0.5971 - val_acc: 0.9524\n",
      "Epoch 652/800\n",
      "114/114 [==============================] - 0s 856us/sample - loss: 6.5784e-04 - acc: 1.0000 - val_loss: 0.5996 - val_acc: 0.9524\n",
      "Epoch 653/800\n",
      "114/114 [==============================] - 0s 890us/sample - loss: 9.0228e-04 - acc: 1.0000 - val_loss: 0.6058 - val_acc: 0.9524\n",
      "Epoch 654/800\n",
      "114/114 [==============================] - 0s 854us/sample - loss: 6.9996e-04 - acc: 1.0000 - val_loss: 0.6014 - val_acc: 0.9524\n",
      "Epoch 655/800\n",
      "114/114 [==============================] - 0s 911us/sample - loss: 5.5931e-04 - acc: 1.0000 - val_loss: 0.5992 - val_acc: 0.9524\n",
      "Epoch 656/800\n",
      "114/114 [==============================] - 0s 872us/sample - loss: 7.0996e-04 - acc: 1.0000 - val_loss: 0.5992 - val_acc: 0.9524\n",
      "Epoch 657/800\n",
      "114/114 [==============================] - 0s 872us/sample - loss: 6.4666e-04 - acc: 1.0000 - val_loss: 0.6022 - val_acc: 0.9524\n",
      "Epoch 658/800\n",
      "114/114 [==============================] - 0s 872us/sample - loss: 6.1494e-04 - acc: 1.0000 - val_loss: 0.6043 - val_acc: 0.9524\n",
      "Epoch 659/800\n",
      "114/114 [==============================] - 0s 870us/sample - loss: 6.0840e-04 - acc: 1.0000 - val_loss: 0.6035 - val_acc: 0.9524\n",
      "Epoch 660/800\n",
      "114/114 [==============================] - 0s 872us/sample - loss: 6.7132e-04 - acc: 1.0000 - val_loss: 0.6015 - val_acc: 0.9524\n",
      "Epoch 661/800\n",
      "114/114 [==============================] - 0s 852us/sample - loss: 5.8303e-04 - acc: 1.0000 - val_loss: 0.6032 - val_acc: 0.9524\n",
      "Epoch 662/800\n",
      "114/114 [==============================] - 0s 890us/sample - loss: 5.7326e-04 - acc: 1.0000 - val_loss: 0.6051 - val_acc: 0.9524\n",
      "Epoch 663/800\n",
      "114/114 [==============================] - 0s 870us/sample - loss: 6.1594e-04 - acc: 1.0000 - val_loss: 0.6062 - val_acc: 0.9524\n",
      "Epoch 664/800\n",
      "114/114 [==============================] - 0s 852us/sample - loss: 5.8764e-04 - acc: 1.0000 - val_loss: 0.6046 - val_acc: 0.9524\n",
      "Epoch 665/800\n",
      "114/114 [==============================] - 0s 888us/sample - loss: 5.5271e-04 - acc: 1.0000 - val_loss: 0.6023 - val_acc: 0.9524\n",
      "Epoch 666/800\n",
      "114/114 [==============================] - 0s 878us/sample - loss: 6.4009e-04 - acc: 1.0000 - val_loss: 0.6034 - val_acc: 0.9524\n",
      "Epoch 667/800\n",
      "114/114 [==============================] - 0s 874us/sample - loss: 6.1918e-04 - acc: 1.0000 - val_loss: 0.6041 - val_acc: 0.9524\n",
      "Epoch 668/800\n",
      "114/114 [==============================] - 0s 867us/sample - loss: 5.8347e-04 - acc: 1.0000 - val_loss: 0.6061 - val_acc: 0.9524\n",
      "Epoch 669/800\n",
      "114/114 [==============================] - 0s 896us/sample - loss: 5.7269e-04 - acc: 1.0000 - val_loss: 0.6057 - val_acc: 0.9524\n",
      "Epoch 670/800\n",
      "114/114 [==============================] - 0s 872us/sample - loss: 5.5728e-04 - acc: 1.0000 - val_loss: 0.6061 - val_acc: 0.9524\n",
      "Epoch 671/800\n",
      "114/114 [==============================] - 0s 869us/sample - loss: 5.5451e-04 - acc: 1.0000 - val_loss: 0.6066 - val_acc: 0.9524\n",
      "Epoch 672/800\n",
      "114/114 [==============================] - 0s 884us/sample - loss: 5.4723e-04 - acc: 1.0000 - val_loss: 0.6077 - val_acc: 0.9524\n",
      "Epoch 673/800\n",
      "114/114 [==============================] - 0s 866us/sample - loss: 5.7545e-04 - acc: 1.0000 - val_loss: 0.6091 - val_acc: 0.9524\n",
      "Epoch 674/800\n",
      "114/114 [==============================] - 0s 874us/sample - loss: 5.5634e-04 - acc: 1.0000 - val_loss: 0.6075 - val_acc: 0.9524\n",
      "Epoch 675/800\n",
      "114/114 [==============================] - 0s 874us/sample - loss: 5.3336e-04 - acc: 1.0000 - val_loss: 0.6069 - val_acc: 0.9524\n",
      "Epoch 676/800\n",
      "114/114 [==============================] - 0s 889us/sample - loss: 5.7318e-04 - acc: 1.0000 - val_loss: 0.6063 - val_acc: 0.9524\n",
      "Epoch 677/800\n",
      "114/114 [==============================] - 0s 854us/sample - loss: 6.1206e-04 - acc: 1.0000 - val_loss: 0.6073 - val_acc: 0.9524\n",
      "Epoch 678/800\n",
      "114/114 [==============================] - 0s 883us/sample - loss: 5.4750e-04 - acc: 1.0000 - val_loss: 0.6118 - val_acc: 0.9524\n",
      "Epoch 679/800\n",
      "114/114 [==============================] - 0s 859us/sample - loss: 6.3477e-04 - acc: 1.0000 - val_loss: 0.6125 - val_acc: 0.9524\n",
      "Epoch 680/800\n",
      "114/114 [==============================] - 0s 885us/sample - loss: 5.6965e-04 - acc: 1.0000 - val_loss: 0.6080 - val_acc: 0.9524\n",
      "Epoch 681/800\n",
      "114/114 [==============================] - 0s 2ms/sample - loss: 5.9003e-04 - acc: 1.0000 - val_loss: 0.6076 - val_acc: 0.9524\n",
      "Epoch 682/800\n",
      "114/114 [==============================] - 0s 888us/sample - loss: 5.6073e-04 - acc: 1.0000 - val_loss: 0.6085 - val_acc: 0.9524\n",
      "Epoch 683/800\n",
      "114/114 [==============================] - 0s 917us/sample - loss: 5.7085e-04 - acc: 1.0000 - val_loss: 0.6121 - val_acc: 0.9524\n",
      "Epoch 684/800\n",
      "114/114 [==============================] - 0s 851us/sample - loss: 5.4893e-04 - acc: 1.0000 - val_loss: 0.6129 - val_acc: 0.9524\n",
      "Epoch 685/800\n",
      "114/114 [==============================] - 0s 879us/sample - loss: 6.0338e-04 - acc: 1.0000 - val_loss: 0.6095 - val_acc: 0.9524\n",
      "Epoch 686/800\n",
      "114/114 [==============================] - 0s 877us/sample - loss: 6.1256e-04 - acc: 1.0000 - val_loss: 0.6116 - val_acc: 0.9524\n",
      "Epoch 687/800\n",
      "114/114 [==============================] - 0s 893us/sample - loss: 5.1764e-04 - acc: 1.0000 - val_loss: 0.6114 - val_acc: 0.9524\n",
      "Epoch 688/800\n",
      "114/114 [==============================] - 0s 872us/sample - loss: 5.0838e-04 - acc: 1.0000 - val_loss: 0.6108 - val_acc: 0.9524\n",
      "Epoch 689/800\n",
      "114/114 [==============================] - 0s 882us/sample - loss: 5.1419e-04 - acc: 1.0000 - val_loss: 0.6112 - val_acc: 0.9524\n",
      "Epoch 690/800\n",
      "114/114 [==============================] - 0s 873us/sample - loss: 5.1135e-04 - acc: 1.0000 - val_loss: 0.6123 - val_acc: 0.9524\n",
      "Epoch 691/800\n",
      "114/114 [==============================] - 0s 869us/sample - loss: 5.0172e-04 - acc: 1.0000 - val_loss: 0.6137 - val_acc: 0.9524\n",
      "Epoch 692/800\n",
      "114/114 [==============================] - 0s 872us/sample - loss: 5.2270e-04 - acc: 1.0000 - val_loss: 0.6147 - val_acc: 0.9524\n",
      "Epoch 693/800\n",
      "114/114 [==============================] - 0s 870us/sample - loss: 5.0854e-04 - acc: 1.0000 - val_loss: 0.6140 - val_acc: 0.9524\n",
      "Epoch 694/800\n",
      "114/114 [==============================] - 0s 874us/sample - loss: 5.1675e-04 - acc: 1.0000 - val_loss: 0.6120 - val_acc: 0.9524\n",
      "Epoch 695/800\n",
      "114/114 [==============================] - 0s 873us/sample - loss: 5.1800e-04 - acc: 1.0000 - val_loss: 0.6130 - val_acc: 0.9524\n",
      "Epoch 696/800\n",
      "114/114 [==============================] - 0s 870us/sample - loss: 5.5783e-04 - acc: 1.0000 - val_loss: 0.6160 - val_acc: 0.9524\n",
      "Epoch 697/800\n",
      "114/114 [==============================] - 0s 872us/sample - loss: 5.4523e-04 - acc: 1.0000 - val_loss: 0.6164 - val_acc: 0.9524\n",
      "Epoch 698/800\n",
      "114/114 [==============================] - 0s 870us/sample - loss: 5.5346e-04 - acc: 1.0000 - val_loss: 0.6142 - val_acc: 0.9524\n",
      "Epoch 699/800\n",
      "114/114 [==============================] - 0s 874us/sample - loss: 4.8781e-04 - acc: 1.0000 - val_loss: 0.6154 - val_acc: 0.9524\n",
      "Epoch 700/800\n",
      "114/114 [==============================] - 0s 870us/sample - loss: 4.7895e-04 - acc: 1.0000 - val_loss: 0.6166 - val_acc: 0.9524\n",
      "Epoch 701/800\n",
      "114/114 [==============================] - 0s 870us/sample - loss: 5.1184e-04 - acc: 1.0000 - val_loss: 0.6169 - val_acc: 0.9524\n",
      "Epoch 702/800\n",
      "114/114 [==============================] - 0s 872us/sample - loss: 4.8787e-04 - acc: 1.0000 - val_loss: 0.6162 - val_acc: 0.9524\n",
      "Epoch 703/800\n",
      "114/114 [==============================] - 0s 879us/sample - loss: 4.8083e-04 - acc: 1.0000 - val_loss: 0.6164 - val_acc: 0.9524\n",
      "Epoch 704/800\n",
      "114/114 [==============================] - 0s 877us/sample - loss: 4.9199e-04 - acc: 1.0000 - val_loss: 0.6180 - val_acc: 0.9524\n",
      "Epoch 705/800\n",
      "114/114 [==============================] - 0s 862us/sample - loss: 4.8107e-04 - acc: 1.0000 - val_loss: 0.6172 - val_acc: 0.9524\n",
      "Epoch 706/800\n",
      "114/114 [==============================] - 0s 884us/sample - loss: 4.7787e-04 - acc: 1.0000 - val_loss: 0.6177 - val_acc: 0.9524\n",
      "Epoch 707/800\n",
      "114/114 [==============================] - 0s 870us/sample - loss: 4.9650e-04 - acc: 1.0000 - val_loss: 0.6171 - val_acc: 0.9524\n",
      "Epoch 708/800\n",
      "114/114 [==============================] - 0s 887us/sample - loss: 5.0988e-04 - acc: 1.0000 - val_loss: 0.6202 - val_acc: 0.9524\n",
      "Epoch 709/800\n",
      "114/114 [==============================] - 0s 859us/sample - loss: 4.7705e-04 - acc: 1.0000 - val_loss: 0.6199 - val_acc: 0.9524\n",
      "Epoch 710/800\n",
      "114/114 [==============================] - 0s 876us/sample - loss: 4.7916e-04 - acc: 1.0000 - val_loss: 0.6183 - val_acc: 0.9524\n",
      "Epoch 711/800\n",
      "114/114 [==============================] - 0s 871us/sample - loss: 4.5901e-04 - acc: 1.0000 - val_loss: 0.6186 - val_acc: 0.9524\n",
      "Epoch 712/800\n",
      "114/114 [==============================] - 0s 2ms/sample - loss: 4.6822e-04 - acc: 1.0000 - val_loss: 0.6201 - val_acc: 0.9524\n",
      "Epoch 713/800\n",
      "114/114 [==============================] - 0s 870us/sample - loss: 4.7067e-04 - acc: 1.0000 - val_loss: 0.6197 - val_acc: 0.9524\n",
      "Epoch 714/800\n",
      "114/114 [==============================] - 0s 885us/sample - loss: 4.5191e-04 - acc: 1.0000 - val_loss: 0.6206 - val_acc: 0.9524\n",
      "Epoch 715/800\n",
      "114/114 [==============================] - 0s 885us/sample - loss: 4.5007e-04 - acc: 1.0000 - val_loss: 0.6213 - val_acc: 0.9524\n",
      "Epoch 716/800\n",
      "114/114 [==============================] - 0s 855us/sample - loss: 4.6320e-04 - acc: 1.0000 - val_loss: 0.6224 - val_acc: 0.9524\n",
      "Epoch 717/800\n",
      "114/114 [==============================] - 0s 911us/sample - loss: 4.9144e-04 - acc: 1.0000 - val_loss: 0.6227 - val_acc: 0.9524\n",
      "Epoch 718/800\n",
      "114/114 [==============================] - 0s 869us/sample - loss: 5.0566e-04 - acc: 1.0000 - val_loss: 0.6189 - val_acc: 0.9524\n",
      "Epoch 719/800\n",
      "114/114 [==============================] - 0s 865us/sample - loss: 4.9589e-04 - acc: 1.0000 - val_loss: 0.6199 - val_acc: 0.9524\n",
      "Epoch 720/800\n",
      "114/114 [==============================] - 0s 887us/sample - loss: 5.0236e-04 - acc: 1.0000 - val_loss: 0.6232 - val_acc: 0.9524\n",
      "Epoch 721/800\n",
      "114/114 [==============================] - 0s 865us/sample - loss: 4.3896e-04 - acc: 1.0000 - val_loss: 0.6231 - val_acc: 0.9524\n",
      "Epoch 722/800\n",
      "114/114 [==============================] - 0s 873us/sample - loss: 4.5076e-04 - acc: 1.0000 - val_loss: 0.6236 - val_acc: 0.9524\n",
      "Epoch 723/800\n",
      "114/114 [==============================] - 0s 864us/sample - loss: 4.3635e-04 - acc: 1.0000 - val_loss: 0.6223 - val_acc: 0.9524\n",
      "Epoch 724/800\n",
      "114/114 [==============================] - 0s 871us/sample - loss: 4.3455e-04 - acc: 1.0000 - val_loss: 0.6222 - val_acc: 0.9524\n",
      "Epoch 725/800\n",
      "114/114 [==============================] - 0s 893us/sample - loss: 4.4112e-04 - acc: 1.0000 - val_loss: 0.6235 - val_acc: 0.9524\n",
      "Epoch 726/800\n",
      "114/114 [==============================] - 0s 853us/sample - loss: 4.2685e-04 - acc: 1.0000 - val_loss: 0.6247 - val_acc: 0.9524\n",
      "Epoch 727/800\n",
      "114/114 [==============================] - 0s 907us/sample - loss: 4.2460e-04 - acc: 1.0000 - val_loss: 0.6251 - val_acc: 0.9524\n",
      "Epoch 728/800\n",
      "114/114 [==============================] - 0s 877us/sample - loss: 4.2283e-04 - acc: 1.0000 - val_loss: 0.6250 - val_acc: 0.9524\n",
      "Epoch 729/800\n",
      "114/114 [==============================] - 0s 876us/sample - loss: 4.6497e-04 - acc: 1.0000 - val_loss: 0.6240 - val_acc: 0.9524\n",
      "Epoch 730/800\n",
      "114/114 [==============================] - 0s 865us/sample - loss: 4.2063e-04 - acc: 1.0000 - val_loss: 0.6259 - val_acc: 0.9524\n",
      "Epoch 731/800\n",
      "114/114 [==============================] - 0s 872us/sample - loss: 4.1873e-04 - acc: 1.0000 - val_loss: 0.6266 - val_acc: 0.9524\n",
      "Epoch 732/800\n",
      "114/114 [==============================] - 0s 869us/sample - loss: 4.2167e-04 - acc: 1.0000 - val_loss: 0.6259 - val_acc: 0.9524\n",
      "Epoch 733/800\n",
      "114/114 [==============================] - 0s 871us/sample - loss: 4.5909e-04 - acc: 1.0000 - val_loss: 0.6251 - val_acc: 0.9524\n",
      "Epoch 734/800\n",
      "114/114 [==============================] - 0s 885us/sample - loss: 4.4976e-04 - acc: 1.0000 - val_loss: 0.6279 - val_acc: 0.9524\n",
      "Epoch 735/800\n",
      "114/114 [==============================] - 0s 865us/sample - loss: 4.2785e-04 - acc: 1.0000 - val_loss: 0.6272 - val_acc: 0.9524\n",
      "Epoch 736/800\n",
      "114/114 [==============================] - 0s 867us/sample - loss: 4.1998e-04 - acc: 1.0000 - val_loss: 0.6267 - val_acc: 0.9524\n",
      "Epoch 737/800\n",
      "114/114 [==============================] - 0s 873us/sample - loss: 4.3981e-04 - acc: 1.0000 - val_loss: 0.6268 - val_acc: 0.9524\n",
      "Epoch 738/800\n",
      "114/114 [==============================] - 0s 882us/sample - loss: 4.1103e-04 - acc: 1.0000 - val_loss: 0.6293 - val_acc: 0.9524\n",
      "Epoch 739/800\n",
      "114/114 [==============================] - 0s 873us/sample - loss: 4.2700e-04 - acc: 1.0000 - val_loss: 0.6297 - val_acc: 0.9524\n",
      "Epoch 740/800\n",
      "114/114 [==============================] - 0s 2ms/sample - loss: 4.0190e-04 - acc: 1.0000 - val_loss: 0.6281 - val_acc: 0.9524\n",
      "Epoch 741/800\n",
      "114/114 [==============================] - 0s 894us/sample - loss: 3.9599e-04 - acc: 1.0000 - val_loss: 0.6266 - val_acc: 0.9524\n",
      "Epoch 742/800\n",
      "114/114 [==============================] - 0s 893us/sample - loss: 4.1831e-04 - acc: 1.0000 - val_loss: 0.6268 - val_acc: 0.9524\n",
      "Epoch 743/800\n",
      "114/114 [==============================] - 0s 857us/sample - loss: 4.2941e-04 - acc: 1.0000 - val_loss: 0.6294 - val_acc: 0.9524\n",
      "Epoch 744/800\n",
      "114/114 [==============================] - 0s 896us/sample - loss: 4.0899e-04 - acc: 1.0000 - val_loss: 0.6305 - val_acc: 0.9524\n",
      "Epoch 745/800\n",
      "114/114 [==============================] - 0s 876us/sample - loss: 4.0117e-04 - acc: 1.0000 - val_loss: 0.6300 - val_acc: 0.9524\n",
      "Epoch 746/800\n",
      "114/114 [==============================] - 0s 892us/sample - loss: 3.9182e-04 - acc: 1.0000 - val_loss: 0.6292 - val_acc: 0.9524\n",
      "Epoch 747/800\n",
      "114/114 [==============================] - 0s 881us/sample - loss: 3.9707e-04 - acc: 1.0000 - val_loss: 0.6290 - val_acc: 0.9524\n",
      "Epoch 748/800\n",
      "114/114 [==============================] - 0s 862us/sample - loss: 3.9171e-04 - acc: 1.0000 - val_loss: 0.6304 - val_acc: 0.9524\n",
      "Epoch 749/800\n",
      "114/114 [==============================] - 0s 889us/sample - loss: 3.9596e-04 - acc: 1.0000 - val_loss: 0.6314 - val_acc: 0.9524\n",
      "Epoch 750/800\n",
      "114/114 [==============================] - 0s 884us/sample - loss: 3.9925e-04 - acc: 1.0000 - val_loss: 0.6303 - val_acc: 0.9524\n",
      "Epoch 751/800\n",
      "114/114 [==============================] - 0s 859us/sample - loss: 3.9068e-04 - acc: 1.0000 - val_loss: 0.6310 - val_acc: 0.9524\n",
      "Epoch 752/800\n",
      "114/114 [==============================] - 0s 897us/sample - loss: 3.9055e-04 - acc: 1.0000 - val_loss: 0.6308 - val_acc: 0.9524\n",
      "Epoch 753/800\n",
      "114/114 [==============================] - 0s 852us/sample - loss: 3.9366e-04 - acc: 1.0000 - val_loss: 0.6320 - val_acc: 0.9524\n",
      "Epoch 754/800\n",
      "114/114 [==============================] - 0s 863us/sample - loss: 3.8567e-04 - acc: 1.0000 - val_loss: 0.6324 - val_acc: 0.9524\n",
      "Epoch 755/800\n",
      "114/114 [==============================] - 0s 870us/sample - loss: 4.6830e-04 - acc: 1.0000 - val_loss: 0.6305 - val_acc: 0.9524\n",
      "Epoch 756/800\n",
      "114/114 [==============================] - 0s 871us/sample - loss: 3.7525e-04 - acc: 1.0000 - val_loss: 0.6326 - val_acc: 0.9524\n",
      "Epoch 757/800\n",
      "114/114 [==============================] - 0s 874us/sample - loss: 3.6484e-04 - acc: 1.0000 - val_loss: 0.6345 - val_acc: 0.9524\n",
      "Epoch 758/800\n",
      "114/114 [==============================] - 0s 884us/sample - loss: 4.1737e-04 - acc: 1.0000 - val_loss: 0.6352 - val_acc: 0.9524\n",
      "Epoch 759/800\n",
      "114/114 [==============================] - 0s 2ms/sample - loss: 3.8670e-04 - acc: 1.0000 - val_loss: 0.6345 - val_acc: 0.9524\n",
      "Epoch 760/800\n",
      "114/114 [==============================] - 0s 115us/sample - loss: 3.7063e-04 - acc: 1.0000 - val_loss: 0.6324 - val_acc: 0.9524\n",
      "Epoch 761/800\n",
      "114/114 [==============================] - 0s 878us/sample - loss: 4.2080e-04 - acc: 1.0000 - val_loss: 0.6309 - val_acc: 0.9524\n",
      "Epoch 762/800\n",
      "114/114 [==============================] - 0s 897us/sample - loss: 4.2274e-04 - acc: 1.0000 - val_loss: 0.6343 - val_acc: 0.9524\n",
      "Epoch 763/800\n",
      "114/114 [==============================] - 0s 907us/sample - loss: 3.6734e-04 - acc: 1.0000 - val_loss: 0.6352 - val_acc: 0.9524\n",
      "Epoch 764/800\n",
      "114/114 [==============================] - 0s 867us/sample - loss: 3.9043e-04 - acc: 1.0000 - val_loss: 0.6366 - val_acc: 0.9524\n",
      "Epoch 765/800\n",
      "114/114 [==============================] - 0s 881us/sample - loss: 3.9293e-04 - acc: 1.0000 - val_loss: 0.6356 - val_acc: 0.9524\n",
      "Epoch 766/800\n",
      "114/114 [==============================] - 0s 861us/sample - loss: 3.5684e-04 - acc: 1.0000 - val_loss: 0.6348 - val_acc: 0.9524\n",
      "Epoch 767/800\n",
      "114/114 [==============================] - 0s 901us/sample - loss: 3.7015e-04 - acc: 1.0000 - val_loss: 0.6340 - val_acc: 0.9524\n",
      "Epoch 768/800\n",
      "114/114 [==============================] - 0s 864us/sample - loss: 3.7182e-04 - acc: 1.0000 - val_loss: 0.6351 - val_acc: 0.9524\n",
      "Epoch 769/800\n",
      "114/114 [==============================] - 0s 870us/sample - loss: 3.5220e-04 - acc: 1.0000 - val_loss: 0.6371 - val_acc: 0.9524\n",
      "Epoch 770/800\n",
      "114/114 [==============================] - 0s 889us/sample - loss: 3.6382e-04 - acc: 1.0000 - val_loss: 0.6381 - val_acc: 0.9524\n",
      "Epoch 771/800\n",
      "114/114 [==============================] - 0s 871us/sample - loss: 3.7048e-04 - acc: 1.0000 - val_loss: 0.6384 - val_acc: 0.9524\n",
      "Epoch 772/800\n",
      "114/114 [==============================] - 0s 870us/sample - loss: 3.7105e-04 - acc: 1.0000 - val_loss: 0.6365 - val_acc: 0.9524\n",
      "Epoch 773/800\n",
      "114/114 [==============================] - 0s 884us/sample - loss: 3.7278e-04 - acc: 1.0000 - val_loss: 0.6366 - val_acc: 0.9524\n",
      "Epoch 774/800\n",
      "114/114 [==============================] - 0s 864us/sample - loss: 3.5341e-04 - acc: 1.0000 - val_loss: 0.6375 - val_acc: 0.9524\n",
      "Epoch 775/800\n",
      "114/114 [==============================] - 0s 866us/sample - loss: 3.5279e-04 - acc: 1.0000 - val_loss: 0.6379 - val_acc: 0.9524\n",
      "Epoch 776/800\n",
      "114/114 [==============================] - 0s 880us/sample - loss: 3.8694e-04 - acc: 1.0000 - val_loss: 0.6396 - val_acc: 0.9524\n",
      "Epoch 777/800\n",
      "114/114 [==============================] - 0s 863us/sample - loss: 3.4943e-04 - acc: 1.0000 - val_loss: 0.6385 - val_acc: 0.9524\n",
      "Epoch 778/800\n",
      "114/114 [==============================] - 0s 871us/sample - loss: 3.6923e-04 - acc: 1.0000 - val_loss: 0.6372 - val_acc: 0.9524\n",
      "Epoch 779/800\n",
      "114/114 [==============================] - 0s 873us/sample - loss: 3.9664e-04 - acc: 1.0000 - val_loss: 0.6401 - val_acc: 0.9524\n",
      "Epoch 780/800\n",
      "114/114 [==============================] - 0s 881us/sample - loss: 3.4996e-04 - acc: 1.0000 - val_loss: 0.6396 - val_acc: 0.9524\n",
      "Epoch 781/800\n",
      "114/114 [==============================] - 0s 863us/sample - loss: 3.4849e-04 - acc: 1.0000 - val_loss: 0.6399 - val_acc: 0.9524\n",
      "Epoch 782/800\n",
      "114/114 [==============================] - 0s 874us/sample - loss: 3.4633e-04 - acc: 1.0000 - val_loss: 0.6403 - val_acc: 0.9524\n",
      "Epoch 783/800\n",
      "114/114 [==============================] - 0s 870us/sample - loss: 3.3479e-04 - acc: 1.0000 - val_loss: 0.6396 - val_acc: 0.9524\n",
      "Epoch 784/800\n",
      "114/114 [==============================] - 0s 872us/sample - loss: 3.5262e-04 - acc: 1.0000 - val_loss: 0.6396 - val_acc: 0.9524\n",
      "Epoch 785/800\n",
      "114/114 [==============================] - 0s 868us/sample - loss: 3.4325e-04 - acc: 1.0000 - val_loss: 0.6407 - val_acc: 0.9524\n",
      "Epoch 786/800\n",
      "114/114 [==============================] - 0s 871us/sample - loss: 3.3974e-04 - acc: 1.0000 - val_loss: 0.6409 - val_acc: 0.9524\n",
      "Epoch 787/800\n",
      "114/114 [==============================] - 0s 874us/sample - loss: 3.3843e-04 - acc: 1.0000 - val_loss: 0.6417 - val_acc: 0.9524\n",
      "Epoch 788/800\n",
      "114/114 [==============================] - 0s 875us/sample - loss: 3.3818e-04 - acc: 1.0000 - val_loss: 0.6419 - val_acc: 0.9524\n",
      "Epoch 789/800\n",
      "114/114 [==============================] - 0s 887us/sample - loss: 3.2621e-04 - acc: 1.0000 - val_loss: 0.6413 - val_acc: 0.9524\n",
      "Epoch 790/800\n",
      "114/114 [==============================] - 0s 112us/sample - loss: 3.4709e-04 - acc: 1.0000 - val_loss: 0.6419 - val_acc: 0.9524\n",
      "Epoch 791/800\n",
      "114/114 [==============================] - 0s 850us/sample - loss: 3.2919e-04 - acc: 1.0000 - val_loss: 0.6421 - val_acc: 0.9524\n",
      "Epoch 792/800\n",
      "114/114 [==============================] - 0s 2ms/sample - loss: 3.2691e-04 - acc: 1.0000 - val_loss: 0.6421 - val_acc: 0.9524\n",
      "Epoch 793/800\n",
      "114/114 [==============================] - 0s 887us/sample - loss: 3.3224e-04 - acc: 1.0000 - val_loss: 0.6427 - val_acc: 0.9524\n",
      "Epoch 794/800\n",
      "114/114 [==============================] - 0s 867us/sample - loss: 3.2684e-04 - acc: 1.0000 - val_loss: 0.6423 - val_acc: 0.9524\n",
      "Epoch 795/800\n",
      "114/114 [==============================] - 0s 910us/sample - loss: 3.2456e-04 - acc: 1.0000 - val_loss: 0.6431 - val_acc: 0.9524\n",
      "Epoch 796/800\n",
      "114/114 [==============================] - 0s 854us/sample - loss: 3.5214e-04 - acc: 1.0000 - val_loss: 0.6449 - val_acc: 0.9524\n",
      "Epoch 797/800\n",
      "114/114 [==============================] - 0s 887us/sample - loss: 3.4032e-04 - acc: 1.0000 - val_loss: 0.6432 - val_acc: 0.9524\n",
      "Epoch 798/800\n",
      "114/114 [==============================] - 0s 874us/sample - loss: 3.2262e-04 - acc: 1.0000 - val_loss: 0.6441 - val_acc: 0.9524\n",
      "Epoch 799/800\n",
      "114/114 [==============================] - 0s 873us/sample - loss: 3.2680e-04 - acc: 1.0000 - val_loss: 0.6439 - val_acc: 0.9524\n",
      "Epoch 800/800\n",
      "114/114 [==============================] - 0s 868us/sample - loss: 3.1496e-04 - acc: 1.0000 - val_loss: 0.6451 - val_acc: 0.9524\n"
     ]
    }
   ],
   "source": [
    "# Run your function to train the model\n",
    "\n",
    "history = train_model(model, train_data, train_targets, epochs=800)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot the learning curves\n",
    "\n",
    "We will now plot two graphs:\n",
    "* Epoch vs accuracy\n",
    "* Epoch vs loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Run this cell to plot the epoch vs accuracy graph\n",
    "\n",
    "try:\n",
    "    plt.plot(history.history['accuracy'])\n",
    "    plt.plot(history.history['val_accuracy'])\n",
    "except KeyError:\n",
    "    plt.plot(history.history['acc'])\n",
    "    plt.plot(history.history['val_acc'])\n",
    "plt.title('Accuracy vs. epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Training', 'Validation'], loc='lower right')\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Run this cell to plot the epoch vs loss graph\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Loss vs. epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Training', 'Validation'], loc='upper right')\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oh no! We have overfit our dataset. You should now try to now try to mitigate this overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reducing overfitting in the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should now define a new regularised model.\n",
    "The specs for the regularised model are the same as our original model, with the addition of two dropout layers, weight decay, and a batch normalisation layer. \n",
    "\n",
    "In particular:\n",
    "\n",
    "* Add a dropout layer after the 3rd Dense layer\n",
    "* Then there should be two more Dense layers with 128 units before a batch normalisation layer\n",
    "* Following this, two more Dense layers with 64 units and then another Dropout layer\n",
    "* Two more Dense layers with 64 units and then the final 3-way softmax layer\n",
    "* Add weight decay (l2 kernel regularisation) in all Dense layers except the final softmax layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### GRADED CELL ####\n",
    "\n",
    "# Complete the following function. \n",
    "# Make sure to not change the function name or arguments.\n",
    "\n",
    "def get_regularised_model(input_shape, dropout_rate, weight_decay):\n",
    "    \"\"\"\n",
    "    This function should build a regularised Sequential model according to the above specification. \n",
    "    The dropout_rate argument in the function should be used to set the Dropout rate for all Dropout layers.\n",
    "    L2 kernel regularisation (weight decay) should be added using the weight_decay argument to \n",
    "    set the weight decay coefficient in all Dense layers that use L2 regularisation.\n",
    "    Ensure the weights are initialised by providing the input_shape argument in the first layer, given by the\n",
    "    function argument input_shape.\n",
    "    Your function should return the model.\n",
    "    \"\"\"\n",
    "    initializer = tf.keras.initializers.he_uniform()\n",
    "    model = Sequential([\n",
    "                      Dense(64, activation='relu', kernel_regularizer = regularizers.l2(weight_decay), kernel_initializer=initializer, bias_initializer='ones', input_shape=input_shape),\n",
    "                      Dense(128, activation='relu', kernel_regularizer = regularizers.l2(weight_decay)),\n",
    "                      Dense(128, activation='relu', kernel_regularizer = regularizers.l2(weight_decay)),\n",
    "                      Dropout(dropout_rate),\n",
    "                      Dense(128, activation='relu', kernel_regularizer = regularizers.l2(weight_decay)),\n",
    "                      Dense(128, activation='relu', kernel_regularizer = regularizers.l2(weight_decay)),\n",
    "                      BatchNormalization(),\n",
    "                      Dense(64, activation='relu', kernel_regularizer = regularizers.l2(weight_decay)),\n",
    "                      Dense(64, activation='relu', kernel_regularizer = regularizers.l2(weight_decay)),\n",
    "                      Dropout(dropout_rate),\n",
    "                      Dense(64, activation='relu', kernel_regularizer = regularizers.l2(weight_decay)),\n",
    "                      Dense(64, activation='relu', kernel_regularizer = regularizers.l2(weight_decay)),\n",
    "                      Dense(3, activation='softmax')\n",
    "    ])\n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Instantiate, compile and train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Instantiate the model, using a dropout rate of 0.3 and weight decay coefficient of 0.001\n",
    "\n",
    "reg_model = get_regularised_model(train_data[0].shape, 0.3, 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "\n",
    "compile_model(reg_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 114 samples, validate on 21 samples\n",
      "Epoch 1/800\n",
      "114/114 [==============================] - 3s 23ms/sample - loss: 1.9815 - acc: 0.3509 - val_loss: 1.9097 - val_acc: 0.6190\n",
      "Epoch 2/800\n",
      "114/114 [==============================] - 0s 838us/sample - loss: 1.9361 - acc: 0.3421 - val_loss: 1.9032 - val_acc: 0.6190\n",
      "Epoch 3/800\n",
      "114/114 [==============================] - 0s 911us/sample - loss: 1.9455 - acc: 0.3246 - val_loss: 1.8922 - val_acc: 0.5238\n",
      "Epoch 4/800\n",
      "114/114 [==============================] - 0s 2ms/sample - loss: 1.9477 - acc: 0.3772 - val_loss: 1.8815 - val_acc: 0.4762\n",
      "Epoch 5/800\n",
      "114/114 [==============================] - 0s 903us/sample - loss: 1.9517 - acc: 0.3509 - val_loss: 1.8721 - val_acc: 0.4762\n",
      "Epoch 6/800\n",
      "114/114 [==============================] - 0s 912us/sample - loss: 1.9643 - acc: 0.3158 - val_loss: 1.8639 - val_acc: 0.4762\n",
      "Epoch 7/800\n",
      "114/114 [==============================] - 0s 2ms/sample - loss: 1.9611 - acc: 0.3070 - val_loss: 1.8579 - val_acc: 0.4762\n",
      "Epoch 8/800\n",
      "114/114 [==============================] - 0s 933us/sample - loss: 1.9298 - acc: 0.3860 - val_loss: 1.8509 - val_acc: 0.4762\n",
      "Epoch 9/800\n",
      "114/114 [==============================] - 0s 896us/sample - loss: 1.9468 - acc: 0.4211 - val_loss: 1.8439 - val_acc: 0.5238\n",
      "Epoch 10/800\n",
      "114/114 [==============================] - 0s 879us/sample - loss: 1.9441 - acc: 0.3860 - val_loss: 1.8367 - val_acc: 0.5238\n",
      "Epoch 11/800\n",
      "114/114 [==============================] - 0s 957us/sample - loss: 1.8985 - acc: 0.4386 - val_loss: 1.8277 - val_acc: 0.5238\n",
      "Epoch 12/800\n",
      "114/114 [==============================] - 0s 899us/sample - loss: 1.9135 - acc: 0.4211 - val_loss: 1.8193 - val_acc: 0.5238\n",
      "Epoch 13/800\n",
      "114/114 [==============================] - 0s 893us/sample - loss: 1.9029 - acc: 0.4386 - val_loss: 1.8132 - val_acc: 0.5238\n",
      "Epoch 14/800\n",
      "114/114 [==============================] - 0s 2ms/sample - loss: 1.9298 - acc: 0.4035 - val_loss: 1.8078 - val_acc: 0.5238\n",
      "Epoch 15/800\n",
      "114/114 [==============================] - 0s 914us/sample - loss: 1.9074 - acc: 0.4298 - val_loss: 1.8038 - val_acc: 0.5238\n",
      "Epoch 16/800\n",
      "114/114 [==============================] - 0s 910us/sample - loss: 1.8562 - acc: 0.4912 - val_loss: 1.7980 - val_acc: 0.5238\n",
      "Epoch 17/800\n",
      "114/114 [==============================] - 0s 2ms/sample - loss: 1.8804 - acc: 0.4298 - val_loss: 1.7897 - val_acc: 0.5238\n",
      "Epoch 18/800\n",
      "114/114 [==============================] - 0s 894us/sample - loss: 1.8801 - acc: 0.5175 - val_loss: 1.7812 - val_acc: 0.5238\n",
      "Epoch 19/800\n",
      "114/114 [==============================] - 0s 940us/sample - loss: 1.8915 - acc: 0.4561 - val_loss: 1.7724 - val_acc: 0.5238\n",
      "Epoch 20/800\n",
      "114/114 [==============================] - 0s 893us/sample - loss: 1.8738 - acc: 0.5088 - val_loss: 1.7616 - val_acc: 0.5238\n",
      "Epoch 21/800\n",
      "114/114 [==============================] - 0s 2ms/sample - loss: 1.8370 - acc: 0.5614 - val_loss: 1.7501 - val_acc: 0.5238\n",
      "Epoch 22/800\n",
      "114/114 [==============================] - 0s 898us/sample - loss: 1.8561 - acc: 0.5088 - val_loss: 1.7414 - val_acc: 0.5238\n",
      "Epoch 23/800\n",
      "114/114 [==============================] - 0s 893us/sample - loss: 1.8354 - acc: 0.5614 - val_loss: 1.7336 - val_acc: 0.5714\n",
      "Epoch 24/800\n",
      "114/114 [==============================] - 0s 2ms/sample - loss: 1.8283 - acc: 0.4825 - val_loss: 1.7254 - val_acc: 0.5714\n",
      "Epoch 25/800\n",
      "114/114 [==============================] - 0s 907us/sample - loss: 1.8069 - acc: 0.5526 - val_loss: 1.7160 - val_acc: 0.5714\n",
      "Epoch 26/800\n",
      "114/114 [==============================] - 0s 900us/sample - loss: 1.7906 - acc: 0.5175 - val_loss: 1.7048 - val_acc: 0.6190\n",
      "Epoch 27/800\n",
      "114/114 [==============================] - 0s 2ms/sample - loss: 1.8045 - acc: 0.5614 - val_loss: 1.6949 - val_acc: 0.6190\n",
      "Epoch 28/800\n",
      "114/114 [==============================] - 0s 903us/sample - loss: 1.8090 - acc: 0.5965 - val_loss: 1.6850 - val_acc: 0.6190\n",
      "Epoch 29/800\n",
      "114/114 [==============================] - 0s 896us/sample - loss: 1.7437 - acc: 0.6754 - val_loss: 1.6749 - val_acc: 0.6190\n",
      "Epoch 30/800\n",
      "114/114 [==============================] - 0s 2ms/sample - loss: 1.7614 - acc: 0.5526 - val_loss: 1.6637 - val_acc: 0.6190\n",
      "Epoch 31/800\n",
      "114/114 [==============================] - 0s 943us/sample - loss: 1.7454 - acc: 0.6579 - val_loss: 1.6536 - val_acc: 0.6190\n",
      "Epoch 32/800\n",
      "114/114 [==============================] - 0s 907us/sample - loss: 1.7107 - acc: 0.6930 - val_loss: 1.6436 - val_acc: 0.6190\n",
      "Epoch 33/800\n",
      "114/114 [==============================] - 0s 2ms/sample - loss: 1.7369 - acc: 0.5702 - val_loss: 1.6325 - val_acc: 0.6190\n",
      "Epoch 34/800\n",
      "114/114 [==============================] - 0s 944us/sample - loss: 1.7343 - acc: 0.5877 - val_loss: 1.6227 - val_acc: 0.6190\n",
      "Epoch 35/800\n",
      "114/114 [==============================] - 0s 904us/sample - loss: 1.7171 - acc: 0.6228 - val_loss: 1.6118 - val_acc: 0.6190\n",
      "Epoch 36/800\n",
      "114/114 [==============================] - 0s 885us/sample - loss: 1.7123 - acc: 0.5965 - val_loss: 1.5998 - val_acc: 0.6190\n",
      "Epoch 37/800\n",
      "114/114 [==============================] - 0s 2ms/sample - loss: 1.6483 - acc: 0.6667 - val_loss: 1.5884 - val_acc: 0.6190\n",
      "Epoch 38/800\n",
      "114/114 [==============================] - 0s 894us/sample - loss: 1.6454 - acc: 0.6579 - val_loss: 1.5764 - val_acc: 0.6190\n",
      "Epoch 39/800\n",
      "114/114 [==============================] - 0s 899us/sample - loss: 1.6623 - acc: 0.6228 - val_loss: 1.5649 - val_acc: 0.6190\n",
      "Epoch 40/800\n",
      "114/114 [==============================] - 0s 889us/sample - loss: 1.6210 - acc: 0.6491 - val_loss: 1.5520 - val_acc: 0.6190\n",
      "Epoch 41/800\n",
      "114/114 [==============================] - 0s 2ms/sample - loss: 1.6200 - acc: 0.6404 - val_loss: 1.5383 - val_acc: 0.6190\n",
      "Epoch 42/800\n",
      "114/114 [==============================] - 0s 921us/sample - loss: 1.5866 - acc: 0.6316 - val_loss: 1.5240 - val_acc: 0.6190\n",
      "Epoch 43/800\n",
      "114/114 [==============================] - 0s 887us/sample - loss: 1.5742 - acc: 0.6842 - val_loss: 1.5105 - val_acc: 0.6190\n",
      "Epoch 44/800\n",
      "114/114 [==============================] - 0s 2ms/sample - loss: 1.5538 - acc: 0.6667 - val_loss: 1.4968 - val_acc: 0.6190\n",
      "Epoch 45/800\n",
      "114/114 [==============================] - 0s 909us/sample - loss: 1.5499 - acc: 0.6754 - val_loss: 1.4820 - val_acc: 0.6190\n",
      "Epoch 46/800\n",
      "114/114 [==============================] - 0s 885us/sample - loss: 1.4819 - acc: 0.7193 - val_loss: 1.4661 - val_acc: 0.6190\n",
      "Epoch 47/800\n",
      "114/114 [==============================] - 0s 884us/sample - loss: 1.4862 - acc: 0.6930 - val_loss: 1.4507 - val_acc: 0.6190\n",
      "Epoch 48/800\n",
      "114/114 [==============================] - 0s 2ms/sample - loss: 1.4803 - acc: 0.6667 - val_loss: 1.4352 - val_acc: 0.6190\n",
      "Epoch 49/800\n",
      "114/114 [==============================] - 0s 906us/sample - loss: 1.4570 - acc: 0.6930 - val_loss: 1.4210 - val_acc: 0.6190\n",
      "Epoch 50/800\n",
      "114/114 [==============================] - 0s 898us/sample - loss: 1.3843 - acc: 0.7281 - val_loss: 1.4082 - val_acc: 0.6190\n",
      "Epoch 51/800\n",
      "114/114 [==============================] - 0s 893us/sample - loss: 1.4353 - acc: 0.7105 - val_loss: 1.3965 - val_acc: 0.6190\n",
      "Epoch 52/800\n",
      "114/114 [==============================] - 0s 941us/sample - loss: 1.4161 - acc: 0.6754 - val_loss: 1.3849 - val_acc: 0.6190\n",
      "Epoch 53/800\n",
      "114/114 [==============================] - 0s 910us/sample - loss: 1.4162 - acc: 0.7018 - val_loss: 1.3739 - val_acc: 0.6190\n",
      "Epoch 54/800\n",
      "114/114 [==============================] - 0s 889us/sample - loss: 1.4060 - acc: 0.6930 - val_loss: 1.3646 - val_acc: 0.6667\n",
      "Epoch 55/800\n",
      "114/114 [==============================] - 0s 2ms/sample - loss: 1.4313 - acc: 0.6491 - val_loss: 1.3561 - val_acc: 0.6667\n",
      "Epoch 56/800\n",
      "114/114 [==============================] - 0s 914us/sample - loss: 1.3771 - acc: 0.7193 - val_loss: 1.3492 - val_acc: 0.6667\n",
      "Epoch 57/800\n",
      "114/114 [==============================] - 0s 899us/sample - loss: 1.3717 - acc: 0.6842 - val_loss: 1.3424 - val_acc: 0.6667\n",
      "Epoch 58/800\n",
      "114/114 [==============================] - 0s 893us/sample - loss: 1.3634 - acc: 0.7193 - val_loss: 1.3349 - val_acc: 0.6667\n",
      "Epoch 59/800\n",
      "114/114 [==============================] - 0s 2ms/sample - loss: 1.3535 - acc: 0.7018 - val_loss: 1.3273 - val_acc: 0.6667\n",
      "Epoch 60/800\n",
      "114/114 [==============================] - 0s 942us/sample - loss: 1.3346 - acc: 0.7018 - val_loss: 1.3196 - val_acc: 0.6667\n",
      "Epoch 61/800\n",
      "114/114 [==============================] - 0s 893us/sample - loss: 1.3132 - acc: 0.7193 - val_loss: 1.3119 - val_acc: 0.6667\n",
      "Epoch 62/800\n",
      "114/114 [==============================] - 0s 884us/sample - loss: 1.3265 - acc: 0.7193 - val_loss: 1.3043 - val_acc: 0.7143\n",
      "Epoch 63/800\n",
      "114/114 [==============================] - 0s 957us/sample - loss: 1.3073 - acc: 0.7193 - val_loss: 1.2972 - val_acc: 0.7143\n",
      "Epoch 64/800\n",
      "114/114 [==============================] - 0s 901us/sample - loss: 1.3163 - acc: 0.7368 - val_loss: 1.2910 - val_acc: 0.7143\n",
      "Epoch 65/800\n",
      "114/114 [==============================] - 0s 890us/sample - loss: 1.2857 - acc: 0.7895 - val_loss: 1.2844 - val_acc: 0.7619\n",
      "Epoch 66/800\n",
      "114/114 [==============================] - 0s 2ms/sample - loss: 1.2978 - acc: 0.7632 - val_loss: 1.2773 - val_acc: 0.7619\n",
      "Epoch 67/800\n",
      "114/114 [==============================] - 0s 944us/sample - loss: 1.2990 - acc: 0.7456 - val_loss: 1.2720 - val_acc: 0.7619\n",
      "Epoch 68/800\n",
      "114/114 [==============================] - 0s 897us/sample - loss: 1.3042 - acc: 0.7368 - val_loss: 1.2676 - val_acc: 0.7619\n",
      "Epoch 69/800\n",
      "114/114 [==============================] - 0s 890us/sample - loss: 1.2893 - acc: 0.7632 - val_loss: 1.2626 - val_acc: 0.7619\n",
      "Epoch 70/800\n",
      "114/114 [==============================] - 0s 938us/sample - loss: 1.2756 - acc: 0.7719 - val_loss: 1.2587 - val_acc: 0.7619\n",
      "Epoch 71/800\n",
      "114/114 [==============================] - 0s 896us/sample - loss: 1.2619 - acc: 0.7807 - val_loss: 1.2548 - val_acc: 0.8095\n",
      "Epoch 72/800\n",
      "114/114 [==============================] - 0s 912us/sample - loss: 1.2337 - acc: 0.8070 - val_loss: 1.2495 - val_acc: 0.8095\n",
      "Epoch 73/800\n",
      "114/114 [==============================] - 0s 2ms/sample - loss: 1.2606 - acc: 0.7719 - val_loss: 1.2448 - val_acc: 0.8095\n",
      "Epoch 74/800\n",
      "114/114 [==============================] - 0s 953us/sample - loss: 1.2693 - acc: 0.7544 - val_loss: 1.2402 - val_acc: 0.8095\n",
      "Epoch 75/800\n",
      "114/114 [==============================] - 0s 906us/sample - loss: 1.2718 - acc: 0.7456 - val_loss: 1.2375 - val_acc: 0.8095\n",
      "Epoch 76/800\n",
      "114/114 [==============================] - 0s 874us/sample - loss: 1.2723 - acc: 0.7807 - val_loss: 1.2357 - val_acc: 0.8095\n",
      "Epoch 77/800\n",
      "114/114 [==============================] - 0s 2ms/sample - loss: 1.2262 - acc: 0.7632 - val_loss: 1.2356 - val_acc: 0.8571\n",
      "Epoch 78/800\n",
      "114/114 [==============================] - 0s 928us/sample - loss: 1.2211 - acc: 0.8333 - val_loss: 1.2330 - val_acc: 0.8571\n",
      "Epoch 79/800\n",
      "114/114 [==============================] - 0s 889us/sample - loss: 1.2415 - acc: 0.7456 - val_loss: 1.2315 - val_acc: 0.8571\n",
      "Epoch 80/800\n",
      "114/114 [==============================] - 0s 2ms/sample - loss: 1.2313 - acc: 0.7982 - val_loss: 1.2312 - val_acc: 0.8571\n",
      "Epoch 81/800\n",
      "114/114 [==============================] - 0s 903us/sample - loss: 1.2152 - acc: 0.7719 - val_loss: 1.2278 - val_acc: 0.9048\n",
      "Epoch 82/800\n",
      "114/114 [==============================] - 0s 866us/sample - loss: 1.2263 - acc: 0.7982 - val_loss: 1.2245 - val_acc: 0.9048\n",
      "Epoch 83/800\n",
      "114/114 [==============================] - 0s 913us/sample - loss: 1.2339 - acc: 0.7895 - val_loss: 1.2228 - val_acc: 0.9048\n",
      "Epoch 84/800\n",
      "114/114 [==============================] - 0s 876us/sample - loss: 1.2110 - acc: 0.8070 - val_loss: 1.2199 - val_acc: 0.9524\n",
      "Epoch 85/800\n",
      "114/114 [==============================] - 0s 2ms/sample - loss: 1.2158 - acc: 0.7895 - val_loss: 1.2170 - val_acc: 0.9524\n",
      "Epoch 86/800\n",
      "114/114 [==============================] - 0s 920us/sample - loss: 1.1680 - acc: 0.8596 - val_loss: 1.2102 - val_acc: 0.9524\n",
      "Epoch 87/800\n",
      "114/114 [==============================] - 0s 903us/sample - loss: 1.2384 - acc: 0.7456 - val_loss: 1.2022 - val_acc: 0.9524\n",
      "Epoch 88/800\n",
      "114/114 [==============================] - 0s 871us/sample - loss: 1.2224 - acc: 0.7193 - val_loss: 1.1970 - val_acc: 0.9524\n",
      "Epoch 89/800\n",
      "114/114 [==============================] - 0s 2ms/sample - loss: 1.1921 - acc: 0.8246 - val_loss: 1.1913 - val_acc: 0.9524\n",
      "Epoch 90/800\n",
      "114/114 [==============================] - 0s 919us/sample - loss: 1.1915 - acc: 0.7632 - val_loss: 1.1838 - val_acc: 0.9524\n",
      "Epoch 91/800\n",
      "114/114 [==============================] - 0s 913us/sample - loss: 1.1543 - acc: 0.7982 - val_loss: 1.1793 - val_acc: 0.9524\n",
      "Epoch 92/800\n",
      "114/114 [==============================] - 0s 2ms/sample - loss: 1.1557 - acc: 0.8158 - val_loss: 1.1765 - val_acc: 0.9524\n",
      "Epoch 93/800\n",
      "114/114 [==============================] - 0s 938us/sample - loss: 1.1932 - acc: 0.8246 - val_loss: 1.1745 - val_acc: 0.9524\n",
      "Epoch 94/800\n",
      "114/114 [==============================] - 0s 871us/sample - loss: 1.1487 - acc: 0.8596 - val_loss: 1.1735 - val_acc: 0.9524\n",
      "Epoch 95/800\n",
      "114/114 [==============================] - 0s 898us/sample - loss: 1.2090 - acc: 0.7281 - val_loss: 1.1732 - val_acc: 0.9048\n",
      "Epoch 96/800\n",
      "114/114 [==============================] - 0s 889us/sample - loss: 1.1510 - acc: 0.7895 - val_loss: 1.1762 - val_acc: 0.9048\n",
      "Epoch 97/800\n",
      "114/114 [==============================] - 0s 2ms/sample - loss: 1.1358 - acc: 0.8421 - val_loss: 1.1763 - val_acc: 0.9048\n",
      "Epoch 98/800\n",
      "114/114 [==============================] - 0s 923us/sample - loss: 1.1558 - acc: 0.8158 - val_loss: 1.1729 - val_acc: 0.9524\n",
      "Epoch 99/800\n",
      "114/114 [==============================] - 0s 888us/sample - loss: 1.1384 - acc: 0.8158 - val_loss: 1.1631 - val_acc: 0.9048\n",
      "Epoch 100/800\n",
      "114/114 [==============================] - 0s 2ms/sample - loss: 1.1497 - acc: 0.8421 - val_loss: 1.1584 - val_acc: 0.9048\n",
      "Epoch 101/800\n",
      "114/114 [==============================] - 0s 946us/sample - loss: 1.1544 - acc: 0.8509 - val_loss: 1.1568 - val_acc: 0.9524\n",
      "Epoch 102/800\n",
      "114/114 [==============================] - 0s 890us/sample - loss: 1.1789 - acc: 0.7807 - val_loss: 1.1492 - val_acc: 0.9048\n",
      "Epoch 103/800\n",
      "114/114 [==============================] - 0s 890us/sample - loss: 1.1259 - acc: 0.8772 - val_loss: 1.1534 - val_acc: 0.9524\n",
      "Epoch 104/800\n",
      "114/114 [==============================] - 0s 875us/sample - loss: 1.1295 - acc: 0.8684 - val_loss: 1.1587 - val_acc: 0.9524\n",
      "Epoch 105/800\n",
      "114/114 [==============================] - 0s 2ms/sample - loss: 1.1408 - acc: 0.8158 - val_loss: 1.1583 - val_acc: 0.9524\n",
      "Epoch 106/800\n",
      "114/114 [==============================] - 0s 871us/sample - loss: 1.1804 - acc: 0.8158 - val_loss: 1.1568 - val_acc: 0.9048\n",
      "Epoch 107/800\n",
      "114/114 [==============================] - 0s 915us/sample - loss: 1.0882 - acc: 0.8860 - val_loss: 1.1564 - val_acc: 0.9048\n",
      "Epoch 108/800\n",
      "114/114 [==============================] - 0s 874us/sample - loss: 1.1348 - acc: 0.8246 - val_loss: 1.1611 - val_acc: 0.9048\n",
      "Epoch 109/800\n",
      "114/114 [==============================] - 0s 945us/sample - loss: 1.1044 - acc: 0.8421 - val_loss: 1.1564 - val_acc: 0.9048\n",
      "Epoch 110/800\n",
      "114/114 [==============================] - 0s 876us/sample - loss: 1.0912 - acc: 0.8684 - val_loss: 1.1500 - val_acc: 0.9048\n",
      "Epoch 111/800\n",
      "114/114 [==============================] - 0s 897us/sample - loss: 1.0994 - acc: 0.8772 - val_loss: 1.1367 - val_acc: 0.9048\n",
      "Epoch 112/800\n",
      "114/114 [==============================] - 0s 891us/sample - loss: 1.1016 - acc: 0.8246 - val_loss: 1.1239 - val_acc: 0.9048\n",
      "Epoch 113/800\n",
      "114/114 [==============================] - 0s 2ms/sample - loss: 1.0815 - acc: 0.9123 - val_loss: 1.1233 - val_acc: 0.9048\n",
      "Epoch 114/800\n",
      "114/114 [==============================] - 0s 899us/sample - loss: 1.0579 - acc: 0.8684 - val_loss: 1.1266 - val_acc: 0.9048\n",
      "Epoch 115/800\n",
      "114/114 [==============================] - 0s 894us/sample - loss: 1.0595 - acc: 0.8684 - val_loss: 1.1304 - val_acc: 0.9048\n",
      "Epoch 116/800\n",
      "114/114 [==============================] - 0s 897us/sample - loss: 1.1132 - acc: 0.8158 - val_loss: 1.1505 - val_acc: 0.9048\n",
      "Epoch 117/800\n",
      "114/114 [==============================] - 0s 879us/sample - loss: 1.0435 - acc: 0.8947 - val_loss: 1.1476 - val_acc: 0.9048\n",
      "Epoch 118/800\n",
      "114/114 [==============================] - 0s 930us/sample - loss: 1.0647 - acc: 0.8860 - val_loss: 1.1439 - val_acc: 0.9048\n",
      "Epoch 119/800\n",
      "114/114 [==============================] - 0s 922us/sample - loss: 1.0252 - acc: 0.9561 - val_loss: 1.1123 - val_acc: 0.9048\n",
      "Epoch 120/800\n",
      "114/114 [==============================] - 0s 892us/sample - loss: 1.0190 - acc: 0.9386 - val_loss: 1.0847 - val_acc: 0.9048\n",
      "Epoch 121/800\n",
      "114/114 [==============================] - 0s 871us/sample - loss: 1.0508 - acc: 0.8772 - val_loss: 1.0624 - val_acc: 0.9048\n",
      "Epoch 122/800\n",
      "114/114 [==============================] - 0s 2ms/sample - loss: 1.0453 - acc: 0.8684 - val_loss: 1.0550 - val_acc: 0.9048\n",
      "Epoch 123/800\n",
      "114/114 [==============================] - 0s 923us/sample - loss: 1.0155 - acc: 0.9035 - val_loss: 1.0407 - val_acc: 0.8571\n",
      "Epoch 124/800\n",
      "114/114 [==============================] - 0s 883us/sample - loss: 1.0005 - acc: 0.9386 - val_loss: 1.0294 - val_acc: 0.8571\n",
      "Epoch 125/800\n",
      "114/114 [==============================] - 0s 874us/sample - loss: 1.0375 - acc: 0.8772 - val_loss: 1.0203 - val_acc: 0.8571\n",
      "Epoch 126/800\n",
      "114/114 [==============================] - 0s 2ms/sample - loss: 0.9833 - acc: 0.9474 - val_loss: 1.0128 - val_acc: 0.8571\n",
      "Epoch 127/800\n",
      "114/114 [==============================] - 0s 897us/sample - loss: 0.9941 - acc: 0.8947 - val_loss: 1.0147 - val_acc: 0.9048\n",
      "Epoch 128/800\n",
      "114/114 [==============================] - 0s 884us/sample - loss: 0.9921 - acc: 0.9123 - val_loss: 1.0454 - val_acc: 0.9048\n",
      "Epoch 129/800\n",
      "114/114 [==============================] - 0s 2ms/sample - loss: 0.9484 - acc: 0.9298 - val_loss: 1.0824 - val_acc: 0.9048\n",
      "Epoch 130/800\n",
      "114/114 [==============================] - 0s 893us/sample - loss: 0.9304 - acc: 0.9474 - val_loss: 1.1048 - val_acc: 0.8571\n",
      "Epoch 131/800\n",
      "114/114 [==============================] - 0s 909us/sample - loss: 1.0043 - acc: 0.8947 - val_loss: 1.1152 - val_acc: 0.8571\n",
      "Epoch 132/800\n",
      "114/114 [==============================] - 0s 903us/sample - loss: 0.9987 - acc: 0.8684 - val_loss: 1.1083 - val_acc: 0.8571\n",
      "Epoch 133/800\n",
      "114/114 [==============================] - 0s 868us/sample - loss: 0.9167 - acc: 0.9649 - val_loss: 1.0951 - val_acc: 0.8571\n",
      "Epoch 134/800\n",
      "114/114 [==============================] - 0s 931us/sample - loss: 0.9775 - acc: 0.9123 - val_loss: 1.0557 - val_acc: 0.9048\n",
      "Epoch 135/800\n",
      "114/114 [==============================] - 0s 893us/sample - loss: 0.9127 - acc: 0.9561 - val_loss: 1.0315 - val_acc: 0.9048\n",
      "Epoch 136/800\n",
      "114/114 [==============================] - 0s 897us/sample - loss: 0.9897 - acc: 0.8684 - val_loss: 1.0223 - val_acc: 0.9048\n",
      "Epoch 137/800\n",
      "114/114 [==============================] - 0s 895us/sample - loss: 0.9395 - acc: 0.9298 - val_loss: 1.0512 - val_acc: 0.8571\n",
      "Epoch 138/800\n",
      "114/114 [==============================] - 0s 870us/sample - loss: 0.9059 - acc: 0.9561 - val_loss: 1.0573 - val_acc: 0.8571\n",
      "Epoch 139/800\n",
      "114/114 [==============================] - 0s 962us/sample - loss: 0.9248 - acc: 0.9386 - val_loss: 1.0196 - val_acc: 0.9048\n",
      "Epoch 140/800\n",
      "114/114 [==============================] - 0s 894us/sample - loss: 0.9470 - acc: 0.9386 - val_loss: 1.0002 - val_acc: 0.9524\n",
      "Epoch 141/800\n",
      "114/114 [==============================] - 0s 888us/sample - loss: 0.9025 - acc: 0.9561 - val_loss: 1.0305 - val_acc: 0.8571\n",
      "Epoch 142/800\n",
      "114/114 [==============================] - 0s 2ms/sample - loss: 0.8677 - acc: 0.9649 - val_loss: 1.0443 - val_acc: 0.8571\n",
      "Epoch 143/800\n",
      "114/114 [==============================] - 0s 890us/sample - loss: 0.9074 - acc: 0.9298 - val_loss: 1.0353 - val_acc: 0.9048\n",
      "Epoch 144/800\n",
      "114/114 [==============================] - 0s 937us/sample - loss: 0.8508 - acc: 0.9737 - val_loss: 1.0292 - val_acc: 0.9048\n",
      "Epoch 145/800\n",
      "114/114 [==============================] - 0s 886us/sample - loss: 0.8895 - acc: 0.9474 - val_loss: 0.9651 - val_acc: 0.9524\n",
      "Epoch 146/800\n",
      "114/114 [==============================] - 0s 877us/sample - loss: 0.8550 - acc: 0.9737 - val_loss: 0.9444 - val_acc: 0.9524\n",
      "Epoch 147/800\n",
      "114/114 [==============================] - 0s 961us/sample - loss: 0.8793 - acc: 0.9561 - val_loss: 0.9383 - val_acc: 0.9524\n",
      "Epoch 148/800\n",
      "114/114 [==============================] - 0s 895us/sample - loss: 0.8581 - acc: 0.9298 - val_loss: 0.9327 - val_acc: 0.9524\n",
      "Epoch 149/800\n",
      "114/114 [==============================] - 0s 892us/sample - loss: 0.8229 - acc: 0.9825 - val_loss: 0.9147 - val_acc: 0.9048\n",
      "Epoch 150/800\n",
      "114/114 [==============================] - 0s 934us/sample - loss: 0.8501 - acc: 0.9912 - val_loss: 0.9137 - val_acc: 0.9048\n",
      "Epoch 151/800\n",
      "114/114 [==============================] - 0s 895us/sample - loss: 0.8626 - acc: 0.9737 - val_loss: 0.9332 - val_acc: 0.9524\n",
      "Epoch 152/800\n",
      "114/114 [==============================] - 0s 890us/sample - loss: 0.8817 - acc: 0.9825 - val_loss: 0.9575 - val_acc: 0.9524\n",
      "Epoch 153/800\n",
      "114/114 [==============================] - 0s 913us/sample - loss: 0.8385 - acc: 0.9561 - val_loss: 1.0019 - val_acc: 0.8571\n",
      "Epoch 154/800\n",
      "114/114 [==============================] - 0s 947us/sample - loss: 0.8637 - acc: 0.9561 - val_loss: 0.9681 - val_acc: 0.9524\n",
      "Epoch 155/800\n",
      "114/114 [==============================] - 0s 906us/sample - loss: 0.8993 - acc: 0.9386 - val_loss: 0.9362 - val_acc: 0.9524\n",
      "Epoch 156/800\n",
      "114/114 [==============================] - 0s 885us/sample - loss: 0.8366 - acc: 0.9649 - val_loss: 0.9269 - val_acc: 0.9524\n",
      "Epoch 157/800\n",
      "114/114 [==============================] - 0s 882us/sample - loss: 0.8110 - acc: 0.9737 - val_loss: 0.9030 - val_acc: 0.9524\n",
      "Epoch 158/800\n",
      "114/114 [==============================] - 0s 960us/sample - loss: 0.8519 - acc: 0.9298 - val_loss: 0.8916 - val_acc: 0.9524\n",
      "Epoch 159/800\n",
      "114/114 [==============================] - 0s 869us/sample - loss: 0.8285 - acc: 0.9649 - val_loss: 0.9097 - val_acc: 0.9524\n",
      "Epoch 160/800\n",
      "114/114 [==============================] - 0s 897us/sample - loss: 0.8516 - acc: 0.9386 - val_loss: 0.9227 - val_acc: 0.9524\n",
      "Epoch 161/800\n",
      "114/114 [==============================] - 0s 889us/sample - loss: 0.8095 - acc: 0.9649 - val_loss: 0.9077 - val_acc: 0.9524\n",
      "Epoch 162/800\n",
      "114/114 [==============================] - 0s 2ms/sample - loss: 0.8250 - acc: 0.9561 - val_loss: 0.8872 - val_acc: 0.9048\n",
      "Epoch 163/800\n",
      "114/114 [==============================] - 0s 892us/sample - loss: 0.8186 - acc: 0.9649 - val_loss: 0.8818 - val_acc: 0.9048\n",
      "Epoch 164/800\n",
      "114/114 [==============================] - 0s 904us/sample - loss: 0.8273 - acc: 0.9649 - val_loss: 0.8787 - val_acc: 0.9048\n",
      "Epoch 165/800\n",
      "114/114 [==============================] - 0s 903us/sample - loss: 0.7947 - acc: 0.9737 - val_loss: 0.8860 - val_acc: 0.9048\n",
      "Epoch 166/800\n",
      "114/114 [==============================] - 0s 2ms/sample - loss: 0.7944 - acc: 0.9825 - val_loss: 0.9040 - val_acc: 0.9524\n",
      "Epoch 167/800\n",
      "114/114 [==============================] - 0s 907us/sample - loss: 0.7907 - acc: 0.9825 - val_loss: 0.9171 - val_acc: 0.9524\n",
      "Epoch 168/800\n",
      "114/114 [==============================] - 0s 894us/sample - loss: 0.7821 - acc: 0.9912 - val_loss: 0.9065 - val_acc: 0.9524\n",
      "Epoch 169/800\n",
      "114/114 [==============================] - 0s 896us/sample - loss: 0.7649 - acc: 1.0000 - val_loss: 0.8864 - val_acc: 0.9048\n",
      "Epoch 170/800\n",
      "114/114 [==============================] - 0s 2ms/sample - loss: 0.7671 - acc: 0.9912 - val_loss: 0.8830 - val_acc: 0.9048\n",
      "Epoch 171/800\n",
      "114/114 [==============================] - 0s 883us/sample - loss: 0.7901 - acc: 0.9825 - val_loss: 0.8818 - val_acc: 0.9048\n",
      "Epoch 172/800\n",
      "114/114 [==============================] - 0s 896us/sample - loss: 0.7846 - acc: 0.9649 - val_loss: 0.8776 - val_acc: 0.9048\n",
      "Epoch 173/800\n",
      "114/114 [==============================] - 0s 891us/sample - loss: 0.7841 - acc: 0.9737 - val_loss: 0.8787 - val_acc: 0.9048\n",
      "Epoch 174/800\n",
      "114/114 [==============================] - 0s 2ms/sample - loss: 0.7657 - acc: 0.9825 - val_loss: 0.8836 - val_acc: 0.9048\n",
      "Epoch 175/800\n",
      "114/114 [==============================] - 0s 895us/sample - loss: 0.8110 - acc: 0.9474 - val_loss: 0.9003 - val_acc: 0.9524\n",
      "Epoch 176/800\n",
      "114/114 [==============================] - 0s 896us/sample - loss: 0.7762 - acc: 0.9737 - val_loss: 0.9166 - val_acc: 0.9524\n",
      "Epoch 177/800\n",
      "114/114 [==============================] - 0s 895us/sample - loss: 0.7851 - acc: 0.9825 - val_loss: 0.9300 - val_acc: 0.9524\n",
      "Epoch 178/800\n",
      "114/114 [==============================] - 0s 2ms/sample - loss: 0.7665 - acc: 0.9737 - val_loss: 0.9285 - val_acc: 0.9524\n",
      "Epoch 179/800\n",
      "114/114 [==============================] - 0s 937us/sample - loss: 0.7510 - acc: 0.9912 - val_loss: 0.8972 - val_acc: 0.9524\n",
      "Epoch 180/800\n",
      "114/114 [==============================] - 0s 885us/sample - loss: 0.7499 - acc: 1.0000 - val_loss: 0.8932 - val_acc: 0.9048\n",
      "Epoch 181/800\n",
      "114/114 [==============================] - 0s 2ms/sample - loss: 0.7666 - acc: 0.9737 - val_loss: 0.8927 - val_acc: 0.9048\n",
      "Epoch 182/800\n",
      "114/114 [==============================] - 0s 907us/sample - loss: 0.7730 - acc: 0.9825 - val_loss: 0.8949 - val_acc: 0.9048\n",
      "Epoch 183/800\n",
      "114/114 [==============================] - 0s 904us/sample - loss: 0.7681 - acc: 0.9737 - val_loss: 0.8964 - val_acc: 0.9048\n",
      "Epoch 184/800\n",
      "114/114 [==============================] - 0s 883us/sample - loss: 0.7726 - acc: 0.9737 - val_loss: 0.8999 - val_acc: 0.9048\n",
      "Epoch 185/800\n",
      "114/114 [==============================] - 0s 2ms/sample - loss: 0.7509 - acc: 0.9825 - val_loss: 0.9022 - val_acc: 0.9048\n",
      "Epoch 186/800\n",
      "114/114 [==============================] - 0s 911us/sample - loss: 0.7621 - acc: 0.9825 - val_loss: 0.9063 - val_acc: 0.9048\n",
      "Epoch 187/800\n",
      "114/114 [==============================] - 0s 896us/sample - loss: 0.7688 - acc: 0.9737 - val_loss: 0.9079 - val_acc: 0.9048\n",
      "Epoch 188/800\n",
      "114/114 [==============================] - 0s 892us/sample - loss: 0.7424 - acc: 0.9912 - val_loss: 0.9048 - val_acc: 0.9048\n",
      "Epoch 189/800\n",
      "114/114 [==============================] - 0s 2ms/sample - loss: 0.7417 - acc: 0.9912 - val_loss: 0.9105 - val_acc: 0.9048\n",
      "Epoch 190/800\n",
      "114/114 [==============================] - 0s 904us/sample - loss: 0.7719 - acc: 0.9737 - val_loss: 0.9127 - val_acc: 0.9048\n",
      "Epoch 191/800\n",
      "114/114 [==============================] - 0s 900us/sample - loss: 0.7473 - acc: 0.9825 - val_loss: 0.9070 - val_acc: 0.9048\n",
      "Epoch 192/800\n",
      "114/114 [==============================] - 0s 884us/sample - loss: 0.7909 - acc: 0.9561 - val_loss: 0.9110 - val_acc: 0.9048\n",
      "Epoch 193/800\n",
      "114/114 [==============================] - 0s 2ms/sample - loss: 0.7992 - acc: 0.9561 - val_loss: 0.9016 - val_acc: 0.9048\n",
      "Epoch 194/800\n",
      "114/114 [==============================] - 0s 898us/sample - loss: 0.7469 - acc: 0.9825 - val_loss: 0.8933 - val_acc: 0.9048\n",
      "Epoch 195/800\n",
      "114/114 [==============================] - 0s 895us/sample - loss: 0.7757 - acc: 0.9737 - val_loss: 0.8909 - val_acc: 0.9048\n",
      "Epoch 196/800\n",
      "114/114 [==============================] - 0s 887us/sample - loss: 0.7496 - acc: 0.9737 - val_loss: 0.8961 - val_acc: 0.9048\n",
      "Epoch 197/800\n",
      "114/114 [==============================] - 0s 2ms/sample - loss: 0.7433 - acc: 0.9825 - val_loss: 0.8940 - val_acc: 0.9048\n",
      "Epoch 198/800\n",
      "114/114 [==============================] - 0s 946us/sample - loss: 0.7535 - acc: 0.9737 - val_loss: 0.8971 - val_acc: 0.9048\n",
      "Epoch 199/800\n",
      "114/114 [==============================] - 0s 917us/sample - loss: 0.7491 - acc: 0.9825 - val_loss: 0.9028 - val_acc: 0.9048\n",
      "Epoch 200/800\n",
      "114/114 [==============================] - 0s 875us/sample - loss: 0.7162 - acc: 1.0000 - val_loss: 0.9084 - val_acc: 0.9048\n",
      "Epoch 201/800\n",
      "114/114 [==============================] - 0s 2ms/sample - loss: 0.7657 - acc: 0.9737 - val_loss: 0.9113 - val_acc: 0.9048\n",
      "Epoch 202/800\n",
      "114/114 [==============================] - 0s 930us/sample - loss: 0.7576 - acc: 0.9649 - val_loss: 0.9147 - val_acc: 0.9048\n",
      "Epoch 203/800\n",
      "114/114 [==============================] - 0s 887us/sample - loss: 0.7390 - acc: 0.9825 - val_loss: 0.9189 - val_acc: 0.9048\n",
      "Epoch 204/800\n",
      "114/114 [==============================] - 0s 901us/sample - loss: 0.7409 - acc: 0.9825 - val_loss: 0.9224 - val_acc: 0.9048\n",
      "Epoch 205/800\n",
      "114/114 [==============================] - 0s 884us/sample - loss: 0.7466 - acc: 0.9649 - val_loss: 0.9214 - val_acc: 0.9048\n",
      "Epoch 206/800\n",
      "114/114 [==============================] - 0s 2ms/sample - loss: 0.7642 - acc: 0.9737 - val_loss: 0.9185 - val_acc: 0.9048\n",
      "Epoch 207/800\n",
      "114/114 [==============================] - 0s 908us/sample - loss: 0.7556 - acc: 0.9561 - val_loss: 0.9147 - val_acc: 0.9048\n",
      "Epoch 208/800\n",
      "114/114 [==============================] - 0s 897us/sample - loss: 0.7484 - acc: 0.9737 - val_loss: 0.9212 - val_acc: 0.9048\n",
      "Epoch 209/800\n",
      "114/114 [==============================] - 0s 878us/sample - loss: 0.7242 - acc: 0.9825 - val_loss: 0.9358 - val_acc: 0.9048\n",
      "Epoch 210/800\n",
      "114/114 [==============================] - 0s 930us/sample - loss: 0.7763 - acc: 0.9649 - val_loss: 0.9429 - val_acc: 0.9048\n",
      "Epoch 211/800\n",
      "114/114 [==============================] - 0s 895us/sample - loss: 0.7201 - acc: 0.9912 - val_loss: 0.9322 - val_acc: 0.9048\n",
      "Epoch 212/800\n",
      "114/114 [==============================] - 0s 899us/sample - loss: 0.7060 - acc: 1.0000 - val_loss: 0.9258 - val_acc: 0.9048\n",
      "Epoch 213/800\n",
      "114/114 [==============================] - 0s 891us/sample - loss: 0.7084 - acc: 0.9912 - val_loss: 0.9269 - val_acc: 0.9048\n",
      "Epoch 214/800\n",
      "114/114 [==============================] - 0s 2ms/sample - loss: 0.7318 - acc: 0.9825 - val_loss: 0.9370 - val_acc: 0.9048\n",
      "Epoch 215/800\n",
      "114/114 [==============================] - 0s 868us/sample - loss: 0.7122 - acc: 0.9912 - val_loss: 0.9498 - val_acc: 0.9048\n",
      "Epoch 216/800\n",
      "114/114 [==============================] - 0s 913us/sample - loss: 0.7320 - acc: 0.9825 - val_loss: 0.9545 - val_acc: 0.9048\n",
      "Epoch 217/800\n",
      "114/114 [==============================] - 0s 888us/sample - loss: 0.7299 - acc: 0.9912 - val_loss: 0.9570 - val_acc: 0.9048\n",
      "Epoch 218/800\n",
      "114/114 [==============================] - 0s 929us/sample - loss: 0.7139 - acc: 0.9912 - val_loss: 0.9608 - val_acc: 0.9048\n",
      "Epoch 219/800\n",
      "114/114 [==============================] - 0s 897us/sample - loss: 0.7529 - acc: 0.9737 - val_loss: 0.9616 - val_acc: 0.9048\n",
      "Epoch 220/800\n",
      "114/114 [==============================] - 0s 900us/sample - loss: 0.7179 - acc: 0.9912 - val_loss: 0.9651 - val_acc: 0.9048\n",
      "Epoch 221/800\n",
      "114/114 [==============================] - 0s 890us/sample - loss: 0.7678 - acc: 0.9561 - val_loss: 0.9601 - val_acc: 0.9048\n",
      "Epoch 222/800\n",
      "114/114 [==============================] - 0s 2ms/sample - loss: 0.7836 - acc: 0.9649 - val_loss: 0.9173 - val_acc: 0.9048\n",
      "Epoch 223/800\n",
      "114/114 [==============================] - 0s 892us/sample - loss: 0.7379 - acc: 0.9825 - val_loss: 0.9012 - val_acc: 0.9524\n",
      "Epoch 224/800\n",
      "114/114 [==============================] - 0s 938us/sample - loss: 0.7161 - acc: 0.9825 - val_loss: 0.8979 - val_acc: 0.9524\n",
      "Epoch 225/800\n",
      "114/114 [==============================] - 0s 890us/sample - loss: 0.7258 - acc: 0.9825 - val_loss: 0.8979 - val_acc: 0.9524\n",
      "Epoch 226/800\n",
      "114/114 [==============================] - 0s 873us/sample - loss: 0.7463 - acc: 0.9737 - val_loss: 0.9080 - val_acc: 0.9048\n",
      "Epoch 227/800\n",
      "114/114 [==============================] - 0s 956us/sample - loss: 0.6991 - acc: 1.0000 - val_loss: 0.9265 - val_acc: 0.9048\n",
      "Epoch 228/800\n",
      "114/114 [==============================] - 0s 870us/sample - loss: 0.7400 - acc: 0.9561 - val_loss: 0.9330 - val_acc: 0.9048\n",
      "Epoch 229/800\n",
      "114/114 [==============================] - 0s 900us/sample - loss: 0.6998 - acc: 0.9912 - val_loss: 0.9195 - val_acc: 0.9048\n",
      "Epoch 230/800\n",
      "114/114 [==============================] - 0s 886us/sample - loss: 0.7350 - acc: 0.9825 - val_loss: 0.9034 - val_acc: 0.9048\n",
      "Epoch 231/800\n",
      "114/114 [==============================] - 0s 2ms/sample - loss: 0.7477 - acc: 0.9737 - val_loss: 0.9126 - val_acc: 0.9048\n",
      "Epoch 232/800\n",
      "114/114 [==============================] - 0s 906us/sample - loss: 0.7006 - acc: 0.9912 - val_loss: 0.9383 - val_acc: 0.9048\n",
      "Epoch 233/800\n",
      "114/114 [==============================] - 0s 904us/sample - loss: 0.7022 - acc: 0.9912 - val_loss: 0.9455 - val_acc: 0.9048\n",
      "Epoch 234/800\n",
      "114/114 [==============================] - 0s 888us/sample - loss: 0.7069 - acc: 0.9912 - val_loss: 0.9219 - val_acc: 0.9048\n",
      "Epoch 235/800\n",
      "114/114 [==============================] - 0s 2ms/sample - loss: 0.6942 - acc: 0.9912 - val_loss: 0.9017 - val_acc: 0.9524\n",
      "Epoch 236/800\n",
      "114/114 [==============================] - 0s 894us/sample - loss: 0.7116 - acc: 0.9912 - val_loss: 0.9208 - val_acc: 0.9048\n",
      "Epoch 237/800\n",
      "114/114 [==============================] - 0s 894us/sample - loss: 0.7153 - acc: 0.9825 - val_loss: 0.9528 - val_acc: 0.9048\n",
      "Epoch 238/800\n",
      "114/114 [==============================] - 0s 894us/sample - loss: 0.7022 - acc: 0.9912 - val_loss: 0.9592 - val_acc: 0.9048\n",
      "Epoch 239/800\n",
      "114/114 [==============================] - 0s 2ms/sample - loss: 0.7017 - acc: 0.9825 - val_loss: 0.9367 - val_acc: 0.9048\n",
      "Epoch 240/800\n",
      "114/114 [==============================] - 0s 936us/sample - loss: 0.7178 - acc: 0.9825 - val_loss: 0.9175 - val_acc: 0.9048\n",
      "Epoch 241/800\n",
      "114/114 [==============================] - 0s 869us/sample - loss: 0.7088 - acc: 0.9825 - val_loss: 0.9218 - val_acc: 0.9048\n",
      "Epoch 242/800\n",
      "114/114 [==============================] - 0s 892us/sample - loss: 0.7303 - acc: 0.9912 - val_loss: 0.9510 - val_acc: 0.9048\n",
      "Epoch 243/800\n",
      "114/114 [==============================] - 0s 897us/sample - loss: 0.7152 - acc: 0.9912 - val_loss: 0.9799 - val_acc: 0.9048\n",
      "Epoch 244/800\n",
      "114/114 [==============================] - 0s 2ms/sample - loss: 0.7072 - acc: 0.9825 - val_loss: 0.9751 - val_acc: 0.9048\n",
      "Epoch 245/800\n",
      "114/114 [==============================] - 0s 910us/sample - loss: 0.7070 - acc: 0.9825 - val_loss: 0.9898 - val_acc: 0.9048\n",
      "Epoch 246/800\n",
      "114/114 [==============================] - 0s 872us/sample - loss: 0.6914 - acc: 0.9912 - val_loss: 0.9890 - val_acc: 0.9048\n",
      "Epoch 247/800\n",
      "114/114 [==============================] - 0s 894us/sample - loss: 0.7015 - acc: 0.9912 - val_loss: 0.9851 - val_acc: 0.9048\n",
      "Epoch 248/800\n",
      "114/114 [==============================] - 0s 925us/sample - loss: 0.7023 - acc: 0.9737 - val_loss: 0.9859 - val_acc: 0.9048\n",
      "Epoch 249/800\n",
      "114/114 [==============================] - 0s 2ms/sample - loss: 0.7043 - acc: 0.9737 - val_loss: 0.9628 - val_acc: 0.9048\n",
      "Epoch 250/800\n",
      "114/114 [==============================] - 0s 900us/sample - loss: 0.7271 - acc: 0.9825 - val_loss: 0.9404 - val_acc: 0.9048\n",
      "Epoch 251/800\n",
      "114/114 [==============================] - 0s 884us/sample - loss: 0.6883 - acc: 0.9912 - val_loss: 0.9364 - val_acc: 0.9048\n",
      "Epoch 252/800\n",
      "114/114 [==============================] - 0s 2ms/sample - loss: 0.7171 - acc: 0.9737 - val_loss: 0.9785 - val_acc: 0.9048\n",
      "Epoch 253/800\n",
      "114/114 [==============================] - 0s 912us/sample - loss: 0.7518 - acc: 0.9737 - val_loss: 0.9946 - val_acc: 0.9048\n",
      "Epoch 254/800\n",
      "114/114 [==============================] - 0s 882us/sample - loss: 0.7896 - acc: 0.9737 - val_loss: 0.9894 - val_acc: 0.9048\n",
      "Epoch 255/800\n",
      "114/114 [==============================] - 0s 892us/sample - loss: 0.7235 - acc: 0.9737 - val_loss: 0.9009 - val_acc: 0.9524\n",
      "Epoch 256/800\n",
      "114/114 [==============================] - 0s 882us/sample - loss: 0.7182 - acc: 0.9825 - val_loss: 0.9109 - val_acc: 0.9524\n",
      "Epoch 257/800\n",
      "114/114 [==============================] - 0s 937us/sample - loss: 0.7654 - acc: 0.9737 - val_loss: 0.9092 - val_acc: 0.9524\n",
      "Epoch 258/800\n",
      "114/114 [==============================] - 0s 898us/sample - loss: 0.7277 - acc: 0.9737 - val_loss: 0.9224 - val_acc: 0.9048\n",
      "Epoch 259/800\n",
      "114/114 [==============================] - 0s 889us/sample - loss: 0.7120 - acc: 0.9737 - val_loss: 0.9550 - val_acc: 0.9048\n",
      "Epoch 260/800\n",
      "114/114 [==============================] - 0s 2ms/sample - loss: 0.7146 - acc: 0.9737 - val_loss: 0.9523 - val_acc: 0.9048\n",
      "Epoch 261/800\n",
      "114/114 [==============================] - 0s 887us/sample - loss: 0.6995 - acc: 0.9825 - val_loss: 0.9264 - val_acc: 0.9048\n",
      "Epoch 262/800\n",
      "114/114 [==============================] - 0s 916us/sample - loss: 0.7307 - acc: 0.9737 - val_loss: 0.9097 - val_acc: 0.9524\n",
      "Epoch 263/800\n",
      "114/114 [==============================] - 0s 891us/sample - loss: 0.7538 - acc: 0.9737 - val_loss: 0.9171 - val_acc: 0.9524\n",
      "Epoch 264/800\n",
      "114/114 [==============================] - 0s 885us/sample - loss: 0.6868 - acc: 0.9825 - val_loss: 0.9218 - val_acc: 0.9048\n",
      "Epoch 265/800\n",
      "114/114 [==============================] - 0s 929us/sample - loss: 0.7257 - acc: 0.9825 - val_loss: 0.9265 - val_acc: 0.9048\n",
      "Epoch 266/800\n",
      "114/114 [==============================] - 0s 924us/sample - loss: 0.6888 - acc: 0.9912 - val_loss: 0.9523 - val_acc: 0.9048\n",
      "Epoch 267/800\n",
      "114/114 [==============================] - 0s 891us/sample - loss: 0.6800 - acc: 0.9912 - val_loss: 0.9540 - val_acc: 0.9048\n",
      "Epoch 268/800\n",
      "114/114 [==============================] - 0s 2ms/sample - loss: 0.7054 - acc: 0.9912 - val_loss: 0.9488 - val_acc: 0.9048\n",
      "Epoch 269/800\n",
      "114/114 [==============================] - 0s 932us/sample - loss: 0.7133 - acc: 0.9825 - val_loss: 0.9626 - val_acc: 0.9048\n",
      "Epoch 270/800\n",
      "114/114 [==============================] - 0s 900us/sample - loss: 0.6850 - acc: 0.9912 - val_loss: 0.9505 - val_acc: 0.9048\n",
      "Epoch 271/800\n",
      "114/114 [==============================] - 0s 889us/sample - loss: 0.6958 - acc: 0.9825 - val_loss: 0.9205 - val_acc: 0.9048\n",
      "Epoch 272/800\n",
      "114/114 [==============================] - 0s 2ms/sample - loss: 0.6772 - acc: 0.9912 - val_loss: 0.9171 - val_acc: 0.9048\n",
      "Epoch 273/800\n",
      "114/114 [==============================] - 0s 932us/sample - loss: 0.6715 - acc: 1.0000 - val_loss: 0.9014 - val_acc: 0.9524\n",
      "Epoch 274/800\n",
      "114/114 [==============================] - 0s 901us/sample - loss: 0.6921 - acc: 0.9912 - val_loss: 0.9034 - val_acc: 0.9048\n",
      "Epoch 275/800\n",
      "114/114 [==============================] - 0s 890us/sample - loss: 0.7000 - acc: 0.9825 - val_loss: 0.9043 - val_acc: 0.9048\n",
      "Epoch 276/800\n",
      "114/114 [==============================] - 0s 2ms/sample - loss: 0.7126 - acc: 0.9649 - val_loss: 0.8848 - val_acc: 0.9524\n",
      "Epoch 277/800\n",
      "114/114 [==============================] - 0s 929us/sample - loss: 0.7558 - acc: 0.9561 - val_loss: 0.8936 - val_acc: 0.9524\n",
      "Epoch 278/800\n",
      "114/114 [==============================] - 0s 893us/sample - loss: 0.7115 - acc: 0.9737 - val_loss: 0.8858 - val_acc: 0.9524\n",
      "Epoch 279/800\n",
      "114/114 [==============================] - 0s 909us/sample - loss: 0.6999 - acc: 0.9649 - val_loss: 0.8861 - val_acc: 0.9524\n",
      "Epoch 280/800\n",
      "114/114 [==============================] - 0s 896us/sample - loss: 0.6616 - acc: 1.0000 - val_loss: 0.9195 - val_acc: 0.9048\n",
      "Epoch 281/800\n",
      "114/114 [==============================] - 0s 959us/sample - loss: 0.6790 - acc: 0.9825 - val_loss: 0.9417 - val_acc: 0.9048\n",
      "Epoch 282/800\n",
      "114/114 [==============================] - 0s 898us/sample - loss: 0.6887 - acc: 0.9825 - val_loss: 0.9370 - val_acc: 0.9048\n",
      "Epoch 283/800\n",
      "114/114 [==============================] - 0s 888us/sample - loss: 0.6730 - acc: 0.9912 - val_loss: 0.9149 - val_acc: 0.9048\n",
      "Epoch 284/800\n",
      "114/114 [==============================] - 0s 2ms/sample - loss: 0.6765 - acc: 0.9825 - val_loss: 0.8935 - val_acc: 0.9048\n",
      "Epoch 285/800\n",
      "114/114 [==============================] - 0s 975us/sample - loss: 0.6816 - acc: 0.9825 - val_loss: 0.8872 - val_acc: 0.9048\n",
      "Epoch 286/800\n",
      "114/114 [==============================] - 0s 872us/sample - loss: 0.7183 - acc: 0.9737 - val_loss: 0.8866 - val_acc: 0.9048\n",
      "Epoch 287/800\n",
      "114/114 [==============================] - 0s 892us/sample - loss: 0.6764 - acc: 0.9912 - val_loss: 0.8902 - val_acc: 0.9048\n",
      "Epoch 288/800\n",
      "114/114 [==============================] - 0s 2ms/sample - loss: 0.6768 - acc: 0.9825 - val_loss: 0.8931 - val_acc: 0.9048\n",
      "Epoch 289/800\n",
      "114/114 [==============================] - 0s 940us/sample - loss: 0.6942 - acc: 0.9737 - val_loss: 0.8923 - val_acc: 0.9048\n",
      "Epoch 290/800\n",
      "114/114 [==============================] - 0s 903us/sample - loss: 0.6584 - acc: 1.0000 - val_loss: 0.9037 - val_acc: 0.9048\n",
      "Epoch 291/800\n",
      "114/114 [==============================] - 0s 887us/sample - loss: 0.7132 - acc: 0.9737 - val_loss: 0.9281 - val_acc: 0.9048\n",
      "Epoch 292/800\n",
      "114/114 [==============================] - 0s 2ms/sample - loss: 0.6812 - acc: 0.9825 - val_loss: 0.8842 - val_acc: 0.9524\n",
      "Epoch 293/800\n",
      "114/114 [==============================] - 0s 894us/sample - loss: 0.6686 - acc: 0.9912 - val_loss: 0.8905 - val_acc: 0.9524\n",
      "Epoch 294/800\n",
      "114/114 [==============================] - 0s 882us/sample - loss: 0.6824 - acc: 0.9825 - val_loss: 0.8951 - val_acc: 0.9524\n",
      "Epoch 295/800\n",
      "114/114 [==============================] - 0s 904us/sample - loss: 0.6684 - acc: 0.9912 - val_loss: 0.9030 - val_acc: 0.9048\n",
      "Epoch 296/800\n",
      "114/114 [==============================] - 0s 2ms/sample - loss: 0.6647 - acc: 0.9912 - val_loss: 0.9348 - val_acc: 0.9048\n",
      "Epoch 297/800\n",
      "114/114 [==============================] - 0s 936us/sample - loss: 0.6863 - acc: 0.9737 - val_loss: 0.9951 - val_acc: 0.9048\n",
      "Epoch 298/800\n",
      "114/114 [==============================] - 0s 893us/sample - loss: 0.6699 - acc: 0.9912 - val_loss: 0.9996 - val_acc: 0.9048\n",
      "Epoch 299/800\n",
      "114/114 [==============================] - 0s 874us/sample - loss: 0.6803 - acc: 0.9825 - val_loss: 0.9681 - val_acc: 0.9048\n",
      "Epoch 300/800\n",
      "114/114 [==============================] - 0s 2ms/sample - loss: 0.6720 - acc: 0.9912 - val_loss: 0.9381 - val_acc: 0.9048\n",
      "Epoch 301/800\n",
      "114/114 [==============================] - 0s 926us/sample - loss: 0.6863 - acc: 0.9825 - val_loss: 0.9226 - val_acc: 0.9524\n",
      "Epoch 302/800\n",
      "114/114 [==============================] - 0s 897us/sample - loss: 0.6600 - acc: 0.9912 - val_loss: 0.9224 - val_acc: 0.9524\n",
      "Epoch 303/800\n",
      "114/114 [==============================] - 0s 892us/sample - loss: 0.6742 - acc: 0.9737 - val_loss: 0.9289 - val_acc: 0.9048\n",
      "Epoch 304/800\n",
      "114/114 [==============================] - 0s 2ms/sample - loss: 0.6903 - acc: 0.9737 - val_loss: 0.9393 - val_acc: 0.9048\n",
      "Epoch 305/800\n",
      "114/114 [==============================] - 0s 892us/sample - loss: 0.6612 - acc: 0.9912 - val_loss: 0.9514 - val_acc: 0.9048\n",
      "Epoch 306/800\n",
      "114/114 [==============================] - 0s 898us/sample - loss: 0.6828 - acc: 0.9912 - val_loss: 0.9649 - val_acc: 0.9048\n",
      "Epoch 307/800\n",
      "114/114 [==============================] - 0s 888us/sample - loss: 0.7205 - acc: 0.9737 - val_loss: 0.9551 - val_acc: 0.9048\n",
      "Epoch 308/800\n",
      "114/114 [==============================] - 0s 2ms/sample - loss: 0.7220 - acc: 0.9649 - val_loss: 0.9580 - val_acc: 0.9048\n",
      "Epoch 309/800\n",
      "114/114 [==============================] - 0s 904us/sample - loss: 0.6690 - acc: 0.9825 - val_loss: 0.9784 - val_acc: 0.9048\n",
      "Epoch 310/800\n",
      "114/114 [==============================] - 0s 894us/sample - loss: 0.6513 - acc: 1.0000 - val_loss: 0.9706 - val_acc: 0.9048\n",
      "Epoch 311/800\n",
      "114/114 [==============================] - 0s 888us/sample - loss: 0.6713 - acc: 0.9912 - val_loss: 0.9737 - val_acc: 0.9048\n",
      "Epoch 312/800\n",
      "114/114 [==============================] - 0s 2ms/sample - loss: 0.6508 - acc: 1.0000 - val_loss: 0.9847 - val_acc: 0.9048\n",
      "Epoch 313/800\n",
      "114/114 [==============================] - 0s 899us/sample - loss: 0.6665 - acc: 0.9912 - val_loss: 0.9878 - val_acc: 0.9048\n",
      "Epoch 314/800\n",
      "114/114 [==============================] - 0s 895us/sample - loss: 0.6676 - acc: 0.9825 - val_loss: 0.9902 - val_acc: 0.9048\n",
      "Epoch 315/800\n",
      "114/114 [==============================] - 0s 880us/sample - loss: 0.6960 - acc: 0.9912 - val_loss: 1.0036 - val_acc: 0.9048\n",
      "Epoch 316/800\n",
      "114/114 [==============================] - 0s 2ms/sample - loss: 0.7265 - acc: 0.9737 - val_loss: 0.9794 - val_acc: 0.9048\n",
      "Epoch 317/800\n",
      "114/114 [==============================] - 0s 2ms/sample - loss: 0.6624 - acc: 0.9912 - val_loss: 0.9401 - val_acc: 0.9048\n",
      "Epoch 318/800\n",
      "114/114 [==============================] - 0s 899us/sample - loss: 0.6511 - acc: 0.9912 - val_loss: 0.9284 - val_acc: 0.9048\n",
      "Epoch 319/800\n",
      "114/114 [==============================] - 0s 891us/sample - loss: 0.6574 - acc: 0.9912 - val_loss: 0.9247 - val_acc: 0.9048\n",
      "Epoch 320/800\n",
      "114/114 [==============================] - 0s 2ms/sample - loss: 0.6570 - acc: 0.9912 - val_loss: 0.9446 - val_acc: 0.9048\n",
      "Epoch 321/800\n",
      "114/114 [==============================] - 0s 928us/sample - loss: 0.6559 - acc: 0.9825 - val_loss: 0.9566 - val_acc: 0.9048\n",
      "Epoch 322/800\n",
      "114/114 [==============================] - 0s 871us/sample - loss: 0.6571 - acc: 0.9825 - val_loss: 0.9633 - val_acc: 0.9048\n",
      "Epoch 323/800\n",
      "114/114 [==============================] - 0s 915us/sample - loss: 0.6581 - acc: 0.9912 - val_loss: 0.9436 - val_acc: 0.9048\n",
      "Epoch 324/800\n",
      "114/114 [==============================] - 0s 867us/sample - loss: 0.6456 - acc: 0.9912 - val_loss: 0.9405 - val_acc: 0.9048\n",
      "Epoch 325/800\n",
      "114/114 [==============================] - 0s 2ms/sample - loss: 0.6735 - acc: 0.9825 - val_loss: 0.9381 - val_acc: 0.9048\n",
      "Epoch 326/800\n",
      "114/114 [==============================] - 0s 909us/sample - loss: 0.6418 - acc: 1.0000 - val_loss: 0.9192 - val_acc: 0.9524\n",
      "Epoch 327/800\n",
      "114/114 [==============================] - 0s 895us/sample - loss: 0.6657 - acc: 0.9737 - val_loss: 0.9218 - val_acc: 0.9524\n",
      "Epoch 328/800\n",
      "114/114 [==============================] - 0s 888us/sample - loss: 0.6824 - acc: 0.9825 - val_loss: 0.9247 - val_acc: 0.9524\n",
      "Epoch 329/800\n",
      "114/114 [==============================] - 0s 875us/sample - loss: 0.6815 - acc: 0.9825 - val_loss: 0.9803 - val_acc: 0.9048\n",
      "Epoch 330/800\n",
      "114/114 [==============================] - 0s 932us/sample - loss: 0.6476 - acc: 0.9912 - val_loss: 1.0214 - val_acc: 0.9048\n",
      "Epoch 331/800\n",
      "114/114 [==============================] - 0s 895us/sample - loss: 0.7006 - acc: 0.9649 - val_loss: 1.0291 - val_acc: 0.9048\n",
      "Epoch 332/800\n",
      "114/114 [==============================] - 0s 915us/sample - loss: 0.6412 - acc: 1.0000 - val_loss: 1.0070 - val_acc: 0.9048\n",
      "Epoch 333/800\n",
      "114/114 [==============================] - 0s 874us/sample - loss: 0.6761 - acc: 0.9825 - val_loss: 0.9583 - val_acc: 0.9048\n",
      "Epoch 334/800\n",
      "114/114 [==============================] - 0s 934us/sample - loss: 0.6306 - acc: 1.0000 - val_loss: 0.9109 - val_acc: 0.9524\n",
      "Epoch 335/800\n",
      "114/114 [==============================] - 0s 922us/sample - loss: 0.6317 - acc: 1.0000 - val_loss: 0.9134 - val_acc: 0.9524\n",
      "Epoch 336/800\n",
      "114/114 [==============================] - 0s 889us/sample - loss: 0.6846 - acc: 0.9561 - val_loss: 0.9065 - val_acc: 0.9524\n",
      "Epoch 337/800\n",
      "114/114 [==============================] - 0s 2ms/sample - loss: 0.6399 - acc: 0.9912 - val_loss: 0.9320 - val_acc: 0.9048\n",
      "Epoch 338/800\n",
      "114/114 [==============================] - 0s 936us/sample - loss: 0.6541 - acc: 0.9912 - val_loss: 0.9456 - val_acc: 0.9048\n",
      "Epoch 339/800\n",
      "114/114 [==============================] - 0s 900us/sample - loss: 0.6448 - acc: 0.9912 - val_loss: 0.9442 - val_acc: 0.9048\n",
      "Epoch 340/800\n",
      "114/114 [==============================] - 0s 896us/sample - loss: 0.6539 - acc: 0.9825 - val_loss: 0.9208 - val_acc: 0.9048\n",
      "Epoch 341/800\n",
      "114/114 [==============================] - 0s 2ms/sample - loss: 0.6457 - acc: 0.9912 - val_loss: 0.9030 - val_acc: 0.9524\n",
      "Epoch 342/800\n",
      "114/114 [==============================] - 0s 924us/sample - loss: 0.6779 - acc: 0.9825 - val_loss: 0.8997 - val_acc: 0.9524\n",
      "Epoch 343/800\n",
      "114/114 [==============================] - 0s 904us/sample - loss: 0.6798 - acc: 0.9649 - val_loss: 0.8963 - val_acc: 0.9524\n",
      "Epoch 344/800\n",
      "114/114 [==============================] - 0s 898us/sample - loss: 0.6838 - acc: 0.9737 - val_loss: 0.9070 - val_acc: 0.9524\n",
      "Epoch 345/800\n",
      "114/114 [==============================] - 0s 874us/sample - loss: 0.6664 - acc: 0.9825 - val_loss: 0.9131 - val_acc: 0.9524\n",
      "Epoch 346/800\n",
      "114/114 [==============================] - 0s 2ms/sample - loss: 0.7167 - acc: 0.9649 - val_loss: 0.8978 - val_acc: 0.9524\n",
      "Epoch 347/800\n",
      "114/114 [==============================] - 0s 928us/sample - loss: 0.6998 - acc: 0.9649 - val_loss: 0.9299 - val_acc: 0.9048\n",
      "Epoch 348/800\n",
      "114/114 [==============================] - 0s 894us/sample - loss: 0.6589 - acc: 0.9912 - val_loss: 0.9299 - val_acc: 0.9048\n",
      "Epoch 349/800\n",
      "114/114 [==============================] - 0s 872us/sample - loss: 0.6435 - acc: 0.9825 - val_loss: 0.8929 - val_acc: 0.9048\n",
      "Epoch 350/800\n",
      "114/114 [==============================] - 0s 932us/sample - loss: 0.6459 - acc: 0.9825 - val_loss: 0.8871 - val_acc: 0.9524\n",
      "Epoch 351/800\n",
      "114/114 [==============================] - 0s 891us/sample - loss: 0.6515 - acc: 0.9912 - val_loss: 0.8898 - val_acc: 0.9524\n",
      "Epoch 352/800\n",
      "114/114 [==============================] - 0s 898us/sample - loss: 0.6583 - acc: 0.9912 - val_loss: 0.9239 - val_acc: 0.9048\n",
      "Epoch 353/800\n",
      "114/114 [==============================] - 0s 893us/sample - loss: 0.6366 - acc: 0.9912 - val_loss: 0.9428 - val_acc: 0.9048\n",
      "Epoch 354/800\n",
      "114/114 [==============================] - 0s 2ms/sample - loss: 0.6511 - acc: 0.9912 - val_loss: 0.9408 - val_acc: 0.9048\n",
      "Epoch 355/800\n",
      "114/114 [==============================] - 0s 913us/sample - loss: 0.6771 - acc: 0.9561 - val_loss: 0.9169 - val_acc: 0.9048\n",
      "Epoch 356/800\n",
      "114/114 [==============================] - 0s 882us/sample - loss: 0.6253 - acc: 1.0000 - val_loss: 0.9108 - val_acc: 0.9524\n",
      "Epoch 357/800\n",
      "114/114 [==============================] - 0s 2ms/sample - loss: 0.6412 - acc: 0.9912 - val_loss: 0.9168 - val_acc: 0.9524\n",
      "Epoch 358/800\n",
      "114/114 [==============================] - 0s 919us/sample - loss: 0.6905 - acc: 0.9825 - val_loss: 0.9236 - val_acc: 0.9524\n",
      "Epoch 359/800\n",
      "114/114 [==============================] - 0s 868us/sample - loss: 0.6361 - acc: 0.9912 - val_loss: 0.9346 - val_acc: 0.9524\n",
      "Epoch 360/800\n",
      "114/114 [==============================] - 0s 917us/sample - loss: 0.6875 - acc: 0.9649 - val_loss: 0.9189 - val_acc: 0.9524\n",
      "Epoch 361/800\n",
      "114/114 [==============================] - 0s 885us/sample - loss: 0.6259 - acc: 0.9912 - val_loss: 0.9380 - val_acc: 0.9048\n",
      "Epoch 362/800\n",
      "114/114 [==============================] - 0s 2ms/sample - loss: 0.6588 - acc: 0.9737 - val_loss: 1.0152 - val_acc: 0.9048\n",
      "Epoch 363/800\n",
      "114/114 [==============================] - 0s 923us/sample - loss: 0.6300 - acc: 1.0000 - val_loss: 1.0279 - val_acc: 0.9048\n",
      "Epoch 364/800\n",
      "114/114 [==============================] - 0s 882us/sample - loss: 0.6342 - acc: 0.9912 - val_loss: 1.0259 - val_acc: 0.9048\n",
      "Epoch 365/800\n",
      "114/114 [==============================] - 0s 882us/sample - loss: 0.6799 - acc: 0.9825 - val_loss: 0.9837 - val_acc: 0.9048\n",
      "Epoch 366/800\n",
      "114/114 [==============================] - 0s 944us/sample - loss: 0.6293 - acc: 0.9912 - val_loss: 0.9247 - val_acc: 0.9048\n",
      "Epoch 367/800\n",
      "114/114 [==============================] - 0s 902us/sample - loss: 0.6414 - acc: 0.9737 - val_loss: 0.9222 - val_acc: 0.9524\n",
      "Epoch 368/800\n",
      "114/114 [==============================] - 0s 875us/sample - loss: 0.6390 - acc: 0.9825 - val_loss: 0.9243 - val_acc: 0.9524\n",
      "Epoch 369/800\n",
      "114/114 [==============================] - 0s 892us/sample - loss: 0.6507 - acc: 0.9825 - val_loss: 0.9202 - val_acc: 0.9524\n",
      "Epoch 370/800\n",
      "114/114 [==============================] - 0s 931us/sample - loss: 0.6541 - acc: 0.9825 - val_loss: 0.9458 - val_acc: 0.9048\n",
      "Epoch 371/800\n",
      "114/114 [==============================] - 0s 893us/sample - loss: 0.6332 - acc: 0.9912 - val_loss: 0.9958 - val_acc: 0.9048\n",
      "Epoch 372/800\n",
      "114/114 [==============================] - 0s 895us/sample - loss: 0.6245 - acc: 0.9912 - val_loss: 1.0173 - val_acc: 0.9048\n",
      "Epoch 373/800\n",
      "114/114 [==============================] - 0s 894us/sample - loss: 0.6405 - acc: 0.9912 - val_loss: 1.0124 - val_acc: 0.9048\n",
      "Epoch 374/800\n",
      "114/114 [==============================] - 0s 942us/sample - loss: 0.6148 - acc: 1.0000 - val_loss: 1.0017 - val_acc: 0.9048\n",
      "Epoch 375/800\n",
      "114/114 [==============================] - 0s 883us/sample - loss: 0.6242 - acc: 1.0000 - val_loss: 0.9988 - val_acc: 0.9048\n",
      "Epoch 376/800\n",
      "114/114 [==============================] - 0s 902us/sample - loss: 0.6124 - acc: 1.0000 - val_loss: 0.9975 - val_acc: 0.9048\n",
      "Epoch 377/800\n",
      "114/114 [==============================] - 0s 883us/sample - loss: 0.6351 - acc: 0.9825 - val_loss: 0.9823 - val_acc: 0.9048\n",
      "Epoch 378/800\n",
      "114/114 [==============================] - 0s 2ms/sample - loss: 0.6191 - acc: 0.9912 - val_loss: 0.9494 - val_acc: 0.9048\n",
      "Epoch 379/800\n",
      "114/114 [==============================] - 0s 926us/sample - loss: 0.6116 - acc: 1.0000 - val_loss: 0.9140 - val_acc: 0.9524\n",
      "Epoch 380/800\n",
      "114/114 [==============================] - 0s 881us/sample - loss: 0.6443 - acc: 0.9825 - val_loss: 0.9054 - val_acc: 0.9524\n",
      "Epoch 381/800\n",
      "114/114 [==============================] - 0s 891us/sample - loss: 0.6482 - acc: 0.9912 - val_loss: 0.9019 - val_acc: 0.9524\n",
      "Epoch 382/800\n",
      "114/114 [==============================] - 0s 893us/sample - loss: 0.6104 - acc: 1.0000 - val_loss: 0.9039 - val_acc: 0.9524\n",
      "Epoch 383/800\n",
      "114/114 [==============================] - 0s 2ms/sample - loss: 0.6129 - acc: 1.0000 - val_loss: 0.9041 - val_acc: 0.9524\n",
      "Epoch 384/800\n",
      "114/114 [==============================] - 0s 922us/sample - loss: 0.6471 - acc: 0.9912 - val_loss: 0.8945 - val_acc: 0.9524\n",
      "Epoch 385/800\n",
      "114/114 [==============================] - 0s 893us/sample - loss: 0.6270 - acc: 0.9912 - val_loss: 0.9349 - val_acc: 0.9048\n",
      "Epoch 386/800\n",
      "114/114 [==============================] - 0s 897us/sample - loss: 0.6145 - acc: 1.0000 - val_loss: 1.0093 - val_acc: 0.9048\n",
      "Epoch 387/800\n",
      "114/114 [==============================] - 0s 2ms/sample - loss: 0.6452 - acc: 0.9737 - val_loss: 1.0185 - val_acc: 0.9048\n",
      "Epoch 388/800\n",
      "114/114 [==============================] - 0s 922us/sample - loss: 0.6295 - acc: 0.9825 - val_loss: 1.0082 - val_acc: 0.9048\n",
      "Epoch 389/800\n",
      "114/114 [==============================] - 0s 896us/sample - loss: 0.6412 - acc: 0.9737 - val_loss: 0.9047 - val_acc: 0.9524\n",
      "Epoch 390/800\n",
      "114/114 [==============================] - 0s 889us/sample - loss: 0.6202 - acc: 0.9912 - val_loss: 0.9099 - val_acc: 0.9524\n",
      "Epoch 391/800\n",
      "114/114 [==============================] - 0s 933us/sample - loss: 0.6340 - acc: 0.9825 - val_loss: 0.9179 - val_acc: 0.9524\n",
      "Epoch 392/800\n",
      "114/114 [==============================] - 0s 893us/sample - loss: 0.6166 - acc: 1.0000 - val_loss: 0.9031 - val_acc: 0.9524\n",
      "Epoch 393/800\n",
      "114/114 [==============================] - 0s 878us/sample - loss: 0.6213 - acc: 0.9912 - val_loss: 0.9016 - val_acc: 0.9524\n",
      "Epoch 394/800\n",
      "114/114 [==============================] - 0s 890us/sample - loss: 0.6313 - acc: 0.9912 - val_loss: 0.9301 - val_acc: 0.9048\n",
      "Epoch 395/800\n",
      "114/114 [==============================] - 0s 896us/sample - loss: 0.6479 - acc: 0.9825 - val_loss: 0.9574 - val_acc: 0.9048\n",
      "Epoch 396/800\n",
      "114/114 [==============================] - 0s 2ms/sample - loss: 0.6060 - acc: 1.0000 - val_loss: 0.9683 - val_acc: 0.9048\n",
      "Epoch 397/800\n",
      "114/114 [==============================] - 0s 897us/sample - loss: 0.6241 - acc: 0.9825 - val_loss: 0.9422 - val_acc: 0.9048\n",
      "Epoch 398/800\n",
      "114/114 [==============================] - 0s 897us/sample - loss: 0.6409 - acc: 0.9825 - val_loss: 0.9205 - val_acc: 0.9524\n",
      "Epoch 399/800\n",
      "114/114 [==============================] - 0s 889us/sample - loss: 0.6239 - acc: 0.9912 - val_loss: 0.9367 - val_acc: 0.9048\n",
      "Epoch 400/800\n",
      "114/114 [==============================] - 0s 872us/sample - loss: 0.6244 - acc: 0.9912 - val_loss: 0.9229 - val_acc: 0.9524\n",
      "Epoch 401/800\n",
      "114/114 [==============================] - 0s 2ms/sample - loss: 0.6186 - acc: 0.9912 - val_loss: 0.9314 - val_acc: 0.9524\n",
      "Epoch 402/800\n",
      "114/114 [==============================] - 0s 907us/sample - loss: 0.6429 - acc: 0.9825 - val_loss: 0.9340 - val_acc: 0.9524\n",
      "Epoch 403/800\n",
      "114/114 [==============================] - 0s 898us/sample - loss: 0.6125 - acc: 1.0000 - val_loss: 0.9391 - val_acc: 0.9524\n",
      "Epoch 404/800\n",
      "114/114 [==============================] - 0s 2ms/sample - loss: 0.6377 - acc: 0.9912 - val_loss: 0.9637 - val_acc: 0.9048\n",
      "Epoch 405/800\n",
      "114/114 [==============================] - 0s 937us/sample - loss: 0.6054 - acc: 1.0000 - val_loss: 0.9867 - val_acc: 0.9048\n",
      "Epoch 406/800\n",
      "114/114 [==============================] - 0s 881us/sample - loss: 0.6195 - acc: 0.9912 - val_loss: 0.9636 - val_acc: 0.9048\n",
      "Epoch 407/800\n",
      "114/114 [==============================] - 0s 905us/sample - loss: 0.6196 - acc: 0.9912 - val_loss: 0.9298 - val_acc: 0.9524\n",
      "Epoch 408/800\n",
      "114/114 [==============================] - 0s 888us/sample - loss: 0.6491 - acc: 0.9825 - val_loss: 0.9254 - val_acc: 0.9524\n",
      "Epoch 409/800\n",
      "114/114 [==============================] - 0s 2ms/sample - loss: 0.6588 - acc: 0.9825 - val_loss: 0.9094 - val_acc: 0.9524\n",
      "Epoch 410/800\n",
      "114/114 [==============================] - 0s 867us/sample - loss: 0.6259 - acc: 0.9912 - val_loss: 0.9032 - val_acc: 0.9524\n",
      "Epoch 411/800\n",
      "114/114 [==============================] - 0s 923us/sample - loss: 0.6057 - acc: 1.0000 - val_loss: 0.9024 - val_acc: 0.9524\n",
      "Epoch 412/800\n",
      "114/114 [==============================] - 0s 2ms/sample - loss: 0.6070 - acc: 1.0000 - val_loss: 0.8990 - val_acc: 0.9524\n",
      "Epoch 413/800\n",
      "114/114 [==============================] - 0s 897us/sample - loss: 0.6117 - acc: 1.0000 - val_loss: 0.8982 - val_acc: 0.9524\n",
      "Epoch 414/800\n",
      "114/114 [==============================] - 0s 936us/sample - loss: 0.6118 - acc: 0.9912 - val_loss: 0.8954 - val_acc: 0.9524\n",
      "Epoch 415/800\n",
      "114/114 [==============================] - 0s 893us/sample - loss: 0.6118 - acc: 1.0000 - val_loss: 0.9016 - val_acc: 0.9524\n",
      "Epoch 416/800\n",
      "114/114 [==============================] - 0s 2ms/sample - loss: 0.6047 - acc: 1.0000 - val_loss: 0.9176 - val_acc: 0.9524\n",
      "Epoch 417/800\n",
      "114/114 [==============================] - 0s 913us/sample - loss: 0.6167 - acc: 0.9825 - val_loss: 0.9133 - val_acc: 0.9524\n",
      "Epoch 418/800\n",
      "114/114 [==============================] - 0s 897us/sample - loss: 0.6168 - acc: 0.9825 - val_loss: 0.9258 - val_acc: 0.9524\n",
      "Epoch 419/800\n",
      "114/114 [==============================] - 0s 893us/sample - loss: 0.6321 - acc: 0.9825 - val_loss: 0.9355 - val_acc: 0.9524\n",
      "Epoch 420/800\n",
      "114/114 [==============================] - 0s 2ms/sample - loss: 0.6473 - acc: 0.9825 - val_loss: 0.9552 - val_acc: 0.9524\n",
      "Epoch 421/800\n",
      "114/114 [==============================] - 0s 905us/sample - loss: 0.6395 - acc: 0.9825 - val_loss: 0.9490 - val_acc: 0.9524\n",
      "Epoch 422/800\n",
      "114/114 [==============================] - 0s 894us/sample - loss: 0.6039 - acc: 0.9912 - val_loss: 0.9502 - val_acc: 0.9048\n",
      "Epoch 423/800\n",
      "114/114 [==============================] - 0s 894us/sample - loss: 0.6187 - acc: 0.9825 - val_loss: 1.0691 - val_acc: 0.9048\n",
      "Epoch 424/800\n",
      "114/114 [==============================] - 0s 2ms/sample - loss: 0.6443 - acc: 0.9825 - val_loss: 1.0340 - val_acc: 0.9048\n",
      "Epoch 425/800\n",
      "114/114 [==============================] - 0s 919us/sample - loss: 0.6926 - acc: 0.9737 - val_loss: 0.9492 - val_acc: 0.9048\n",
      "Epoch 426/800\n",
      "114/114 [==============================] - 0s 899us/sample - loss: 0.6061 - acc: 0.9825 - val_loss: 0.9289 - val_acc: 0.9524\n",
      "Epoch 427/800\n",
      "114/114 [==============================] - 0s 885us/sample - loss: 0.6621 - acc: 0.9825 - val_loss: 0.9276 - val_acc: 0.9524\n",
      "Epoch 428/800\n",
      "114/114 [==============================] - 0s 2ms/sample - loss: 0.6235 - acc: 0.9825 - val_loss: 0.9172 - val_acc: 0.9524\n",
      "Epoch 429/800\n",
      "114/114 [==============================] - 0s 907us/sample - loss: 0.6219 - acc: 0.9825 - val_loss: 0.9070 - val_acc: 0.9524\n",
      "Epoch 430/800\n",
      "114/114 [==============================] - 0s 870us/sample - loss: 0.6069 - acc: 0.9912 - val_loss: 0.9510 - val_acc: 0.9048\n",
      "Epoch 431/800\n",
      "114/114 [==============================] - 0s 898us/sample - loss: 0.6305 - acc: 0.9737 - val_loss: 0.9697 - val_acc: 0.9048\n",
      "Epoch 432/800\n",
      "114/114 [==============================] - 0s 890us/sample - loss: 0.6272 - acc: 0.9825 - val_loss: 0.9437 - val_acc: 0.9048\n",
      "Epoch 433/800\n",
      "114/114 [==============================] - 0s 2ms/sample - loss: 0.6572 - acc: 0.9561 - val_loss: 0.9061 - val_acc: 0.9524\n",
      "Epoch 434/800\n",
      "114/114 [==============================] - 0s 936us/sample - loss: 0.5953 - acc: 1.0000 - val_loss: 0.9288 - val_acc: 0.9524\n",
      "Epoch 435/800\n",
      "114/114 [==============================] - 0s 866us/sample - loss: 0.6019 - acc: 1.0000 - val_loss: 0.9326 - val_acc: 0.9524\n",
      "Epoch 436/800\n",
      "114/114 [==============================] - 0s 891us/sample - loss: 0.6689 - acc: 0.9737 - val_loss: 0.9518 - val_acc: 0.9048\n",
      "Epoch 437/800\n",
      "114/114 [==============================] - 0s 2ms/sample - loss: 0.6055 - acc: 0.9912 - val_loss: 0.9839 - val_acc: 0.9048\n",
      "Epoch 438/800\n",
      "114/114 [==============================] - 0s 888us/sample - loss: 0.5940 - acc: 1.0000 - val_loss: 0.9912 - val_acc: 0.9048\n",
      "Epoch 439/800\n",
      "114/114 [==============================] - 0s 899us/sample - loss: 0.6184 - acc: 0.9825 - val_loss: 0.9261 - val_acc: 0.9048\n",
      "Epoch 440/800\n",
      "114/114 [==============================] - 0s 889us/sample - loss: 0.6090 - acc: 0.9825 - val_loss: 0.9096 - val_acc: 0.9524\n",
      "Epoch 441/800\n",
      "114/114 [==============================] - 0s 2ms/sample - loss: 0.6185 - acc: 0.9825 - val_loss: 0.9110 - val_acc: 0.9524\n",
      "Epoch 442/800\n",
      "114/114 [==============================] - 0s 919us/sample - loss: 0.6020 - acc: 0.9912 - val_loss: 0.9083 - val_acc: 0.9524\n",
      "Epoch 443/800\n",
      "114/114 [==============================] - 0s 882us/sample - loss: 0.6122 - acc: 0.9912 - val_loss: 0.9316 - val_acc: 0.9048\n",
      "Epoch 444/800\n",
      "114/114 [==============================] - 0s 2ms/sample - loss: 0.6233 - acc: 0.9912 - val_loss: 0.9401 - val_acc: 0.9048\n",
      "Epoch 445/800\n",
      "114/114 [==============================] - 0s 893us/sample - loss: 0.6786 - acc: 0.9737 - val_loss: 0.9632 - val_acc: 0.9048\n",
      "Epoch 446/800\n",
      "114/114 [==============================] - 0s 935us/sample - loss: 0.6043 - acc: 0.9912 - val_loss: 0.9386 - val_acc: 0.9048\n",
      "Epoch 447/800\n",
      "114/114 [==============================] - 0s 890us/sample - loss: 0.5939 - acc: 0.9912 - val_loss: 0.9215 - val_acc: 0.9524\n",
      "Epoch 448/800\n",
      "114/114 [==============================] - 0s 872us/sample - loss: 0.6393 - acc: 0.9737 - val_loss: 0.9182 - val_acc: 0.9524\n",
      "Epoch 449/800\n",
      "114/114 [==============================] - 0s 2ms/sample - loss: 0.6034 - acc: 0.9912 - val_loss: 0.9150 - val_acc: 0.9524\n",
      "Epoch 450/800\n",
      "114/114 [==============================] - 0s 929us/sample - loss: 0.6163 - acc: 0.9912 - val_loss: 0.9118 - val_acc: 0.9524\n",
      "Epoch 451/800\n",
      "114/114 [==============================] - 0s 895us/sample - loss: 0.5988 - acc: 1.0000 - val_loss: 0.9192 - val_acc: 0.9524\n",
      "Epoch 452/800\n",
      "114/114 [==============================] - 0s 2ms/sample - loss: 0.6075 - acc: 0.9912 - val_loss: 0.9238 - val_acc: 0.9524\n",
      "Epoch 453/800\n",
      "114/114 [==============================] - 0s 919us/sample - loss: 0.6611 - acc: 0.9737 - val_loss: 0.9025 - val_acc: 0.9524\n",
      "Epoch 454/800\n",
      "114/114 [==============================] - 0s 898us/sample - loss: 0.6030 - acc: 0.9912 - val_loss: 0.9049 - val_acc: 0.9048\n",
      "Epoch 455/800\n",
      "114/114 [==============================] - 0s 887us/sample - loss: 0.5966 - acc: 0.9912 - val_loss: 0.9643 - val_acc: 0.9048\n",
      "Epoch 456/800\n",
      "114/114 [==============================] - 0s 2ms/sample - loss: 0.6439 - acc: 0.9737 - val_loss: 0.9106 - val_acc: 0.9048\n",
      "Epoch 457/800\n",
      "114/114 [==============================] - 0s 903us/sample - loss: 0.6122 - acc: 0.9825 - val_loss: 0.8951 - val_acc: 0.9524\n",
      "Epoch 458/800\n",
      "114/114 [==============================] - 0s 942us/sample - loss: 0.6383 - acc: 0.9912 - val_loss: 0.8990 - val_acc: 0.9524\n",
      "Epoch 459/800\n",
      "114/114 [==============================] - 0s 890us/sample - loss: 0.6088 - acc: 0.9912 - val_loss: 0.8934 - val_acc: 0.9524\n",
      "Epoch 460/800\n",
      "114/114 [==============================] - 0s 2ms/sample - loss: 0.6065 - acc: 0.9825 - val_loss: 0.9352 - val_acc: 0.9048\n",
      "Epoch 461/800\n",
      "114/114 [==============================] - 0s 909us/sample - loss: 0.6268 - acc: 0.9737 - val_loss: 0.9261 - val_acc: 0.9048\n",
      "Epoch 462/800\n",
      "114/114 [==============================] - 0s 897us/sample - loss: 0.5931 - acc: 0.9912 - val_loss: 0.9260 - val_acc: 0.9048\n",
      "Epoch 463/800\n",
      "114/114 [==============================] - 0s 887us/sample - loss: 0.6002 - acc: 0.9912 - val_loss: 0.8952 - val_acc: 0.9048\n",
      "Epoch 464/800\n",
      "114/114 [==============================] - 0s 2ms/sample - loss: 0.6161 - acc: 0.9825 - val_loss: 0.8929 - val_acc: 0.9524\n",
      "Epoch 465/800\n",
      "114/114 [==============================] - 0s 907us/sample - loss: 0.5852 - acc: 1.0000 - val_loss: 0.9247 - val_acc: 0.9524\n",
      "Epoch 466/800\n",
      "114/114 [==============================] - 0s 898us/sample - loss: 0.6105 - acc: 0.9912 - val_loss: 0.9287 - val_acc: 0.9524\n",
      "Epoch 467/800\n",
      "114/114 [==============================] - 0s 891us/sample - loss: 0.6571 - acc: 0.9825 - val_loss: 0.9018 - val_acc: 0.9524\n",
      "Epoch 468/800\n",
      "114/114 [==============================] - 0s 2ms/sample - loss: 0.5962 - acc: 0.9825 - val_loss: 0.8870 - val_acc: 0.9524\n",
      "Epoch 469/800\n",
      "114/114 [==============================] - 0s 929us/sample - loss: 0.5838 - acc: 1.0000 - val_loss: 0.9093 - val_acc: 0.9048\n",
      "Epoch 470/800\n",
      "114/114 [==============================] - 0s 891us/sample - loss: 0.5983 - acc: 0.9825 - val_loss: 0.9156 - val_acc: 0.9048\n",
      "Epoch 471/800\n",
      "114/114 [==============================] - 0s 889us/sample - loss: 0.6070 - acc: 0.9912 - val_loss: 0.9202 - val_acc: 0.9048\n",
      "Epoch 472/800\n",
      "114/114 [==============================] - 0s 2ms/sample - loss: 0.5819 - acc: 1.0000 - val_loss: 0.9204 - val_acc: 0.9048\n",
      "Epoch 473/800\n",
      "114/114 [==============================] - 0s 896us/sample - loss: 0.5912 - acc: 0.9912 - val_loss: 0.8984 - val_acc: 0.9524\n",
      "Epoch 474/800\n",
      "114/114 [==============================] - 0s 932us/sample - loss: 0.6034 - acc: 0.9825 - val_loss: 0.8975 - val_acc: 0.9524\n",
      "Epoch 475/800\n",
      "114/114 [==============================] - 0s 883us/sample - loss: 0.5912 - acc: 0.9912 - val_loss: 0.8924 - val_acc: 0.9524\n",
      "Epoch 476/800\n",
      "114/114 [==============================] - 0s 932us/sample - loss: 0.6674 - acc: 0.9649 - val_loss: 0.8947 - val_acc: 0.9524\n",
      "Epoch 477/800\n",
      "114/114 [==============================] - 0s 895us/sample - loss: 0.5811 - acc: 1.0000 - val_loss: 0.8901 - val_acc: 0.9524\n",
      "Epoch 478/800\n",
      "114/114 [==============================] - 0s 899us/sample - loss: 0.6010 - acc: 0.9825 - val_loss: 0.8931 - val_acc: 0.9524\n",
      "Epoch 479/800\n",
      "114/114 [==============================] - 0s 886us/sample - loss: 0.6124 - acc: 0.9825 - val_loss: 0.8903 - val_acc: 0.9524\n",
      "Epoch 480/800\n",
      "114/114 [==============================] - 0s 2ms/sample - loss: 0.5915 - acc: 0.9912 - val_loss: 0.9247 - val_acc: 0.9524\n",
      "Epoch 481/800\n",
      "114/114 [==============================] - 0s 930us/sample - loss: 0.5880 - acc: 0.9912 - val_loss: 0.9497 - val_acc: 0.9524\n",
      "Epoch 482/800\n",
      "114/114 [==============================] - 0s 893us/sample - loss: 0.6220 - acc: 0.9825 - val_loss: 0.9332 - val_acc: 0.9524\n",
      "Epoch 483/800\n",
      "114/114 [==============================] - 0s 2ms/sample - loss: 0.5856 - acc: 0.9912 - val_loss: 0.9121 - val_acc: 0.9524\n",
      "Epoch 484/800\n",
      "114/114 [==============================] - 0s 904us/sample - loss: 0.5857 - acc: 0.9825 - val_loss: 0.8949 - val_acc: 0.9524\n",
      "Epoch 485/800\n",
      "114/114 [==============================] - 0s 897us/sample - loss: 0.6122 - acc: 0.9737 - val_loss: 0.8953 - val_acc: 0.9524\n",
      "Epoch 486/800\n",
      "114/114 [==============================] - 0s 893us/sample - loss: 0.5915 - acc: 0.9912 - val_loss: 0.8998 - val_acc: 0.9524\n",
      "Epoch 487/800\n",
      "114/114 [==============================] - 0s 2ms/sample - loss: 0.6012 - acc: 0.9825 - val_loss: 0.9047 - val_acc: 0.9524\n",
      "Epoch 488/800\n",
      "114/114 [==============================] - 0s 947us/sample - loss: 0.5726 - acc: 1.0000 - val_loss: 0.9126 - val_acc: 0.9524\n",
      "Epoch 489/800\n",
      "114/114 [==============================] - 0s 899us/sample - loss: 0.5929 - acc: 0.9912 - val_loss: 0.9022 - val_acc: 0.9524\n",
      "Epoch 490/800\n",
      "114/114 [==============================] - 0s 889us/sample - loss: 0.5711 - acc: 1.0000 - val_loss: 0.8892 - val_acc: 0.9524\n",
      "Epoch 491/800\n",
      "114/114 [==============================] - 0s 2ms/sample - loss: 0.5697 - acc: 1.0000 - val_loss: 0.8819 - val_acc: 0.9524\n",
      "Epoch 492/800\n",
      "114/114 [==============================] - 0s 907us/sample - loss: 0.5775 - acc: 1.0000 - val_loss: 0.8893 - val_acc: 0.9524\n",
      "Epoch 493/800\n",
      "114/114 [==============================] - 0s 895us/sample - loss: 0.6456 - acc: 0.9649 - val_loss: 0.8785 - val_acc: 0.9524\n",
      "Epoch 494/800\n",
      "114/114 [==============================] - 0s 2ms/sample - loss: 0.5747 - acc: 1.0000 - val_loss: 0.8941 - val_acc: 0.9524\n",
      "Epoch 495/800\n",
      "114/114 [==============================] - 0s 947us/sample - loss: 0.5828 - acc: 0.9912 - val_loss: 0.9153 - val_acc: 0.9524\n",
      "Epoch 496/800\n",
      "114/114 [==============================] - 0s 880us/sample - loss: 0.5976 - acc: 0.9912 - val_loss: 0.9145 - val_acc: 0.9524\n",
      "Epoch 497/800\n",
      "114/114 [==============================] - 0s 897us/sample - loss: 0.6208 - acc: 0.9737 - val_loss: 0.9003 - val_acc: 0.9524\n",
      "Epoch 498/800\n",
      "114/114 [==============================] - 0s 885us/sample - loss: 0.5749 - acc: 1.0000 - val_loss: 0.8841 - val_acc: 0.9524\n",
      "Epoch 499/800\n",
      "114/114 [==============================] - 0s 2ms/sample - loss: 0.6068 - acc: 0.9737 - val_loss: 0.8812 - val_acc: 0.9524\n",
      "Epoch 500/800\n",
      "114/114 [==============================] - 0s 875us/sample - loss: 0.5750 - acc: 1.0000 - val_loss: 0.8872 - val_acc: 0.9524\n",
      "Epoch 501/800\n",
      "114/114 [==============================] - 0s 896us/sample - loss: 0.6238 - acc: 0.9649 - val_loss: 0.8988 - val_acc: 0.9524\n",
      "Epoch 502/800\n",
      "114/114 [==============================] - 0s 887us/sample - loss: 0.5675 - acc: 1.0000 - val_loss: 0.9161 - val_acc: 0.9524\n",
      "Epoch 503/800\n",
      "114/114 [==============================] - 0s 2ms/sample - loss: 0.5847 - acc: 1.0000 - val_loss: 0.9312 - val_acc: 0.9524\n",
      "Epoch 504/800\n",
      "114/114 [==============================] - 0s 895us/sample - loss: 0.5927 - acc: 0.9912 - val_loss: 0.9246 - val_acc: 0.9524\n",
      "Epoch 505/800\n",
      "114/114 [==============================] - 0s 902us/sample - loss: 0.5976 - acc: 0.9825 - val_loss: 0.8968 - val_acc: 0.9524\n",
      "Epoch 506/800\n",
      "114/114 [==============================] - 0s 889us/sample - loss: 0.5656 - acc: 1.0000 - val_loss: 0.9023 - val_acc: 0.9048\n",
      "Epoch 507/800\n",
      "114/114 [==============================] - 0s 2ms/sample - loss: 0.5939 - acc: 0.9912 - val_loss: 0.9580 - val_acc: 0.9048\n",
      "Epoch 508/800\n",
      "114/114 [==============================] - 0s 902us/sample - loss: 0.6116 - acc: 0.9825 - val_loss: 0.9248 - val_acc: 0.9048\n",
      "Epoch 509/800\n",
      "114/114 [==============================] - 0s 907us/sample - loss: 0.5805 - acc: 0.9912 - val_loss: 0.8937 - val_acc: 0.9524\n",
      "Epoch 510/800\n",
      "114/114 [==============================] - 0s 2ms/sample - loss: 0.6256 - acc: 0.9737 - val_loss: 0.8963 - val_acc: 0.9524\n",
      "Epoch 511/800\n",
      "114/114 [==============================] - 0s 929us/sample - loss: 0.5824 - acc: 0.9912 - val_loss: 0.8799 - val_acc: 0.9524\n",
      "Epoch 512/800\n",
      "114/114 [==============================] - 0s 908us/sample - loss: 0.6071 - acc: 0.9912 - val_loss: 0.8760 - val_acc: 0.9524\n",
      "Epoch 513/800\n",
      "114/114 [==============================] - 0s 892us/sample - loss: 0.5964 - acc: 0.9825 - val_loss: 0.8708 - val_acc: 0.9524\n",
      "Epoch 514/800\n",
      "114/114 [==============================] - 0s 2ms/sample - loss: 0.5846 - acc: 0.9825 - val_loss: 0.8726 - val_acc: 0.9524\n",
      "Epoch 515/800\n",
      "114/114 [==============================] - 0s 936us/sample - loss: 0.5837 - acc: 0.9825 - val_loss: 0.8903 - val_acc: 0.9524\n",
      "Epoch 516/800\n",
      "114/114 [==============================] - 0s 894us/sample - loss: 0.5737 - acc: 1.0000 - val_loss: 0.9051 - val_acc: 0.9524\n",
      "Epoch 517/800\n",
      "114/114 [==============================] - 0s 891us/sample - loss: 0.5893 - acc: 0.9912 - val_loss: 0.9097 - val_acc: 0.9524\n",
      "Epoch 518/800\n",
      "114/114 [==============================] - 0s 2ms/sample - loss: 0.5909 - acc: 0.9912 - val_loss: 0.8862 - val_acc: 0.9524\n",
      "Epoch 519/800\n",
      "114/114 [==============================] - 0s 921us/sample - loss: 0.5946 - acc: 0.9825 - val_loss: 0.8821 - val_acc: 0.9524\n",
      "Epoch 520/800\n",
      "114/114 [==============================] - 0s 896us/sample - loss: 0.5981 - acc: 0.9912 - val_loss: 0.8837 - val_acc: 0.9524\n",
      "Epoch 521/800\n",
      "114/114 [==============================] - 0s 891us/sample - loss: 0.5932 - acc: 0.9825 - val_loss: 0.8823 - val_acc: 0.9524\n",
      "Epoch 522/800\n",
      "114/114 [==============================] - 0s 2ms/sample - loss: 0.5773 - acc: 0.9912 - val_loss: 0.8939 - val_acc: 0.9048\n",
      "Epoch 523/800\n",
      "114/114 [==============================] - 0s 900us/sample - loss: 0.5656 - acc: 1.0000 - val_loss: 0.9131 - val_acc: 0.9048\n",
      "Epoch 524/800\n",
      "114/114 [==============================] - 0s 897us/sample - loss: 0.5672 - acc: 1.0000 - val_loss: 0.9181 - val_acc: 0.9048\n",
      "Epoch 525/800\n",
      "114/114 [==============================] - 0s 888us/sample - loss: 0.6228 - acc: 0.9737 - val_loss: 0.9228 - val_acc: 0.9048\n",
      "Epoch 526/800\n",
      "114/114 [==============================] - 0s 2ms/sample - loss: 0.5700 - acc: 1.0000 - val_loss: 0.8789 - val_acc: 0.9524\n",
      "Epoch 527/800\n",
      "114/114 [==============================] - 0s 900us/sample - loss: 0.5656 - acc: 1.0000 - val_loss: 0.8927 - val_acc: 0.9524\n",
      "Epoch 528/800\n",
      "114/114 [==============================] - 0s 896us/sample - loss: 0.6441 - acc: 0.9737 - val_loss: 0.8950 - val_acc: 0.9524\n",
      "Epoch 529/800\n",
      "114/114 [==============================] - 0s 900us/sample - loss: 0.5611 - acc: 1.0000 - val_loss: 0.8946 - val_acc: 0.9524\n",
      "Epoch 530/800\n",
      "114/114 [==============================] - 0s 2ms/sample - loss: 0.5861 - acc: 0.9912 - val_loss: 0.8758 - val_acc: 0.9524\n",
      "Epoch 531/800\n",
      "114/114 [==============================] - 0s 896us/sample - loss: 0.5646 - acc: 1.0000 - val_loss: 0.8854 - val_acc: 0.9048\n",
      "Epoch 532/800\n",
      "114/114 [==============================] - 0s 895us/sample - loss: 0.5838 - acc: 0.9912 - val_loss: 0.9204 - val_acc: 0.9048\n",
      "Epoch 533/800\n",
      "114/114 [==============================] - 0s 892us/sample - loss: 0.5903 - acc: 0.9912 - val_loss: 0.8838 - val_acc: 0.9048\n",
      "Epoch 534/800\n",
      "114/114 [==============================] - 0s 2ms/sample - loss: 0.5844 - acc: 0.9912 - val_loss: 0.8606 - val_acc: 0.9524\n",
      "Epoch 535/800\n",
      "114/114 [==============================] - 0s 894us/sample - loss: 0.5595 - acc: 1.0000 - val_loss: 0.8585 - val_acc: 0.9524\n",
      "Epoch 536/800\n",
      "114/114 [==============================] - 0s 900us/sample - loss: 0.5747 - acc: 0.9912 - val_loss: 0.8579 - val_acc: 0.9524\n",
      "Epoch 537/800\n",
      "114/114 [==============================] - 0s 892us/sample - loss: 0.5718 - acc: 0.9912 - val_loss: 0.8585 - val_acc: 0.9524\n",
      "Epoch 538/800\n",
      "114/114 [==============================] - 0s 2ms/sample - loss: 0.5563 - acc: 1.0000 - val_loss: 0.8709 - val_acc: 0.9048\n",
      "Epoch 539/800\n",
      "114/114 [==============================] - 0s 873us/sample - loss: 0.5639 - acc: 1.0000 - val_loss: 0.8903 - val_acc: 0.9048\n",
      "Epoch 540/800\n",
      "114/114 [==============================] - 0s 888us/sample - loss: 0.5673 - acc: 1.0000 - val_loss: 0.9247 - val_acc: 0.9048\n",
      "Epoch 541/800\n",
      "114/114 [==============================] - 0s 2ms/sample - loss: 0.5799 - acc: 0.9825 - val_loss: 0.8693 - val_acc: 0.9524\n",
      "Epoch 542/800\n",
      "114/114 [==============================] - 0s 883us/sample - loss: 0.5564 - acc: 1.0000 - val_loss: 0.9077 - val_acc: 0.9524\n",
      "Epoch 543/800\n",
      "114/114 [==============================] - 0s 901us/sample - loss: 0.5555 - acc: 1.0000 - val_loss: 0.9441 - val_acc: 0.9524\n",
      "Epoch 544/800\n",
      "114/114 [==============================] - 0s 884us/sample - loss: 0.5911 - acc: 0.9825 - val_loss: 0.9350 - val_acc: 0.9524\n",
      "Epoch 545/800\n",
      "114/114 [==============================] - 0s 2ms/sample - loss: 0.6083 - acc: 0.9737 - val_loss: 0.8899 - val_acc: 0.9524\n",
      "Epoch 546/800\n",
      "114/114 [==============================] - 0s 891us/sample - loss: 0.5584 - acc: 1.0000 - val_loss: 0.8581 - val_acc: 0.9524\n",
      "Epoch 547/800\n",
      "114/114 [==============================] - 0s 908us/sample - loss: 0.5569 - acc: 1.0000 - val_loss: 0.9206 - val_acc: 0.9048\n",
      "Epoch 548/800\n",
      "114/114 [==============================] - 0s 886us/sample - loss: 0.5701 - acc: 0.9912 - val_loss: 0.9355 - val_acc: 0.9048\n",
      "Epoch 549/800\n",
      "114/114 [==============================] - 0s 2ms/sample - loss: 0.5727 - acc: 0.9825 - val_loss: 0.8685 - val_acc: 0.9524\n",
      "Epoch 550/800\n",
      "114/114 [==============================] - 0s 931us/sample - loss: 0.5864 - acc: 0.9825 - val_loss: 0.9229 - val_acc: 0.9524\n",
      "Epoch 551/800\n",
      "114/114 [==============================] - 0s 872us/sample - loss: 0.5676 - acc: 0.9912 - val_loss: 0.9562 - val_acc: 0.9524\n",
      "Epoch 552/800\n",
      "114/114 [==============================] - 0s 895us/sample - loss: 0.5915 - acc: 0.9825 - val_loss: 0.9379 - val_acc: 0.9524\n",
      "Epoch 553/800\n",
      "114/114 [==============================] - 0s 895us/sample - loss: 0.5928 - acc: 0.9825 - val_loss: 0.8920 - val_acc: 0.9524\n",
      "Epoch 554/800\n",
      "114/114 [==============================] - 0s 2ms/sample - loss: 0.5807 - acc: 0.9912 - val_loss: 0.8668 - val_acc: 0.9524\n",
      "Epoch 555/800\n",
      "114/114 [==============================] - 0s 943us/sample - loss: 0.5923 - acc: 0.9825 - val_loss: 0.9204 - val_acc: 0.9048\n",
      "Epoch 556/800\n",
      "114/114 [==============================] - 0s 873us/sample - loss: 0.5603 - acc: 0.9912 - val_loss: 0.8991 - val_acc: 0.9048\n",
      "Epoch 557/800\n",
      "114/114 [==============================] - 0s 908us/sample - loss: 0.6002 - acc: 0.9825 - val_loss: 0.8765 - val_acc: 0.9048\n",
      "Epoch 558/800\n",
      "114/114 [==============================] - 0s 2ms/sample - loss: 0.5638 - acc: 0.9912 - val_loss: 0.8667 - val_acc: 0.9524\n",
      "Epoch 559/800\n",
      "114/114 [==============================] - 0s 948us/sample - loss: 0.5608 - acc: 0.9912 - val_loss: 0.8702 - val_acc: 0.9524\n",
      "Epoch 560/800\n",
      "114/114 [==============================] - 0s 898us/sample - loss: 0.5784 - acc: 0.9912 - val_loss: 0.8622 - val_acc: 0.9524\n",
      "Epoch 561/800\n",
      "114/114 [==============================] - 0s 870us/sample - loss: 0.5573 - acc: 0.9912 - val_loss: 0.8556 - val_acc: 0.9524\n",
      "Epoch 562/800\n",
      "114/114 [==============================] - 0s 889us/sample - loss: 0.5496 - acc: 1.0000 - val_loss: 0.8524 - val_acc: 0.9524\n",
      "Epoch 563/800\n",
      "114/114 [==============================] - 0s 931us/sample - loss: 0.5640 - acc: 0.9912 - val_loss: 0.8499 - val_acc: 0.9524\n",
      "Epoch 564/800\n",
      "114/114 [==============================] - 0s 898us/sample - loss: 0.5614 - acc: 0.9912 - val_loss: 0.8479 - val_acc: 0.9524\n",
      "Epoch 565/800\n",
      "114/114 [==============================] - 0s 896us/sample - loss: 0.5724 - acc: 0.9825 - val_loss: 0.8531 - val_acc: 0.9524\n",
      "Epoch 566/800\n",
      "114/114 [==============================] - 0s 885us/sample - loss: 0.5606 - acc: 0.9912 - val_loss: 0.8723 - val_acc: 0.9524\n",
      "Epoch 567/800\n",
      "114/114 [==============================] - 0s 929us/sample - loss: 0.5533 - acc: 1.0000 - val_loss: 0.8875 - val_acc: 0.9524\n",
      "Epoch 568/800\n",
      "114/114 [==============================] - 0s 909us/sample - loss: 0.5681 - acc: 0.9912 - val_loss: 0.8996 - val_acc: 0.9524\n",
      "Epoch 569/800\n",
      "114/114 [==============================] - 0s 891us/sample - loss: 0.5567 - acc: 0.9912 - val_loss: 0.8931 - val_acc: 0.9524\n",
      "Epoch 570/800\n",
      "114/114 [==============================] - 0s 893us/sample - loss: 0.5611 - acc: 0.9912 - val_loss: 0.8666 - val_acc: 0.9524\n",
      "Epoch 571/800\n",
      "114/114 [==============================] - 0s 2ms/sample - loss: 0.5547 - acc: 0.9912 - val_loss: 0.8764 - val_acc: 0.9048\n",
      "Epoch 572/800\n",
      "114/114 [==============================] - 0s 930us/sample - loss: 0.5628 - acc: 0.9912 - val_loss: 0.8807 - val_acc: 0.9048\n",
      "Epoch 573/800\n",
      "114/114 [==============================] - 0s 891us/sample - loss: 0.5978 - acc: 0.9825 - val_loss: 0.8586 - val_acc: 0.9524\n",
      "Epoch 574/800\n",
      "114/114 [==============================] - 0s 891us/sample - loss: 0.5565 - acc: 0.9912 - val_loss: 0.8637 - val_acc: 0.9524\n",
      "Epoch 575/800\n",
      "114/114 [==============================] - 0s 2ms/sample - loss: 0.6078 - acc: 0.9737 - val_loss: 0.8968 - val_acc: 0.9524\n",
      "Epoch 576/800\n",
      "114/114 [==============================] - 0s 930us/sample - loss: 0.5501 - acc: 1.0000 - val_loss: 0.9247 - val_acc: 0.9524\n",
      "Epoch 577/800\n",
      "114/114 [==============================] - 0s 887us/sample - loss: 0.5790 - acc: 0.9912 - val_loss: 0.9116 - val_acc: 0.9524\n",
      "Epoch 578/800\n",
      "114/114 [==============================] - 0s 902us/sample - loss: 0.5533 - acc: 1.0000 - val_loss: 0.9013 - val_acc: 0.9524\n",
      "Epoch 579/800\n",
      "114/114 [==============================] - 0s 2ms/sample - loss: 0.5739 - acc: 0.9825 - val_loss: 0.8830 - val_acc: 0.9524\n",
      "Epoch 580/800\n",
      "114/114 [==============================] - 0s 940us/sample - loss: 0.5442 - acc: 1.0000 - val_loss: 0.8985 - val_acc: 0.9048\n",
      "Epoch 581/800\n",
      "114/114 [==============================] - 0s 901us/sample - loss: 0.5903 - acc: 0.9825 - val_loss: 0.9480 - val_acc: 0.9048\n",
      "Epoch 582/800\n",
      "114/114 [==============================] - 0s 881us/sample - loss: 0.5498 - acc: 1.0000 - val_loss: 0.9726 - val_acc: 0.9048\n",
      "Epoch 583/800\n",
      "114/114 [==============================] - 0s 933us/sample - loss: 0.5834 - acc: 0.9912 - val_loss: 0.9077 - val_acc: 0.9048\n",
      "Epoch 584/800\n",
      "114/114 [==============================] - 0s 903us/sample - loss: 0.5599 - acc: 0.9825 - val_loss: 0.8723 - val_acc: 0.9524\n",
      "Epoch 585/800\n",
      "114/114 [==============================] - 0s 902us/sample - loss: 0.5673 - acc: 0.9912 - val_loss: 0.8724 - val_acc: 0.9524\n",
      "Epoch 586/800\n",
      "114/114 [==============================] - 0s 880us/sample - loss: 0.5448 - acc: 1.0000 - val_loss: 0.8720 - val_acc: 0.9524\n",
      "Epoch 587/800\n",
      "114/114 [==============================] - 0s 2ms/sample - loss: 0.5412 - acc: 1.0000 - val_loss: 0.8720 - val_acc: 0.9524\n",
      "Epoch 588/800\n",
      "114/114 [==============================] - 0s 888us/sample - loss: 0.5575 - acc: 0.9912 - val_loss: 0.8679 - val_acc: 0.9524\n",
      "Epoch 589/800\n",
      "114/114 [==============================] - 0s 861us/sample - loss: 0.5495 - acc: 1.0000 - val_loss: 0.8644 - val_acc: 0.9524\n",
      "Epoch 590/800\n",
      "114/114 [==============================] - 0s 914us/sample - loss: 0.5556 - acc: 0.9912 - val_loss: 0.8639 - val_acc: 0.9524\n",
      "Epoch 591/800\n",
      "114/114 [==============================] - 0s 878us/sample - loss: 0.5757 - acc: 0.9825 - val_loss: 0.8773 - val_acc: 0.9524\n",
      "Epoch 592/800\n",
      "114/114 [==============================] - 0s 898us/sample - loss: 0.5596 - acc: 0.9912 - val_loss: 0.8784 - val_acc: 0.9524\n",
      "Epoch 593/800\n",
      "114/114 [==============================] - 0s 927us/sample - loss: 0.5683 - acc: 0.9825 - val_loss: 0.8585 - val_acc: 0.9524\n",
      "Epoch 594/800\n",
      "114/114 [==============================] - 0s 895us/sample - loss: 0.5456 - acc: 1.0000 - val_loss: 0.8776 - val_acc: 0.9048\n",
      "Epoch 595/800\n",
      "114/114 [==============================] - 0s 892us/sample - loss: 0.5543 - acc: 0.9912 - val_loss: 0.9052 - val_acc: 0.9048\n",
      "Epoch 596/800\n",
      "114/114 [==============================] - 0s 2ms/sample - loss: 0.5530 - acc: 0.9912 - val_loss: 0.8662 - val_acc: 0.9048\n",
      "Epoch 597/800\n",
      "114/114 [==============================] - 0s 947us/sample - loss: 0.5686 - acc: 0.9912 - val_loss: 0.8428 - val_acc: 0.9524\n",
      "Epoch 598/800\n",
      "114/114 [==============================] - 0s 895us/sample - loss: 0.5442 - acc: 1.0000 - val_loss: 0.8529 - val_acc: 0.9524\n",
      "Epoch 599/800\n",
      "114/114 [==============================] - 0s 892us/sample - loss: 0.5613 - acc: 0.9737 - val_loss: 0.8575 - val_acc: 0.9524\n",
      "Epoch 600/800\n",
      "114/114 [==============================] - 0s 2ms/sample - loss: 0.5568 - acc: 0.9912 - val_loss: 0.8580 - val_acc: 0.9524\n",
      "Epoch 601/800\n",
      "114/114 [==============================] - 0s 927us/sample - loss: 0.5471 - acc: 0.9912 - val_loss: 0.8660 - val_acc: 0.9524\n",
      "Epoch 602/800\n",
      "114/114 [==============================] - 0s 885us/sample - loss: 0.5466 - acc: 0.9912 - val_loss: 0.8745 - val_acc: 0.9524\n",
      "Epoch 603/800\n",
      "114/114 [==============================] - 0s 867us/sample - loss: 0.5643 - acc: 0.9912 - val_loss: 0.8848 - val_acc: 0.9048\n",
      "Epoch 604/800\n",
      "114/114 [==============================] - 0s 920us/sample - loss: 0.5388 - acc: 1.0000 - val_loss: 0.8999 - val_acc: 0.9048\n",
      "Epoch 605/800\n",
      "114/114 [==============================] - 0s 875us/sample - loss: 0.5430 - acc: 1.0000 - val_loss: 0.8977 - val_acc: 0.9048\n",
      "Epoch 606/800\n",
      "114/114 [==============================] - 0s 2ms/sample - loss: 0.5538 - acc: 0.9912 - val_loss: 0.8847 - val_acc: 0.9524\n",
      "Epoch 607/800\n",
      "114/114 [==============================] - 0s 898us/sample - loss: 0.5370 - acc: 1.0000 - val_loss: 0.9001 - val_acc: 0.9524\n",
      "Epoch 608/800\n",
      "114/114 [==============================] - 0s 888us/sample - loss: 0.5458 - acc: 0.9912 - val_loss: 0.8919 - val_acc: 0.9524\n",
      "Epoch 609/800\n",
      "114/114 [==============================] - 0s 899us/sample - loss: 0.5642 - acc: 0.9825 - val_loss: 0.8719 - val_acc: 0.9524\n",
      "Epoch 610/800\n",
      "114/114 [==============================] - 0s 2ms/sample - loss: 0.5434 - acc: 1.0000 - val_loss: 0.8727 - val_acc: 0.9524\n",
      "Epoch 611/800\n",
      "114/114 [==============================] - 0s 946us/sample - loss: 0.5472 - acc: 0.9912 - val_loss: 0.8772 - val_acc: 0.9524\n",
      "Epoch 612/800\n",
      "114/114 [==============================] - 0s 888us/sample - loss: 0.5456 - acc: 0.9912 - val_loss: 0.8793 - val_acc: 0.9524\n",
      "Epoch 613/800\n",
      "114/114 [==============================] - 0s 899us/sample - loss: 0.5357 - acc: 1.0000 - val_loss: 0.8844 - val_acc: 0.9048\n",
      "Epoch 614/800\n",
      "114/114 [==============================] - 0s 868us/sample - loss: 0.5402 - acc: 1.0000 - val_loss: 0.8821 - val_acc: 0.9524\n",
      "Epoch 615/800\n",
      "114/114 [==============================] - 0s 935us/sample - loss: 0.5472 - acc: 0.9912 - val_loss: 0.8829 - val_acc: 0.9524\n",
      "Epoch 616/800\n",
      "114/114 [==============================] - 0s 900us/sample - loss: 0.5350 - acc: 1.0000 - val_loss: 0.9050 - val_acc: 0.9524\n",
      "Epoch 617/800\n",
      "114/114 [==============================] - 0s 902us/sample - loss: 0.5357 - acc: 1.0000 - val_loss: 0.9210 - val_acc: 0.9524\n",
      "Epoch 618/800\n",
      "114/114 [==============================] - 0s 2ms/sample - loss: 0.5394 - acc: 0.9912 - val_loss: 0.9218 - val_acc: 0.9524\n",
      "Epoch 619/800\n",
      "114/114 [==============================] - 0s 943us/sample - loss: 0.6216 - acc: 0.9737 - val_loss: 0.8835 - val_acc: 0.9524\n",
      "Epoch 620/800\n",
      "114/114 [==============================] - 0s 892us/sample - loss: 0.5504 - acc: 0.9912 - val_loss: 0.9193 - val_acc: 0.9048\n",
      "Epoch 621/800\n",
      "114/114 [==============================] - 0s 897us/sample - loss: 0.5401 - acc: 1.0000 - val_loss: 0.9729 - val_acc: 0.9048\n",
      "Epoch 622/800\n",
      "114/114 [==============================] - 0s 2ms/sample - loss: 0.5476 - acc: 0.9825 - val_loss: 0.9517 - val_acc: 0.9048\n",
      "Epoch 623/800\n",
      "114/114 [==============================] - 0s 893us/sample - loss: 0.5388 - acc: 1.0000 - val_loss: 0.8906 - val_acc: 0.9048\n",
      "Epoch 624/800\n",
      "114/114 [==============================] - 0s 934us/sample - loss: 0.5481 - acc: 0.9825 - val_loss: 0.8637 - val_acc: 0.9524\n",
      "Epoch 625/800\n",
      "114/114 [==============================] - 0s 888us/sample - loss: 0.5488 - acc: 0.9912 - val_loss: 0.9027 - val_acc: 0.9524\n",
      "Epoch 626/800\n",
      "114/114 [==============================] - 0s 876us/sample - loss: 0.5624 - acc: 0.9825 - val_loss: 0.9167 - val_acc: 0.9524\n",
      "Epoch 627/800\n",
      "114/114 [==============================] - 0s 934us/sample - loss: 0.5328 - acc: 1.0000 - val_loss: 0.8980 - val_acc: 0.9524\n",
      "Epoch 628/800\n",
      "114/114 [==============================] - 0s 907us/sample - loss: 0.5560 - acc: 0.9825 - val_loss: 0.8828 - val_acc: 0.9524\n",
      "Epoch 629/800\n",
      "114/114 [==============================] - 0s 900us/sample - loss: 0.5403 - acc: 1.0000 - val_loss: 0.9028 - val_acc: 0.9048\n",
      "Epoch 630/800\n",
      "114/114 [==============================] - 0s 873us/sample - loss: 0.5354 - acc: 1.0000 - val_loss: 0.8849 - val_acc: 0.9524\n",
      "Epoch 631/800\n",
      "114/114 [==============================] - 0s 2ms/sample - loss: 0.5349 - acc: 1.0000 - val_loss: 0.8915 - val_acc: 0.9524\n",
      "Epoch 632/800\n",
      "114/114 [==============================] - 0s 910us/sample - loss: 0.5577 - acc: 0.9912 - val_loss: 0.8838 - val_acc: 0.9524\n",
      "Epoch 633/800\n",
      "114/114 [==============================] - 0s 897us/sample - loss: 0.5565 - acc: 0.9825 - val_loss: 0.8790 - val_acc: 0.9524\n",
      "Epoch 634/800\n",
      "114/114 [==============================] - 0s 889us/sample - loss: 0.5554 - acc: 0.9825 - val_loss: 0.8792 - val_acc: 0.9524\n",
      "Epoch 635/800\n",
      "114/114 [==============================] - 0s 2ms/sample - loss: 0.5413 - acc: 1.0000 - val_loss: 0.8946 - val_acc: 0.9524\n",
      "Epoch 636/800\n",
      "114/114 [==============================] - 0s 870us/sample - loss: 0.5628 - acc: 0.9737 - val_loss: 0.8975 - val_acc: 0.9524\n",
      "Epoch 637/800\n",
      "114/114 [==============================] - 0s 897us/sample - loss: 0.5488 - acc: 0.9912 - val_loss: 0.9168 - val_acc: 0.9524\n",
      "Epoch 638/800\n",
      "114/114 [==============================] - 0s 896us/sample - loss: 0.5422 - acc: 0.9912 - val_loss: 0.9408 - val_acc: 0.9524\n",
      "Epoch 639/800\n",
      "114/114 [==============================] - 0s 934us/sample - loss: 0.5377 - acc: 0.9912 - val_loss: 0.9574 - val_acc: 0.9524\n",
      "Epoch 640/800\n",
      "114/114 [==============================] - 0s 896us/sample - loss: 0.5349 - acc: 1.0000 - val_loss: 0.9399 - val_acc: 0.9524\n",
      "Epoch 641/800\n",
      "114/114 [==============================] - 0s 898us/sample - loss: 0.5502 - acc: 0.9912 - val_loss: 0.9227 - val_acc: 0.9524\n",
      "Epoch 642/800\n",
      "114/114 [==============================] - 0s 889us/sample - loss: 0.5440 - acc: 0.9825 - val_loss: 0.9093 - val_acc: 0.9524\n",
      "Epoch 643/800\n",
      "114/114 [==============================] - 0s 2ms/sample - loss: 0.5309 - acc: 1.0000 - val_loss: 0.8770 - val_acc: 0.9524\n",
      "Epoch 644/800\n",
      "114/114 [==============================] - 0s 889us/sample - loss: 0.5285 - acc: 1.0000 - val_loss: 0.8740 - val_acc: 0.9524\n",
      "Epoch 645/800\n",
      "114/114 [==============================] - 0s 892us/sample - loss: 0.5332 - acc: 1.0000 - val_loss: 0.8967 - val_acc: 0.9048\n",
      "Epoch 646/800\n",
      "114/114 [==============================] - 0s 916us/sample - loss: 0.5319 - acc: 1.0000 - val_loss: 0.9097 - val_acc: 0.9048\n",
      "Epoch 647/800\n",
      "114/114 [==============================] - 0s 869us/sample - loss: 0.5456 - acc: 0.9912 - val_loss: 0.8871 - val_acc: 0.9048\n",
      "Epoch 648/800\n",
      "114/114 [==============================] - 0s 2ms/sample - loss: 0.5336 - acc: 1.0000 - val_loss: 0.8937 - val_acc: 0.9048\n",
      "Epoch 649/800\n",
      "114/114 [==============================] - 0s 906us/sample - loss: 0.5557 - acc: 0.9825 - val_loss: 0.8674 - val_acc: 0.9524\n",
      "Epoch 650/800\n",
      "114/114 [==============================] - 0s 905us/sample - loss: 0.5261 - acc: 1.0000 - val_loss: 0.8585 - val_acc: 0.9524\n",
      "Epoch 651/800\n",
      "114/114 [==============================] - 0s 887us/sample - loss: 0.5314 - acc: 1.0000 - val_loss: 0.8609 - val_acc: 0.9524\n",
      "Epoch 652/800\n",
      "114/114 [==============================] - 0s 2ms/sample - loss: 0.5270 - acc: 1.0000 - val_loss: 0.8672 - val_acc: 0.9524\n",
      "Epoch 653/800\n",
      "114/114 [==============================] - 0s 893us/sample - loss: 0.5285 - acc: 1.0000 - val_loss: 0.8688 - val_acc: 0.9524\n",
      "Epoch 654/800\n",
      "114/114 [==============================] - 0s 900us/sample - loss: 0.5633 - acc: 0.9825 - val_loss: 0.8736 - val_acc: 0.9524\n",
      "Epoch 655/800\n",
      "114/114 [==============================] - 0s 913us/sample - loss: 0.5334 - acc: 1.0000 - val_loss: 0.8669 - val_acc: 0.9524\n",
      "Epoch 656/800\n",
      "114/114 [==============================] - 0s 870us/sample - loss: 0.5276 - acc: 1.0000 - val_loss: 0.8629 - val_acc: 0.9524\n",
      "Epoch 657/800\n",
      "114/114 [==============================] - 0s 934us/sample - loss: 0.5281 - acc: 0.9912 - val_loss: 0.8701 - val_acc: 0.9524\n",
      "Epoch 658/800\n",
      "114/114 [==============================] - 0s 896us/sample - loss: 0.5334 - acc: 0.9912 - val_loss: 0.8678 - val_acc: 0.9524\n",
      "Epoch 659/800\n",
      "114/114 [==============================] - 0s 910us/sample - loss: 0.5453 - acc: 0.9912 - val_loss: 0.8709 - val_acc: 0.9524\n",
      "Epoch 660/800\n",
      "114/114 [==============================] - 0s 874us/sample - loss: 0.5237 - acc: 1.0000 - val_loss: 0.8691 - val_acc: 0.9524\n",
      "Epoch 661/800\n",
      "114/114 [==============================] - 0s 2ms/sample - loss: 0.5228 - acc: 1.0000 - val_loss: 0.8774 - val_acc: 0.9048\n",
      "Epoch 662/800\n",
      "114/114 [==============================] - 0s 897us/sample - loss: 0.5576 - acc: 0.9912 - val_loss: 0.8645 - val_acc: 0.9524\n",
      "Epoch 663/800\n",
      "114/114 [==============================] - 0s 891us/sample - loss: 0.5217 - acc: 1.0000 - val_loss: 0.8632 - val_acc: 0.9524\n",
      "Epoch 664/800\n",
      "114/114 [==============================] - 0s 893us/sample - loss: 0.5223 - acc: 1.0000 - val_loss: 0.8664 - val_acc: 0.9524\n",
      "Epoch 665/800\n",
      "114/114 [==============================] - 0s 890us/sample - loss: 0.5298 - acc: 1.0000 - val_loss: 0.8607 - val_acc: 0.9524\n",
      "Epoch 666/800\n",
      "114/114 [==============================] - 0s 941us/sample - loss: 0.5317 - acc: 0.9912 - val_loss: 0.8635 - val_acc: 0.9524\n",
      "Epoch 667/800\n",
      "114/114 [==============================] - 0s 899us/sample - loss: 0.5230 - acc: 1.0000 - val_loss: 0.8683 - val_acc: 0.9524\n",
      "Epoch 668/800\n",
      "114/114 [==============================] - 0s 886us/sample - loss: 0.5291 - acc: 1.0000 - val_loss: 0.8798 - val_acc: 0.9524\n",
      "Epoch 669/800\n",
      "114/114 [==============================] - 0s 2ms/sample - loss: 0.5195 - acc: 1.0000 - val_loss: 0.8960 - val_acc: 0.9524\n",
      "Epoch 670/800\n",
      "114/114 [==============================] - 0s 940us/sample - loss: 0.5185 - acc: 1.0000 - val_loss: 0.9077 - val_acc: 0.9524\n",
      "Epoch 671/800\n",
      "114/114 [==============================] - 0s 877us/sample - loss: 0.5196 - acc: 1.0000 - val_loss: 0.9148 - val_acc: 0.9524\n",
      "Epoch 672/800\n",
      "114/114 [==============================] - 0s 904us/sample - loss: 0.5316 - acc: 0.9912 - val_loss: 0.9098 - val_acc: 0.9524\n",
      "Epoch 673/800\n",
      "114/114 [==============================] - 0s 878us/sample - loss: 0.5263 - acc: 1.0000 - val_loss: 0.8897 - val_acc: 0.9524\n",
      "Epoch 674/800\n",
      "114/114 [==============================] - 0s 2ms/sample - loss: 0.5165 - acc: 1.0000 - val_loss: 0.8717 - val_acc: 0.9524\n",
      "Epoch 675/800\n",
      "114/114 [==============================] - 0s 912us/sample - loss: 0.5208 - acc: 1.0000 - val_loss: 0.8707 - val_acc: 0.9524\n",
      "Epoch 676/800\n",
      "114/114 [==============================] - 0s 900us/sample - loss: 0.5398 - acc: 0.9912 - val_loss: 0.8748 - val_acc: 0.9524\n",
      "Epoch 677/800\n",
      "114/114 [==============================] - 0s 876us/sample - loss: 0.5182 - acc: 1.0000 - val_loss: 0.8848 - val_acc: 0.9524\n",
      "Epoch 678/800\n",
      "114/114 [==============================] - 0s 2ms/sample - loss: 0.5154 - acc: 1.0000 - val_loss: 0.8921 - val_acc: 0.9524\n",
      "Epoch 679/800\n",
      "114/114 [==============================] - 0s 890us/sample - loss: 0.5212 - acc: 1.0000 - val_loss: 0.8878 - val_acc: 0.9524\n",
      "Epoch 680/800\n",
      "114/114 [==============================] - 0s 928us/sample - loss: 0.5147 - acc: 1.0000 - val_loss: 0.8771 - val_acc: 0.9524\n",
      "Epoch 681/800\n",
      "114/114 [==============================] - 0s 904us/sample - loss: 0.5158 - acc: 1.0000 - val_loss: 0.8814 - val_acc: 0.9524\n",
      "Epoch 682/800\n",
      "114/114 [==============================] - 0s 2ms/sample - loss: 0.5210 - acc: 0.9912 - val_loss: 0.8783 - val_acc: 0.9524\n",
      "Epoch 683/800\n",
      "114/114 [==============================] - 0s 902us/sample - loss: 0.5353 - acc: 0.9912 - val_loss: 0.8873 - val_acc: 0.9524\n",
      "Epoch 684/800\n",
      "114/114 [==============================] - 0s 889us/sample - loss: 0.5466 - acc: 0.9912 - val_loss: 0.8871 - val_acc: 0.9524\n",
      "Epoch 685/800\n",
      "114/114 [==============================] - 0s 884us/sample - loss: 0.5135 - acc: 1.0000 - val_loss: 0.8794 - val_acc: 0.9524\n",
      "Epoch 686/800\n",
      "114/114 [==============================] - 0s 888us/sample - loss: 0.5160 - acc: 1.0000 - val_loss: 0.8821 - val_acc: 0.9524\n",
      "Epoch 687/800\n",
      "114/114 [==============================] - 0s 2ms/sample - loss: 0.5162 - acc: 1.0000 - val_loss: 0.8848 - val_acc: 0.9524\n",
      "Epoch 688/800\n",
      "114/114 [==============================] - 0s 933us/sample - loss: 0.5597 - acc: 0.9825 - val_loss: 0.8728 - val_acc: 0.9524\n",
      "Epoch 689/800\n",
      "114/114 [==============================] - 0s 889us/sample - loss: 0.5128 - acc: 1.0000 - val_loss: 0.8609 - val_acc: 0.9524\n",
      "Epoch 690/800\n",
      "114/114 [==============================] - 0s 2ms/sample - loss: 0.5184 - acc: 1.0000 - val_loss: 0.8721 - val_acc: 0.9524\n",
      "Epoch 691/800\n",
      "114/114 [==============================] - 0s 970us/sample - loss: 0.5481 - acc: 0.9912 - val_loss: 0.9029 - val_acc: 0.9048\n",
      "Epoch 692/800\n",
      "114/114 [==============================] - 0s 857us/sample - loss: 0.5187 - acc: 0.9912 - val_loss: 0.8798 - val_acc: 0.9524\n",
      "Epoch 693/800\n",
      "114/114 [==============================] - 0s 890us/sample - loss: 0.5102 - acc: 1.0000 - val_loss: 0.8845 - val_acc: 0.9524\n",
      "Epoch 694/800\n",
      "114/114 [==============================] - 0s 2ms/sample - loss: 0.5294 - acc: 0.9912 - val_loss: 0.8933 - val_acc: 0.9524\n",
      "Epoch 695/800\n",
      "114/114 [==============================] - 0s 864us/sample - loss: 0.5109 - acc: 1.0000 - val_loss: 0.8862 - val_acc: 0.9524\n",
      "Epoch 696/800\n",
      "114/114 [==============================] - 0s 913us/sample - loss: 0.5094 - acc: 1.0000 - val_loss: 0.8811 - val_acc: 0.9524\n",
      "Epoch 697/800\n",
      "114/114 [==============================] - 0s 903us/sample - loss: 0.5495 - acc: 0.9912 - val_loss: 0.8813 - val_acc: 0.9524\n",
      "Epoch 698/800\n",
      "114/114 [==============================] - 0s 871us/sample - loss: 0.5109 - acc: 1.0000 - val_loss: 0.8891 - val_acc: 0.9524\n",
      "Epoch 699/800\n",
      "114/114 [==============================] - 0s 2ms/sample - loss: 0.5167 - acc: 0.9912 - val_loss: 0.9026 - val_acc: 0.9524\n",
      "Epoch 700/800\n",
      "114/114 [==============================] - 0s 898us/sample - loss: 0.5125 - acc: 1.0000 - val_loss: 0.9139 - val_acc: 0.9524\n",
      "Epoch 701/800\n",
      "114/114 [==============================] - 0s 896us/sample - loss: 0.5330 - acc: 0.9912 - val_loss: 0.9144 - val_acc: 0.9524\n",
      "Epoch 702/800\n",
      "114/114 [==============================] - 0s 887us/sample - loss: 0.5094 - acc: 1.0000 - val_loss: 0.9000 - val_acc: 0.9524\n",
      "Epoch 703/800\n",
      "114/114 [==============================] - 0s 2ms/sample - loss: 0.5116 - acc: 1.0000 - val_loss: 0.8919 - val_acc: 0.9524\n",
      "Epoch 704/800\n",
      "114/114 [==============================] - 0s 926us/sample - loss: 0.5109 - acc: 1.0000 - val_loss: 0.8884 - val_acc: 0.9524\n",
      "Epoch 705/800\n",
      "114/114 [==============================] - 0s 911us/sample - loss: 0.5094 - acc: 1.0000 - val_loss: 0.8861 - val_acc: 0.9524\n",
      "Epoch 706/800\n",
      "114/114 [==============================] - 0s 883us/sample - loss: 0.5112 - acc: 1.0000 - val_loss: 0.8854 - val_acc: 0.9524\n",
      "Epoch 707/800\n",
      "114/114 [==============================] - 0s 871us/sample - loss: 0.5122 - acc: 1.0000 - val_loss: 0.8840 - val_acc: 0.9524\n",
      "Epoch 708/800\n",
      "114/114 [==============================] - 0s 2ms/sample - loss: 0.5280 - acc: 0.9912 - val_loss: 0.8828 - val_acc: 0.9524\n",
      "Epoch 709/800\n",
      "114/114 [==============================] - 0s 911us/sample - loss: 0.5113 - acc: 1.0000 - val_loss: 0.9094 - val_acc: 0.9524\n",
      "Epoch 710/800\n",
      "114/114 [==============================] - 0s 889us/sample - loss: 0.5110 - acc: 1.0000 - val_loss: 0.9264 - val_acc: 0.9524\n",
      "Epoch 711/800\n",
      "114/114 [==============================] - 0s 898us/sample - loss: 0.5250 - acc: 0.9912 - val_loss: 0.9128 - val_acc: 0.9524\n",
      "Epoch 712/800\n",
      "114/114 [==============================] - 0s 2ms/sample - loss: 0.5122 - acc: 1.0000 - val_loss: 0.8917 - val_acc: 0.9524\n",
      "Epoch 713/800\n",
      "114/114 [==============================] - 0s 905us/sample - loss: 0.5094 - acc: 1.0000 - val_loss: 0.8778 - val_acc: 0.9524\n",
      "Epoch 714/800\n",
      "114/114 [==============================] - 0s 897us/sample - loss: 0.5249 - acc: 0.9825 - val_loss: 0.8926 - val_acc: 0.9524\n",
      "Epoch 715/800\n",
      "114/114 [==============================] - 0s 893us/sample - loss: 0.5269 - acc: 0.9912 - val_loss: 0.9084 - val_acc: 0.9524\n",
      "Epoch 716/800\n",
      "114/114 [==============================] - 0s 935us/sample - loss: 0.5243 - acc: 0.9912 - val_loss: 0.9264 - val_acc: 0.9524\n",
      "Epoch 717/800\n",
      "114/114 [==============================] - 0s 897us/sample - loss: 0.5188 - acc: 1.0000 - val_loss: 0.9381 - val_acc: 0.9524\n",
      "Epoch 718/800\n",
      "114/114 [==============================] - 0s 894us/sample - loss: 0.5180 - acc: 0.9912 - val_loss: 0.9260 - val_acc: 0.9524\n",
      "Epoch 719/800\n",
      "114/114 [==============================] - 0s 893us/sample - loss: 0.5050 - acc: 1.0000 - val_loss: 0.9184 - val_acc: 0.9524\n",
      "Epoch 720/800\n",
      "114/114 [==============================] - 0s 2ms/sample - loss: 0.5242 - acc: 0.9912 - val_loss: 0.8978 - val_acc: 0.9524\n",
      "Epoch 721/800\n",
      "114/114 [==============================] - 0s 926us/sample - loss: 0.5405 - acc: 0.9912 - val_loss: 0.9315 - val_acc: 0.9048\n",
      "Epoch 722/800\n",
      "114/114 [==============================] - 0s 912us/sample - loss: 0.5057 - acc: 1.0000 - val_loss: 0.9809 - val_acc: 0.9048\n",
      "Epoch 723/800\n",
      "114/114 [==============================] - 0s 890us/sample - loss: 0.5028 - acc: 1.0000 - val_loss: 1.0004 - val_acc: 0.9048\n",
      "Epoch 724/800\n",
      "114/114 [==============================] - 0s 876us/sample - loss: 0.5062 - acc: 1.0000 - val_loss: 0.9919 - val_acc: 0.9048\n",
      "Epoch 725/800\n",
      "114/114 [==============================] - 0s 929us/sample - loss: 0.5519 - acc: 0.9912 - val_loss: 0.9121 - val_acc: 0.9524\n",
      "Epoch 726/800\n",
      "114/114 [==============================] - 0s 928us/sample - loss: 0.5225 - acc: 0.9912 - val_loss: 0.9015 - val_acc: 0.9524\n",
      "Epoch 727/800\n",
      "114/114 [==============================] - 0s 885us/sample - loss: 0.5180 - acc: 0.9912 - val_loss: 0.8876 - val_acc: 0.9524\n",
      "Epoch 728/800\n",
      "114/114 [==============================] - 0s 2ms/sample - loss: 0.5037 - acc: 1.0000 - val_loss: 0.8855 - val_acc: 0.9524\n",
      "Epoch 729/800\n",
      "114/114 [==============================] - 0s 944us/sample - loss: 0.5032 - acc: 1.0000 - val_loss: 0.8850 - val_acc: 0.9524\n",
      "Epoch 730/800\n",
      "114/114 [==============================] - 0s 871us/sample - loss: 0.5043 - acc: 1.0000 - val_loss: 0.8846 - val_acc: 0.9524\n",
      "Epoch 731/800\n",
      "114/114 [==============================] - 0s 897us/sample - loss: 0.5322 - acc: 0.9912 - val_loss: 0.8741 - val_acc: 0.9524\n",
      "Epoch 732/800\n",
      "114/114 [==============================] - 0s 893us/sample - loss: 0.5208 - acc: 0.9825 - val_loss: 0.8727 - val_acc: 0.9524\n",
      "Epoch 733/800\n",
      "114/114 [==============================] - 0s 2ms/sample - loss: 0.5054 - acc: 1.0000 - val_loss: 0.8840 - val_acc: 0.9524\n",
      "Epoch 734/800\n",
      "114/114 [==============================] - 0s 893us/sample - loss: 0.5124 - acc: 0.9912 - val_loss: 0.8869 - val_acc: 0.9524\n",
      "Epoch 735/800\n",
      "114/114 [==============================] - 0s 904us/sample - loss: 0.5213 - acc: 0.9912 - val_loss: 0.8805 - val_acc: 0.9524\n",
      "Epoch 736/800\n",
      "114/114 [==============================] - 0s 888us/sample - loss: 0.5020 - acc: 1.0000 - val_loss: 0.8851 - val_acc: 0.9048\n",
      "Epoch 737/800\n",
      "114/114 [==============================] - 0s 2ms/sample - loss: 0.5246 - acc: 0.9737 - val_loss: 0.9123 - val_acc: 0.9048\n",
      "Epoch 738/800\n",
      "114/114 [==============================] - 0s 941us/sample - loss: 0.5139 - acc: 0.9912 - val_loss: 0.8844 - val_acc: 0.9524\n",
      "Epoch 739/800\n",
      "114/114 [==============================] - 0s 894us/sample - loss: 0.4982 - acc: 1.0000 - val_loss: 0.9082 - val_acc: 0.9524\n",
      "Epoch 740/800\n",
      "114/114 [==============================] - 0s 896us/sample - loss: 0.5629 - acc: 0.9825 - val_loss: 0.9399 - val_acc: 0.9524\n",
      "Epoch 741/800\n",
      "114/114 [==============================] - 0s 873us/sample - loss: 0.5030 - acc: 1.0000 - val_loss: 0.9442 - val_acc: 0.9524\n",
      "Epoch 742/800\n",
      "114/114 [==============================] - 0s 935us/sample - loss: 0.5014 - acc: 1.0000 - val_loss: 0.9387 - val_acc: 0.9524\n",
      "Epoch 743/800\n",
      "114/114 [==============================] - 0s 895us/sample - loss: 0.5119 - acc: 0.9912 - val_loss: 0.9152 - val_acc: 0.9524\n",
      "Epoch 744/800\n",
      "114/114 [==============================] - 0s 912us/sample - loss: 0.5077 - acc: 1.0000 - val_loss: 0.8894 - val_acc: 0.9524\n",
      "Epoch 745/800\n",
      "114/114 [==============================] - 0s 873us/sample - loss: 0.5455 - acc: 0.9825 - val_loss: 0.8661 - val_acc: 0.9524\n",
      "Epoch 746/800\n",
      "114/114 [==============================] - 0s 2ms/sample - loss: 0.5028 - acc: 1.0000 - val_loss: 0.8753 - val_acc: 0.9524\n",
      "Epoch 747/800\n",
      "114/114 [==============================] - 0s 896us/sample - loss: 0.5758 - acc: 0.9737 - val_loss: 0.9108 - val_acc: 0.9524\n",
      "Epoch 748/800\n",
      "114/114 [==============================] - 0s 892us/sample - loss: 0.5071 - acc: 0.9912 - val_loss: 0.9200 - val_acc: 0.9524\n",
      "Epoch 749/800\n",
      "114/114 [==============================] - 0s 896us/sample - loss: 0.5074 - acc: 1.0000 - val_loss: 0.9261 - val_acc: 0.9524\n",
      "Epoch 750/800\n",
      "114/114 [==============================] - 0s 2ms/sample - loss: 0.5594 - acc: 0.9737 - val_loss: 0.9194 - val_acc: 0.9524\n",
      "Epoch 751/800\n",
      "114/114 [==============================] - 0s 900us/sample - loss: 0.5124 - acc: 0.9912 - val_loss: 0.9109 - val_acc: 0.9524\n",
      "Epoch 752/800\n",
      "114/114 [==============================] - 0s 896us/sample - loss: 0.5067 - acc: 0.9912 - val_loss: 0.8840 - val_acc: 0.9524\n",
      "Epoch 753/800\n",
      "114/114 [==============================] - 0s 887us/sample - loss: 0.5237 - acc: 0.9912 - val_loss: 0.8522 - val_acc: 0.9524\n",
      "Epoch 754/800\n",
      "114/114 [==============================] - 0s 2ms/sample - loss: 0.5011 - acc: 1.0000 - val_loss: 0.8344 - val_acc: 0.9524\n",
      "Epoch 755/800\n",
      "114/114 [==============================] - 0s 908us/sample - loss: 0.5102 - acc: 0.9825 - val_loss: 0.8382 - val_acc: 0.9524\n",
      "Epoch 756/800\n",
      "114/114 [==============================] - 0s 895us/sample - loss: 0.6034 - acc: 0.9737 - val_loss: 0.8358 - val_acc: 0.9524\n",
      "Epoch 757/800\n",
      "114/114 [==============================] - 0s 897us/sample - loss: 0.5025 - acc: 0.9912 - val_loss: 0.9015 - val_acc: 0.9048\n",
      "Epoch 758/800\n",
      "114/114 [==============================] - 0s 2ms/sample - loss: 0.5041 - acc: 0.9912 - val_loss: 0.8549 - val_acc: 0.9048\n",
      "Epoch 759/800\n",
      "114/114 [==============================] - 0s 896us/sample - loss: 0.5902 - acc: 0.9825 - val_loss: 0.8390 - val_acc: 0.9524\n",
      "Epoch 760/800\n",
      "114/114 [==============================] - 0s 940us/sample - loss: 0.4974 - acc: 1.0000 - val_loss: 0.8350 - val_acc: 0.9524\n",
      "Epoch 761/800\n",
      "114/114 [==============================] - 0s 891us/sample - loss: 0.4951 - acc: 1.0000 - val_loss: 0.8434 - val_acc: 0.9524\n",
      "Epoch 762/800\n",
      "114/114 [==============================] - 0s 2ms/sample - loss: 0.5221 - acc: 0.9825 - val_loss: 0.8442 - val_acc: 0.9524\n",
      "Epoch 763/800\n",
      "114/114 [==============================] - 0s 893us/sample - loss: 0.4978 - acc: 1.0000 - val_loss: 0.8296 - val_acc: 0.9524\n",
      "Epoch 764/800\n",
      "114/114 [==============================] - 0s 915us/sample - loss: 0.5134 - acc: 0.9912 - val_loss: 0.8367 - val_acc: 0.9048\n",
      "Epoch 765/800\n",
      "114/114 [==============================] - 0s 873us/sample - loss: 0.4934 - acc: 1.0000 - val_loss: 0.8487 - val_acc: 0.9048\n",
      "Epoch 766/800\n",
      "114/114 [==============================] - 0s 2ms/sample - loss: 0.5069 - acc: 0.9912 - val_loss: 0.8606 - val_acc: 0.9048\n",
      "Epoch 767/800\n",
      "114/114 [==============================] - 0s 907us/sample - loss: 0.4965 - acc: 1.0000 - val_loss: 0.8577 - val_acc: 0.9048\n",
      "Epoch 768/800\n",
      "114/114 [==============================] - 0s 899us/sample - loss: 0.5088 - acc: 0.9912 - val_loss: 0.8379 - val_acc: 0.9524\n",
      "Epoch 769/800\n",
      "114/114 [==============================] - 0s 894us/sample - loss: 0.4920 - acc: 1.0000 - val_loss: 0.8550 - val_acc: 0.9524\n",
      "Epoch 770/800\n",
      "114/114 [==============================] - 0s 934us/sample - loss: 0.5078 - acc: 0.9912 - val_loss: 0.8619 - val_acc: 0.9524\n",
      "Epoch 771/800\n",
      "114/114 [==============================] - 0s 898us/sample - loss: 0.4987 - acc: 1.0000 - val_loss: 0.8517 - val_acc: 0.9524\n",
      "Epoch 772/800\n",
      "114/114 [==============================] - 0s 912us/sample - loss: 0.4939 - acc: 1.0000 - val_loss: 0.8431 - val_acc: 0.9524\n",
      "Epoch 773/800\n",
      "114/114 [==============================] - 0s 873us/sample - loss: 0.5066 - acc: 0.9912 - val_loss: 0.8473 - val_acc: 0.9524\n",
      "Epoch 774/800\n",
      "114/114 [==============================] - 0s 2ms/sample - loss: 0.4928 - acc: 1.0000 - val_loss: 0.9425 - val_acc: 0.9048\n",
      "Epoch 775/800\n",
      "114/114 [==============================] - 0s 899us/sample - loss: 0.5026 - acc: 0.9912 - val_loss: 0.9839 - val_acc: 0.9048\n",
      "Epoch 776/800\n",
      "114/114 [==============================] - 0s 894us/sample - loss: 0.5039 - acc: 0.9825 - val_loss: 0.8779 - val_acc: 0.9048\n",
      "Epoch 777/800\n",
      "114/114 [==============================] - 0s 893us/sample - loss: 0.4931 - acc: 1.0000 - val_loss: 0.8609 - val_acc: 0.9524\n",
      "Epoch 778/800\n",
      "114/114 [==============================] - 0s 933us/sample - loss: 0.5632 - acc: 0.9737 - val_loss: 0.8867 - val_acc: 0.9524\n",
      "Epoch 779/800\n",
      "114/114 [==============================] - 0s 893us/sample - loss: 0.4967 - acc: 0.9912 - val_loss: 0.8957 - val_acc: 0.9524\n",
      "Epoch 780/800\n",
      "114/114 [==============================] - 0s 897us/sample - loss: 0.5144 - acc: 0.9912 - val_loss: 0.8672 - val_acc: 0.9524\n",
      "Epoch 781/800\n",
      "114/114 [==============================] - 0s 890us/sample - loss: 0.5012 - acc: 0.9912 - val_loss: 0.8476 - val_acc: 0.9524\n",
      "Epoch 782/800\n",
      "114/114 [==============================] - 0s 2ms/sample - loss: 0.4871 - acc: 1.0000 - val_loss: 0.9006 - val_acc: 0.9048\n",
      "Epoch 783/800\n",
      "114/114 [==============================] - 0s 900us/sample - loss: 0.5173 - acc: 0.9912 - val_loss: 0.9472 - val_acc: 0.9048\n",
      "Epoch 784/800\n",
      "114/114 [==============================] - 0s 886us/sample - loss: 0.5434 - acc: 0.9912 - val_loss: 0.8904 - val_acc: 0.9048\n",
      "Epoch 785/800\n",
      "114/114 [==============================] - 0s 892us/sample - loss: 0.4952 - acc: 0.9912 - val_loss: 0.8501 - val_acc: 0.9524\n",
      "Epoch 786/800\n",
      "114/114 [==============================] - 0s 871us/sample - loss: 0.4896 - acc: 1.0000 - val_loss: 0.8781 - val_acc: 0.9524\n",
      "Epoch 787/800\n",
      "114/114 [==============================] - 0s 951us/sample - loss: 0.5736 - acc: 0.9737 - val_loss: 0.8714 - val_acc: 0.9524\n",
      "Epoch 788/800\n",
      "114/114 [==============================] - 0s 897us/sample - loss: 0.4893 - acc: 1.0000 - val_loss: 0.8555 - val_acc: 0.9524\n",
      "Epoch 789/800\n",
      "114/114 [==============================] - 0s 937us/sample - loss: 0.4980 - acc: 0.9912 - val_loss: 0.8437 - val_acc: 0.9524\n",
      "Epoch 790/800\n",
      "114/114 [==============================] - 0s 927us/sample - loss: 0.5066 - acc: 0.9912 - val_loss: 0.8353 - val_acc: 0.9524\n",
      "Epoch 791/800\n",
      "114/114 [==============================] - 0s 908us/sample - loss: 0.4853 - acc: 1.0000 - val_loss: 0.8529 - val_acc: 0.9048\n",
      "Epoch 792/800\n",
      "114/114 [==============================] - 0s 894us/sample - loss: 0.4991 - acc: 0.9912 - val_loss: 0.8488 - val_acc: 0.9048\n",
      "Epoch 793/800\n",
      "114/114 [==============================] - 0s 887us/sample - loss: 0.5108 - acc: 0.9912 - val_loss: 0.8262 - val_acc: 0.9524\n",
      "Epoch 794/800\n",
      "114/114 [==============================] - 0s 2ms/sample - loss: 0.5021 - acc: 0.9825 - val_loss: 0.8094 - val_acc: 0.9524\n",
      "Epoch 795/800\n",
      "114/114 [==============================] - 0s 949us/sample - loss: 0.5045 - acc: 0.9912 - val_loss: 0.8223 - val_acc: 0.9524\n",
      "Epoch 796/800\n",
      "114/114 [==============================] - 0s 896us/sample - loss: 0.4864 - acc: 1.0000 - val_loss: 0.8597 - val_acc: 0.9524\n",
      "Epoch 797/800\n",
      "114/114 [==============================] - 0s 887us/sample - loss: 0.4940 - acc: 1.0000 - val_loss: 0.8776 - val_acc: 0.9524\n",
      "Epoch 798/800\n",
      "114/114 [==============================] - 0s 877us/sample - loss: 0.4844 - acc: 1.0000 - val_loss: 0.8690 - val_acc: 0.9524\n",
      "Epoch 799/800\n",
      "114/114 [==============================] - 0s 895us/sample - loss: 0.4847 - acc: 1.0000 - val_loss: 0.8541 - val_acc: 0.9524\n",
      "Epoch 800/800\n",
      "114/114 [==============================] - 0s 933us/sample - loss: 0.4926 - acc: 0.9912 - val_loss: 0.8422 - val_acc: 0.9524\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "\n",
    "reg_history = train_model(reg_model, train_data, train_targets, epochs=800)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot the learning curves\n",
    "\n",
    "Let's now plot the loss and accuracy for the training and validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'reg_history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-b8870a36c14b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreg_history\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreg_history\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'reg_history' is not defined"
     ]
    }
   ],
   "source": [
    "#Run this cell to plot the new accuracy vs epoch graph\n",
    "\n",
    "try:\n",
    "    plt.plot(reg_history.history['accuracy'])\n",
    "    plt.plot(reg_history.history['val_accuracy'])\n",
    "except KeyError:\n",
    "    plt.plot(reg_history.history['acc'])\n",
    "    plt.plot(reg_history.history['val_acc'])\n",
    "plt.title('Accuracy vs. epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Training', 'Validation'], loc='lower right')\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run this cell to plot the new loss vs epoch graph\n",
    "\n",
    "plt.plot(reg_history.history['loss'])\n",
    "plt.plot(reg_history.history['val_loss'])\n",
    "plt.title('Loss vs. epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Training', 'Validation'], loc='upper right')\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the regularisation has helped to reduce the overfitting of the network.\n",
    "You will now incorporate callbacks into a new training run that implements early stopping and learning rate reduction on plateaux.\n",
    "\n",
    "Fill in the function below so that:\n",
    "\n",
    "* It creates an `EarlyStopping` callback object and a `ReduceLROnPlateau` callback object\n",
    "* The early stopping callback is used and monitors validation loss with the mode set to `\"min\"` and patience of 30.\n",
    "* The learning rate reduction on plateaux is used with a learning rate factor of 0.2 and a patience of 20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### GRADED CELL ####\n",
    "\n",
    "# Complete the following function. \n",
    "# Make sure to not change the function name or arguments.\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "\n",
    "def get_callbacks():\n",
    "    \"\"\"\n",
    "    This function should create and return a tuple (early_stopping, learning_rate_reduction) callbacks.\n",
    "    The callbacks should be instantiated according to the above requirements.\n",
    "    \"\"\"\n",
    "    early_stop = tf.keras.callbacks.EarlyStopping( monitor='val_loss', patience=30, mode='min')\n",
    "    learning_rate_reduction = tf.keras.callbacks.ReduceLROnPlateau(patience=20, factor=0.2)\n",
    "    return early_stop, learning_rate_reduction\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the cell below to instantiate and train the regularised model with the callbacks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "call_model = get_regularised_model(train_data[0].shape, 0.3, 0.0001)\n",
    "compile_model(call_model)\n",
    "early_stopping, learning_rate_reduction = get_callbacks()\n",
    "call_history = call_model.fit(train_data, train_targets, epochs=800, validation_split=0.15,\n",
    "                         callbacks=[early_stopping, learning_rate_reduction], verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learning_rate_reduction.patience"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's replot the accuracy and loss graphs for our new model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "try:\n",
    "    plt.plot(call_history.history['accuracy'])\n",
    "    plt.plot(call_history.history['val_accuracy'])\n",
    "except KeyError:\n",
    "    plt.plot(call_history.history['acc'])\n",
    "    plt.plot(call_history.history['val_acc'])\n",
    "plt.title('Accuracy vs. epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Training', 'Validation'], loc='lower right')\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(call_history.history['loss'])\n",
    "plt.plot(call_history.history['val_loss'])\n",
    "plt.title('Loss vs. epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Training', 'Validation'], loc='upper right')\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.216\n",
      "Test accuracy: 93.33%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test set\n",
    "\n",
    "test_loss, test_acc = call_model.evaluate(test_data, test_targets, verbose=0)\n",
    "print(\"Test loss: {:.3f}\\nTest accuracy: {:.2f}%\".format(test_loss, 100 * test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations for completing this programming assignment! In the next week of the course we will learn how to save and load pre-trained models."
   ]
  }
 ],
 "metadata": {
  "coursera": {
   "course_slug": "tensor-flow-2-1",
   "graded_item_id": "mtZ4n",
   "launcher_item_id": "WphgK"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
